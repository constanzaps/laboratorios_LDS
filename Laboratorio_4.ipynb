{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Tabla de Contenidos",
      "title_sidebar": "Contenidos",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "241.867px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "enunciado_Laboratorio4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUZ1dFPHzAHl"
      },
      "source": [
        "<h1><center>Laboratorio 4: 驴Superh茅roe o Villano? Ω</center></h1>\n",
        "\n",
        "<center><strong>MDS7202: Laboratorio de Programaci贸n Cient铆fica para Ciencia de Datos</strong></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UD8X1uhGzAHq"
      },
      "source": [
        "### Cuerpo Docente:\n",
        "\n",
        "- Profesor: Pablo Badilla\n",
        "- Auxiliar: Ignacio Meza D.\n",
        "- Ayudante: Diego Irarr谩zaval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FG8a9z-YjDv4"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXflExjqzAHr"
      },
      "source": [
        "### Equipo: SUPER IMPORTANTE - notebooks sin nombre no ser谩n revisados\n",
        "\n",
        "- Nombre de alumno 1: Constanza Pe帽a\n",
        "- Nombre de alumno 2: Benjam铆n Tejeda\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AD-V0bbZzAHr"
      },
      "source": [
        "### **Link de repositorio de GitHub:** `https://github.com/constanzaps/laboratorios_LDS`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcnsiQMkzAHr"
      },
      "source": [
        "### Indice \n",
        "\n",
        "1. [Temas a tratar](#Temas-a-tratar:)\n",
        "3. [Descripcci贸n del laboratorio](#Descripci贸n-del-laboratorio.)\n",
        "4. [Desarrollo](#Desarrollo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uBLPj1PzAHs"
      },
      "source": [
        "# Temas a tratar\n",
        "\n",
        "- Clasificaci贸n con texto.\n",
        "- Clasificaci贸n en `scikit-learn`.\n",
        "- Modelos a trav茅s del uso de `pipeline`.\n",
        "- Optimizaci贸n de modelos usando `GridSearchCV`.\n",
        "\n",
        "## Reglas:\n",
        "\n",
        "- Fecha de entrega: 4/06/2021\n",
        "- **Grupos de 2 personas**\n",
        "- **Ausentes** deber谩n realizar la actividad solos. \n",
        "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser谩n respondidos por este medio.\n",
        "- Prohibidas las copias. \n",
        "- Pueden usar cualquer matrial del curso que estimen conveniente.\n",
        "\n",
        "### Objetivos principales del laboratorio\n",
        "\n",
        "- Aplicar las ventajas que nos ofrece crear un pipeline.\n",
        "- Obtener caracteristicas desde texto.\n",
        "- Crear modelos de clasificaci贸n de texto.\n",
        "- Optimizar la clasificaci贸n de texto usando wordclouds.\n",
        "- Usar herramientas de visualizaci贸n de texto como las wordclouds.\n",
        "\n",
        "El laboratorio deber谩 ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al m谩ximo las funciones optimizadas que nos entrega `pandas`, las cuales vale mencionar, son bastante m谩s eficientes que los iteradores nativos sobre DataFrames."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhISwri4zAHy"
      },
      "source": [
        "#Importamos librerias utiles "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-29T00:08:16.884674Z",
          "start_time": "2021-03-29T00:08:16.349846Z"
        },
        "id": "uyc33dKdzAHy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0098aa61-dfc1-4188-b6b0-1804391c2164"
      },
      "source": [
        "# Librer铆a Core del lab.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.model_selection import train_test_split \n",
        "\n",
        "# Pre-procesamiento\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Clasifaci贸n\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "# Metricas de evaluaci贸n\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "# Librer铆a para plotear\n",
        "!pip install --upgrade plotly\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Proyecciones en baja dimensionalidad: UMAP\n",
        "!pip install umap-learn\n",
        "\n",
        "# Librer铆a para NLP\n",
        "!pip install nltk\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize  \n",
        "from nltk.stem import PorterStemmer\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting plotly\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/f6/bd3c17c8003b6641df1228e80e1acac97ed8402635e46c2571f8e1ef63af/plotly-4.14.3-py2.py3-none-any.whl (13.2MB)\n",
            "\u001b[K     || 13.2MB 202kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly) (1.3.3)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from plotly) (1.15.0)\n",
            "Installing collected packages: plotly\n",
            "  Found existing installation: plotly 4.4.1\n",
            "    Uninstalling plotly-4.4.1:\n",
            "      Successfully uninstalled plotly-4.4.1\n",
            "Successfully installed plotly-4.14.3\n",
            "Collecting umap-learn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/69/85e7f950bb75792ad5d666d86c5f3e62eedbb942848e7e3126513af9999c/umap-learn-0.5.1.tar.gz (80kB)\n",
            "\u001b[K     || 81kB 2.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (1.4.1)\n",
            "Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (0.51.2)\n",
            "Collecting pynndescent>=0.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/65/8189298dd3a05bbad716ee8e249764ff8800e365d8dc652ad2192ca01b4a/pynndescent-0.5.2.tar.gz (1.1MB)\n",
            "\u001b[K     || 1.2MB 15.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22->umap-learn) (1.0.1)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn) (57.0.0)\n",
            "Building wheels for collected packages: umap-learn, pynndescent\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.1-cp37-none-any.whl size=76569 sha256=2ebf64187dbdcb64d3b3cfa8d4dfe9f55db53517a5d54ad0c0c7b670d370af19\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/df/d5/a3691296ff779f25cd1cf415a3af954b987fb53111e3392cf4\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynndescent: filename=pynndescent-0.5.2-cp37-none-any.whl size=51362 sha256=b39ccbc5c4303e738e469921c5068b9269005dba76dd1ef74289a4f447bf2c78\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/52/4e/4c28d04d144a28f89e2575fb63628df6e6d49b56c5ddd0c74e\n",
            "Successfully built umap-learn pynndescent\n",
            "Installing collected packages: pynndescent, umap-learn\n",
            "Successfully installed pynndescent-0.5.2 umap-learn-0.5.1\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpOTbQcxbSiy"
      },
      "source": [
        "# 1. 驴Quien es Bat Cow?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Q93vbNS25bM"
      },
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"https://static.wikia.nocookie.net/p__/images/a/a2/Bat-Cow.jpg/revision/latest?cb=20180108185037&path-prefix=protagonist\" width=\"350\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnmZfFpxTTYX"
      },
      "source": [
        "En vez de estar oprotunamente desarrollando las tareas y las evaluaciones correspondientes al curso, su profesor de catedra y su auxiliar discuten acerca la alineaci贸n del personaje de ficci贸n *Bat-Cow*. \n",
        "\n",
        "El cuerpo docente, no logra ponerse de acuerdo acerca de la alineaci贸n del personaje, es decir, si lucha junto a las fuerzas del bien, si neutral a cualquier eventualidad o derechamente es un villano.\n",
        "El auxiliar plantea (de forma superficial) que *Bat-cow* posee una siniestra mirada, com煤n caracter铆stica de los personajes malvados. \n",
        "Por otra parte, extendiendo las ideas de Rousseau, el profesor (*se cree fil贸sofo... y*) plantea que tal como los humanos no nacen malos, no existe motivo por el cual un rumiante humanizado con superpoderes deba serlo.\n",
        "\n",
        "Sin embargo, ambos concuerdan en es dif铆cil estimar la alineaci贸n solo usando los atributos f铆sicos, por lo que creen el an谩lisis debe ser complementado a煤n m谩s antes de comunicarle los resultados a su estudiantado. Buscando m谩s informaci贸n, ambos sujetos se percatan de la existencia de un excelente antecedente para estimar la alineaci贸n: la historia personal de cada superh茅roe o villano.\n",
        "\n",
        "Es por esto le solicitan que construya y optimice un clasificador basado en texto el cual analice la alineaci贸n de cada personaje basado en su historia personal.\n",
        "\n",
        "Para este laboratorio deben trabajar con los datos `df_comics.csv` y `comics_no_label.csv` subidos a u-cursos. El primero es un conjunto de datos que les servir谩 para entrenar un modelo de clasificaci贸n, mientras que el segundo es un dataset con personajes de ficci贸n no etiquetados a predecir (s铆, aqu铆 est谩 la misteriosa Batcow).\n",
        "\n",
        "Para iniciar este laboratorio, cargue los dataset se帽alados y visualice a trav茅s de la funci贸n `head` los atributos que poseen cada uno de los dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jqq-s010Iwl1",
        "outputId": "c422a4fc-a03f-4968-8708-e2b09f9828cb"
      },
      "source": [
        "# Usar solamente si utilizan Collab.\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "dir = '//content//drive//My Drive//Oto帽o 2021//Laboratorio//Lab 4//'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bED3w3tDbSCf"
      },
      "source": [
        "df_comics = pd.read_csv(dir+'df_comics.csv')\n",
        "df_comics_no_label = pd.read_csv(dir+'comics_no_label.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4tFPrFA4_O5"
      },
      "source": [
        "## 1.1 Obtenci贸n de Features [2 puntos]\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media0.giphy.com/media/eIUpSyzwGp0YhAMTKr/200.gif\" width=\"300\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_4NF0_V5XZ-"
      },
      "source": [
        "Su primera tarea consiste en generar un vector de caracter铆sticas para el atributo `history_text`. En este atributo se presenta una breve descripci贸n de la historia de cada uno de los personajes de ficci贸n presentes en el dataset (si un personaje tiene este atributo nulo, elim铆nelo). Luego, para obtener caracter铆sticas de texto aplique el modelo de conteo `bag of words` de la siguiente forma:\n",
        "\n",
        "- Utilice `CountVectorized` junto al tokenizador (que le proveemos) `LemmaTokenizer`.\n",
        "- Obtenga caracteristicas de los 1-gramas y 2-gramas del texto (ver clase).\n",
        "- Fijar un maximo de 10.000 caracteristicas para el vector de salida.\n",
        "\n",
        "Finalmente, aplique `MinMaxScaler()` sobre `atributos_de_interes` y concatene el valor obtenido con el matriz de caracteristicas obtenidas con bag of words.\n",
        "\n",
        "```python\n",
        "atributos_de_interes = ['intelligence_score', 'strength_score', 'speed_score', 'durability_score', 'power_score', 'combat_score']\n",
        "```\n",
        "\n",
        "No es necesario que obtenga un dataframe en concreto con las caracter铆sticas solicitadas. Se le recomienda generar un `ColumnTransformer()` para aplicar las transformaciones solicitadas en un pipeline.\n",
        "\n",
        "**To-Do:**\n",
        "- [ ] Obtener a traves de bag of words caracteristicas del resumen de historia de cada personaje.\n",
        "- [ ] Aplicar MinMaxScaler sobre los atributos de interes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ay080DunHcOS"
      },
      "source": [
        "#### C贸digo aqu铆 ####\n",
        "df_comics = df_comics.dropna(subset=['history_text'])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixmI9S6poGDm"
      },
      "source": [
        "stop_words = stopwords.words('english')\n",
        "\n",
        "class LemmaTokenizer:\n",
        "    def __init__(self):\n",
        "        self.ps = PorterStemmer()\n",
        "    def __call__(self, doc):\n",
        "        doc_tok = word_tokenize(doc)\n",
        "        doc_tok = [t for t in doc_tok if t not in stop_words]\n",
        "        return [self.ps.stem(t) for t in doc_tok]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIBeBtUz2IDj"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer(tokenizer=LemmaTokenizer(),\n",
        "                             lowercase=True,\n",
        "                             max_features=10000,\n",
        "                             strip_accents=\"ascii\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bGBC_SP0XJ-"
      },
      "source": [
        "bow = vectorizer.fit_transform(df_comics[\"history_text\"])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TL_0D9a04C_",
        "outputId": "434198ce-ac44-4f9e-d1e8-2a71ac84ab48"
      },
      "source": [
        "print(vectorizer.get_feature_names())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['!', '#', '$', '%', '&', \"'\", \"''\", \"'d\", \"'it\", \"'ll\", \"'m\", \"'other-realm\", \"'power\", \"'re\", \"'real\", \"'s\", \"'the\", \"'ve\", '(', ')', ',', '-', '--', '-sign-', '.', '...', '/', '/b', '/h', '/i', '030', '1', '10', '100', '1000', '11', '12', '1200', '12th', '13', '14', '142', '15', '16', '17', '18', '19', '1920', '1930', '1936', '1938', '1940', '1940.', '1941', '1942', '1943', '1944', '1945', '1946', '1947', '1949', '1950', '1953', '1954', '1958', '1959', '1960', '1961', '1962', '1963', '1964', '1970', '1972', '1973', '1975', '1976', '1977', '198', '1980', '1983', '1984', '1985', '1990', '1991', '1992', '1995', '1997', '1999', '19th', '1st', '2', '2.', '20', '2000', '2001', '2002', '2003', '2004', '2005', '2006', '2011', '2012', '2014', '2015', '2016', '2017', '2018', '2099', '20th', '21', '21st', '22', '23', '24', '25', '25th', '26', '2nd', '3', '3,000', '3.', '30', '3000', '30th', '31st', '34', '4', '4.', '40', '42', '5', '5,000', '50', '52', '6', '60', '616', '64th', '7', '70', '8', '9', '90', ':', ';', '?', '[', ']', '``', 'a-bomb', 'a.d.', 'a.i.m', 'a.i.m.', 'a.k.a', 'a.r.g.u.', 'aa', 'aaron', 'abandon', 'abbi', 'abbott', 'abdic', 'abdol', 'abduct', 'abe', 'abi', 'abigail', 'abil', 'abin', 'abl', 'ablaz', 'abner', 'abnorm', 'aboard', 'abomin', 'aborigin', 'abort', 'abra', 'abraham', 'abraxa', 'abroad', 'abruptli', 'absenc', 'absent', 'absolut', 'absorb', 'absorpt', 'abstract', 'abus', 'abyss', 'academ', 'academi', 'acanti', 'acceler', 'accept', 'access', 'accid', 'accident', 'acclaim', 'accommod', 'accompani', 'accomplic', 'accomplish', 'accord', 'accordingli', 'accost', 'account', 'accumul', 'accuraci', 'accus', 'ace', 'achiev', 'achil', 'acid', 'acknowledg', 'acolyt', 'acotilletta2', 'acquaint', 'acquir', 'acrobat', 'across', 'act', 'action', 'activ', 'activist', 'actor', 'actress', 'actual', 'ad', 'ada', 'adam', 'adamantium', 'adapt', 'add', 'adder', 'addict', 'addit', 'addl', 'address', 'adelin', 'adept', 'adher', 'adjust', 'administ', 'administr', 'admir', 'admit', 'adolesc', 'adolf', 'adopt', 'ador', 'adrenalin', 'adrian', 'adrienn', 'adrift', 'adult', 'adulthood', 'advanc', 'advantag', 'advent', 'adventur', 'adversari', 'advertis', 'advic', 'advis', 'advisor', 'aegi', 'aeri', 'aerial', 'aerospac', 'aether', 'affair', 'affect', 'affection', 'affili', 'afflict', 'afford', 'afghanistan', 'afoul', 'afraid', 'africa', 'african', 'african-american', 'afterlif', 'aftermath', 'afternoon', 'afterward', 'afterword', 'agamemnon', 'agamotto', 'agatha', 'age', 'agenc', 'agenda', 'agent', 'aggrav', 'aggress', 'agil', 'agit', 'ago', 'agoni', 'agre', 'agreement', 'ahab', 'ahead', 'ahk-ton', 'ahold', 'ai', 'aid', 'aida', 'ail', 'ailment', 'aim', 'air', 'air-walk', 'airborn', 'aircraft', 'airjitzu', 'airplan', 'airport', 'airship', 'ajax', 'aka', 'akasaka', 'akatsuki', 'akihira', 'akihiro', 'akin', 'akira', 'akita', 'akkaba', 'al', 'alan', 'alarm', 'alaska', 'albanian', 'albeit', 'albert', 'albu', 'alcatraz', 'alchemax', 'alchemi', 'alcohol', 'alderaan', 'aldo', 'alec', 'aleksei', 'alert', 'alex', 'alexand', 'alexia', 'alfr', 'ali', 'alia', 'alic', 'alicia', 'alien', 'align', 'alik', 'alison', 'aliv', 'all-american', 'all-new', 'all-out', 'all-star', 'allan', 'allat', 'alleg', 'allegedli', 'allegi', 'allen', 'allen/th', 'allevi', 'alley', 'alleyway', 'alli', 'allianc', 'allison', 'allow', 'alloy', 'almerac', 'almost', 'alon', 'along', 'alongsid', 'alp', 'alpha', 'alphonso', 'alraun', 'alreadi', 'alright', 'also', 'altar', 'alter', 'alter-ego', 'alterc', 'altern', 'although', 'altogeth', 'alucard', 'alura', 'alveu', 'alvin', 'alway', 'alyosha', 'amadeu', 'amahl', 'amalgam', 'aman', 'amanda', 'amass', 'amateur', 'amaya', 'amaz', 'amazo', 'amazon', 'amazonian', 'ambassador', 'amber', 'ambit', 'ambiti', 'ambul', 'ambush', 'amelia', 'amend', 'america', 'american', 'ami', 'amic', 'amid', 'amidst', 'amiko', 'amiss', 'ammo', 'amnesia', 'amnesiac', 'amnesti', 'amo', 'amok', 'amon', 'among', 'amongst', 'amor', 'amora', 'amount', 'amphibi', 'amplifi', 'amput', 'amulet', 'amus', 'amygdala', 'ana', 'anacondrai', 'anakin', 'analysi', 'analyz', 'anansi', 'anarki', 'ancestor', 'ancestr', 'anchor', 'ancient', 'and/or', 'ander', 'anderson', 'andi', 'ando', 'andrea', 'andrew', 'android', 'andromeda', 'anew', 'angband', 'angel', 'angela', 'angelica', 'angelo', 'angelu', 'anger', 'angl', 'angri', 'angrili', 'anguish', 'ani-m', 'ani-men', 'anim', 'animos', 'ankl', 'ann', 'anna', 'annabeth', 'annex', 'anni', 'annihil', 'annihilu', 'anniversari', 'announc', 'annoy', 'annual', 'anomali', 'anonym', 'anoth', 'answer', 'ant', 'ant-man', 'antagonist', 'antarct', 'antarctica', 'antenna', 'anthil', 'anthoni', 'anti-hero', 'anti-lif', 'anti-matt', 'anti-monitor', 'anti-mut', 'anti-spawn', 'anti-venom', 'antic', 'anticip', 'antidot', 'antimatt', 'antiop', 'antiqu', 'antithesi', 'anton', 'anya', 'anybodi', 'anymor', 'anyon', 'anyth', 'anytim', 'anyway', 'anywher', 'apach', 'apart', 'apathet', 'ape', 'apocalyps', 'apokolip', 'apollo', 'apolog', 'apostl', 'appal', 'appar', 'apparatu', 'appeal', 'appear', 'appl', 'appli', 'applic', 'appoint', 'appreci', 'apprehend', 'apprentic', 'approach', 'appropri', 'approv', 'approxim', 'april', 'aptitud', 'aqua', 'aquababi', 'aquagirl', 'aqualad', 'aquaman', 'aquat', 'aquista', 'aquon', 'arab', 'arabian', 'aramilla', 'arbit', 'arc', 'arcad', 'arcadia', 'arcadian', 'arcan', 'arch-enemi', 'archaeologist', 'archangel', 'archenemi', 'archer', 'archeri', 'archi', 'archiv', 'arclight', 'arctic', 'arcturu', 'arda', 'are', 'area', 'arena', 'argent', 'argenta', 'argo', 'argu', 'arguabl', 'argument', 'ari', 'ariana', 'ariel', 'arin', 'arion', 'aris', 'arisia', 'arizona', 'ark', 'arkham', 'arklay', 'arkon', 'arlington', 'arm', 'armada', 'armageddon', 'armament', 'armando', 'armi', 'armor', 'armori', 'armour', 'armstrong', 'arnim', 'arno', 'arnold', 'aron', 'aros', 'around', 'arous', 'arrang', 'array', 'arrest', 'arriv', 'arrog', 'arrow', 'arsen', 'art', 'artemi', 'arthur', 'arti', 'articl', 'artifact', 'artifici', 'artist', 'artoo', 'ascend', 'ascens', 'asgard', 'asgardian', 'ash', 'asha', 'asham', 'ashley', 'ashor', 'asia', 'asian', 'asid', 'ask', 'askani', 'asleep', 'asmodeu', 'aspect', 'aspheera', 'aspir', 'assail', 'assassin', 'assault', 'assembl', 'assemblag', 'assert', 'asset', 'assign', 'assimil', 'assist', 'associ', 'assort', 'assum', 'assumpt', 'assur', 'asteroid', 'asteroth', 'astonish', 'astra', 'astral', 'astronaut', 'asylum', 'ate', 'athena', 'athlet', 'atla', 'atlan', 'atlanna', 'atlant', 'atlanta', 'atlantean', 'atlanti', 'atmospher', 'atom', 'atom-smash', 'aton', 'atop', 'atroc', 'atrocitu', 'attach', 'attack', 'attain', 'attempt', 'attend', 'attent', 'attilan', 'attitud', 'attorney', 'attract', 'attribut', 'attuma', 'aubrey', 'auction', 'audienc', 'audit', 'augment', 'august', 'aunt', 'aura', 'aurora', 'auschwitz', 'auspic', 'australia', 'australian', 'austria', 'author', 'autobiographi', 'automat', 'automaton', 'automobil', 'autumn', 'avail', 'avalanch', 'avalon', 'avatar', 'aveng', 'avenu', 'averag', 'avers', 'avert', 'avia', 'avil', 'avoid', 'avram', 'aw', 'await', 'awak', 'awaken', 'awar', 'award', 'away', 'awe', 'awesom', 'awhil', 'awkward', 'awok', 'awoken', 'awri', 'axe', 'axi', 'axl', 'axlon', 'ayla', 'az-bat', 'azazel', 'azimuth', 'azkaban', 'azrael', 'b', 'b.', 'b.j', 'b.o.w.', 'b.p.r.d', 'babel', 'babi', 'babidi', 'babylon', 'babysitt', 'bach', 'back', 'back-up', 'backfir', 'background', 'backlash', 'backstori', 'backup', 'backward', 'bad', 'badg', 'badli', 'badnik', 'badoon', 'baelish', 'baffler', 'bag', 'bagalia', 'bail', 'bailey', 'bain', 'bait', 'baker', 'balanc', 'balconi', 'bald', 'balder', 'baldwin', 'balkan', 'ball', 'balrog', 'ban', 'bana-mighdal', 'band', 'bandag', 'bandit', 'bane', 'bang', 'banish', 'bank', 'banner', 'banshe', 'bantam', 'bar', 'baratheon', 'barb', 'barbara', 'barbarian', 'bard', 'barda', 'bare', 'barg', 'bargain', 'barlow', 'barn', 'barney', 'baro', 'baron', 'barrag', 'barren', 'barri', 'barrier', 'barrington', 'bart', 'bartino', 'barton', 'base', 'basebal', 'basement', 'basi', 'basic', 'basketbal', 'bass', 'bastard', 'bastion', 'bat', 'bat-famili', 'batarang', 'batcav', 'batgirl', 'bath', 'bathroom', 'batman', 'batmobil', 'batroc', 'batson', 'batsuit', 'battalion', 'batter', 'batteri', 'battl', 'battle-suit', 'battlefield', 'battleground', 'battlestar', 'battlesuit', 'battleworld', 'batw', 'batwoman', 'bauer', 'baxter', 'bay', 'bazin', 'bc', 'be', 'beach', 'beacon', 'beak', 'beal', 'beam', 'bear', 'beard', 'bearer', 'beast', 'beat', 'beaten', 'beatric', 'beaubier', 'beauti', 'becam', 'beck', 'beckett', 'becom', 'bed', 'bedlam', 'bedroom', 'bee', 'beelzebub', 'beer', 'beetl', 'beforehand', 'befriend', 'beg', 'began', 'begin', 'begrudgingli', 'begun', 'behalf', 'behavior', 'behaviour', 'behead', 'behemoth', 'behest', 'behind', 'bekka', 'belasco', 'belief', 'believ', 'bell', 'bella', 'belling', 'belmond', 'belmont', 'belong', 'belov', 'belova', 'belt', 'ben', 'bend', 'beneath', 'benefactor', 'benefici', 'benefit', 'benevol', 'benjamin', 'bennet', 'bent', 'bentley', 'bequeath', 'berat', 'beret', 'berlin', 'bermuda', 'bernard', 'berni', 'berra', 'berserk', 'bertinelli', 'bertron', 'besid', 'besieg', 'best', 'bestial', 'bestow', 'bet', 'beta', 'beth', 'betray', 'betroth', 'betsi', 'bett', 'better', 'betti', 'beverli', 'bevi', 'bewild', 'beyond', 'bialya', 'bibl', 'bicker', 'bid', 'bidder', 'bide', 'bifrost', 'big', 'big-daddi', 'bigger', 'biggest', 'bill', 'billi', 'billion', 'billionair', 'binari', 'bind', 'bio-belt', 'bio-weapon', 'biochem', 'biochemist', 'biochemistri', 'bioelectr', 'biographi', 'biohazard', 'biolog', 'biologist', 'biomet', 'bionic', 'bird', 'birdman', 'birkin', 'birth', 'birthday', 'birthplac', 'birthright', 'bishop', 'bit', 'bite', 'bitten', 'bitter', 'bizarr', 'bizarro', 'bizarro-girl', 'bizarrogirl', 'black', 'blackest', 'blackgat', 'blackguard', 'blackhawk', 'blackheart', 'blackmail', 'blackout', 'blacksmith', 'blackw', 'blackwatch', 'blackwel', 'blade', 'blair', 'blake', 'blame', 'blank', 'blast', 'blastaar', 'blaster', 'blaze', 'bldhaven', 'bleach', 'bleak', 'bleed', 'blend', 'bless', 'blew', 'blight', 'blind', 'blindfold', 'bling', 'blink', 'blizzard', 'blob', 'block', 'blockbust', 'blond', 'blonski', 'blood', 'bloodax', 'bloodhawk', 'bloodi', 'bloodlin', 'bloodlust', 'bloodsh', 'bloodsport', 'bloodston', 'bloodthirsti', 'bloodwraith', 'blossom', 'blow', 'blown', 'bludgeon', 'bludhaven', 'blue', 'blueprint', 'blunt', 'blur', 'board', 'boast', 'boat', 'boathous', 'bob', 'bobbi', 'boch', 'bodi', 'bodili', 'bodyguard', 'bodysuit', 'bogan', 'boil', 'bokk', 'bolivar', 'bolland', 'bolovax', 'bolster', 'bolt', 'bomb', 'bombard', 'bomber', 'bombshel', 'bond', 'bone', 'bong', 'boo', 'boobi', 'booby-trap', 'boodikka', 'book', 'boom', 'boom-boom', 'boomer', 'boomerang', 'boon', 'boost', 'booster', 'boot', 'booth', 'bor', 'borazzon', 'border', 'bore', 'boreal', 'boredom', 'borg', 'born', 'borrow', 'boss', 'boston', 'botan', 'botanist', 'bother', 'bottl', 'bottom', 'bought', 'boulder', 'bounc', 'bound', 'boundari', 'bounti', 'bout', 'bova', 'bow', 'bowen', 'bowl', 'bowser', 'box', 'boxer', 'boy', 'boyfriend', 'boyl', 'bprd', 'bracelet', 'braddock', 'bradley', 'brag', 'brain', 'braini', 'brainiac', 'brainpow', 'brainwash', 'brainwav', 'branch', 'brand', 'brandt', 'brash', 'brauner', 'brave', 'braveri', 'brawl', 'brazil', 'breach', 'break', 'breakdown', 'breaker', 'breakout', 'breakthrough', 'breakup', 'breakworld', 'breath', 'breed', 'brenda', 'brendan', 'brent', 'brethren', 'brew', 'brian', 'bribe', 'bride', 'bridg', 'brief', 'briefcas', 'briefli', 'brigad', 'bright', 'brightest', 'brightwind', 'brik', 'brilliant', 'brimston', 'bring', 'brink', 'britain', 'british', 'briton', 'britt', 'broadcast', 'brock', 'broke', 'broken', 'broken-heart', 'broker', 'bronz', 'brood', 'brooklyn', 'bros.', 'brothel', 'brother', 'brotherhood', 'brought', 'brown', 'bruce', 'bruis', 'brujeria', 'brundl', 'brundlefli', 'brunnhild', 'brunt', 'brush', 'brutaal', 'brutal', 'brute', 'brutish', 'bruttenholm', 'bryan', 'bryant', 'bsaa', 'bu', 'bubbl', 'buchanan', 'bucki', 'bud', 'buddi', 'buffi', 'bug', 'bugl', 'build', 'builder', 'built', 'bulk', 'bull', 'bullet', 'bulli', 'bullock', 'bullsey', 'bum', 'bumblebe', 'bumbleboy', 'bump', 'bunker', 'burden', 'bureau', 'bureaucrat', 'burgeon', 'burglar', 'burglari', 'buri', 'burial', 'burk', 'burn', 'burnt', 'burr', 'burst', 'burstein', 'burton', 'burtram', 'bushido', 'bushman', 'bushmast', 'busi', 'businessman', 'businessmen', 'bust', 'buster', 'butcher', 'butler', 'button', 'buu', 'buy', 'buyer', 'bypass', 'byron', 'bystand', 'c.', 'c4', 'ca', 'cabal', 'cabba', 'cabe', 'cabin', 'cabinet', 'cabl', 'cach', 'cadet', 'cadmu', 'cadr', 'caesar', 'cafe', 'cafeteria', 'cage', 'caiera', 'cain', 'cairo', 'caitlin', 'cake', 'calam', 'calcul', 'calendar', 'caliban', 'caliburn', 'california', 'call', 'callisto', 'calm', 'calmli', 'calogero', 'calvari', 'calvin', 'calypso', 'came', 'camelot', 'cameo', 'camera', 'cameron', 'cammi', 'camp', 'campaign', 'campbel', 'campu', 'canada', 'canadian', 'canari', 'cancel', 'cancer', 'cancervers', 'candi', 'candid', 'candl', 'cane', 'cani', 'canist', 'cannon', 'cannonbal', 'canon', 'canyon', 'cap', 'capabl', 'capac', 'cape', 'caper', 'capit', 'capitol', 'cappi', 'capsul', 'captain', 'captiv', 'captor', 'captur', 'car', 'caraka', 'carbonadium', 'card', 'cardboard', 'cardiac', 'cardin', 'care', 'career', 'careless', 'caretak', 'cargg', 'cargil', 'cargo', 'caribbean', 'carjack', 'carl', 'carlton', 'carmin', 'carnag', 'carniv', 'carol', 'carolina', 'carolyn', 'carpent', 'carri', 'carrier', 'carrion', 'carson', 'cartel', 'carter', 'cartoon', 'carv', 'case', 'cash', 'casino', 'casket', 'cassandra', 'cassi', 'cassidi', 'cast', 'castl', 'castlevania', 'casual', 'casualti', 'cat', 'cat-lik', 'cat-soul', 'cataclysm', 'catastroph', 'cataton', 'catch', 'catelyn', 'cathedr', 'cathol', 'catman', 'catwoman', 'caucasian', 'caught', 'caul', 'caulifla', 'caus', 'caution', 'cavallo', 'cave', 'cave-in', 'cavendish', 'cavern', 'caviti', 'cbi', 'cd', 'ceas', 'cede', 'ceil', 'celebr', 'celesti', 'cell', 'cellmat', 'cellular', 'cement', 'cemeteri', 'center', 'centiped', 'centr', 'central', 'centuri', 'centurion', 'ceo', 'cerdia', 'cerebr', 'cerebra', 'cerebro', 'ceremoni', 'cersei', 'certain', 'certainli', 'certif', \"ch'od\", 'cha', 'chafe', 'chagrin', 'chain', 'chainsaw', 'chair', 'chairman', 'challeng', 'chamber', 'chameleon', 'champa', 'champion', 'chanc', 'chancellor', 'chandler', 'chang', 'changel', 'channel', 'chantinel', 'chao', 'chaotic', 'chapel', 'chapter', 'char', 'charact', 'characterist', 'charax', 'charg', 'charit', 'chariti', 'charl', 'charlemagn', 'charli', 'charlott', 'charm', 'charter', 'chase', 'chasm', 'chast', 'chastis', 'chat', 'cheap', 'cheat', 'check', 'checkmat', 'cheer', 'cheerlead', 'cheetah', 'chemic', 'chemistri', 'chemo', 'chen', 'cheney', 'cheshir', 'chess', 'chessmen', 'chest', 'chew', 'chewbacca', 'cheyenn', 'chi', 'chiantang', 'chicago', 'chico', 'chief', 'child', 'childbirth', 'childhood', 'childlik', 'children', 'chimera', 'chimp', 'china', 'chines', 'chip', 'chitauri', 'cho', 'choi', 'choic', 'choke', 'choos', 'chop', 'chopper', 'chose', 'chosen', 'chri', 'christ', 'christen', 'christian', 'christin', 'christina', 'christma', 'christoph', 'chronal', 'chronicl', 'chrono', 'chronopoli', 'chrysali', 'chu', 'chuck', 'chuma', 'chunk', 'church', 'chute', 'cia', 'ciel', 'cindi', 'cipher', 'circ', 'circa', 'circl', 'circu', 'circuit', 'circuitri', 'circul', 'circumst', 'cisco', 'citadel', 'citat', 'cite', 'citi', 'citizen', 'citizenship', 'civil', 'civilian', 'clad', 'claim', 'clair', 'clan', 'clandestin', 'clariss', 'clark', 'clash', 'class', 'classic', 'classif', 'classifi', 'classmat', 'claudett', 'claw', 'clay', 'clayfac', 'clea', 'clean', 'cleans', 'clear', 'clearli', 'cleric', 'clever', 'client', 'cliff', 'climact', 'climat', 'climax', 'climb', 'clinic', 'clint', 'cloak', 'clock', 'clone', 'close', 'closer', 'closest', 'closet', 'closur', 'cloth', 'cloud', 'clous', 'clown', 'clu', 'club', 'clue', 'cluemast', 'cluster', 'clutch', 'clyde', 'co-lead', 'co-work', 'co.', 'coach', 'coagul', 'coal', 'coalit', 'coast', 'coat', 'cobalt', 'cobblepot', 'cobra', 'cocain', 'cocki', 'cockpit', 'coconut', 'cocoon', 'cocott', 'code', 'code-nam', 'codenam', 'coerc', 'coexist', 'coffe', 'coffin', 'cog', 'cogliostro', 'cohort', 'coin', 'coincid', 'coincident', 'col.', 'colcord', 'cold', 'coldfir', 'cole', 'collabor', 'collaps', 'collar', 'colleagu', 'collect', 'collector', 'colleen', 'colleg', 'collid', 'collin', 'collis', 'colombian', 'colonel', 'coloni', 'color', 'colorado', 'coloss', 'colossu', 'colu', 'coluan', 'columbia', 'column', 'coma', 'comatos', 'combat', 'combin', 'come', 'comedian', 'comet', 'comfort', 'comic', 'command', 'commando', 'commemor', 'commenc', 'commend', 'comment', 'commerci', 'commiss', 'commission', 'commit', 'committe', 'common', 'commonli', 'commun', 'communist', 'compani', 'companion', 'compar', 'comparison', 'compart', 'compass', 'compassion', 'compatriot', 'compel', 'compens', 'compet', 'competit', 'competitor', 'complac', 'complain', 'complet', 'complex', 'compli', 'complic', 'compliment', 'compon', 'compos', 'composit', 'compound', 'comprehens', 'compris', 'compromis', 'compuls', 'comput', 'comrad', 'conal', 'conceal', 'conced', 'conceiv', 'concentr', 'concept', 'concern', 'conclud', 'conclus', 'concoct', 'concret', 'concuss', 'condemn', 'condit', 'conduct', 'conduit', 'confederaci', 'confer', 'confess', 'confid', 'confidant', 'confin', 'confirm', 'confisc', 'conflict', 'confront', 'confus', 'conglomer', 'congratul', 'connect', 'connecticut', 'conner', 'connor', 'conquer', 'conqueror', 'conquest', 'conscienc', 'consciou', 'conscious', 'consent', 'consequ', 'consid', 'consider', 'consist', 'consol', 'consort', 'conspir', 'conspiraci', 'constant', 'constantin', 'constantli', 'constrictor', 'construct', 'consult', 'consum', 'consumm', 'consumpt', 'contact', 'contain', 'contamin', 'contempl', 'contemporari', 'contend', 'content', 'contest', 'contin', 'conting', 'continu', 'continuum', 'contract', 'contrail', 'contrari', 'contrast', 'contraxia', 'contraxian', 'contribut', 'control', 'controversi', 'convalesc', 'conveni', 'convent', 'converg', 'convers', 'convert', 'convict', 'convinc', 'convoy', 'cook', 'cooki', 'cool', 'cooper', 'coordin', 'cop', 'cope', 'copi', 'copperhead', 'copycat', 'corben', 'cord', 'core', 'corneliu', 'corner', 'corona', 'corp', 'corpor', 'corps', 'corpsmen', 'correct', 'correctli', 'correspond', 'corrigan', 'corrupt', 'corsair', 'cortana', 'cortex', 'cortez', 'corusc', 'corvu', 'cosmic', 'cosmo', 'cost', 'costa', 'costum', 'cottonmouth', 'cough', 'could', 'couldnt', 'coulson', 'council', 'counsel', 'count', 'countdown', 'counter', 'counter-attack', 'counter-earth', 'counteract', 'counterpart', 'counti', 'countless', 'countri', 'coup', 'coupl', 'courag', 'courier', 'cours', 'court', 'courtley', 'courtney', 'cousin', 'cove', 'coven', 'cover', 'covert', 'covertli', 'covet', 'cow', 'coward', 'cowl', 'coy', 'cpr', 'cqc', 'crabrant', 'crack', 'crackajack', 'craft', 'crane', 'crash', 'crash-land', 'crashland', 'crate', 'crave', 'crawford', 'crawl', 'cray', 'craze', 'crazi', 'cream', 'creat', 'creation', 'creativ', 'creator', 'creatur', 'credit', 'creed', 'creel', 'crescent', 'crew', 'cri', 'crime', 'crime-boss', 'crime-fight', 'crime-lord', 'crimebust', 'crimefight', 'crimelord', 'crimin', 'criminolog', 'crimson', 'crippl', 'crise', 'crisi', 'critic', 'croc', 'crocodil', 'cronal', 'croni', 'cronu', 'crook', 'cross', 'cross-tim', 'crossbon', 'crossfir', 'crossov', 'crouch', 'crow', 'crowbar', 'crowd', 'crown', 'crucial', 'crucibl', 'crucifi', 'crude', 'cruel', 'cruelti', 'cruiser', 'crumbl', 'crusad', 'crush', 'crusher', 'cruz', 'cryogen', 'crypt', 'cryptic', 'crystal', 'crystallin', 'csa', 'cuba', 'cuban', 'cube', 'cubot', 'cuckoo', 'cull', 'culloden', 'culmin', 'culprit', 'cult', 'cultist', 'cultur', 'cun', 'cup', 'curat', 'curb', 'cure', 'curios', 'curiou', 'current', 'curri', 'curs', 'curt', 'curtail', 'curti', 'custer', 'custodi', 'custom', 'cut', 'cy-gor', 'cyber', 'cyberdemon', 'cyberdyn', 'cyberfac', 'cybermanc', 'cybernet', 'cyberspac', 'cyborg', 'cycl', 'cyclop', 'cylind', 'cynic', 'cynthia', 'cypher', 'cypru', 'cyru', 'cyttorak', 'czarnian', 'czonk', \"d'bari\", \"d'ken\", \"d'nur\", \"d'spayr\", 'd.c.', 'd.l', 'da', 'dad', 'daddi', 'daedalu', 'dagger', 'daili', 'daimio', 'daimon', 'daisi', 'daken', 'dakimh', 'dakota', 'dale', 'dalla', 'dalton', 'dam', 'dama', 'damag', 'damian', 'damien', 'damn', 'damnat', 'dampen', 'dan', 'dana', 'danc', 'dane', 'danger', 'dani', 'daniel', 'danni', 'dant', 'danver', 'daphn', 'dare', 'daredevil', 'dareth', 'darhk', 'dark', 'darkchild', 'darker', 'darkest', 'darkforc', 'darkhawk', 'darkhold', 'darkholm', 'darkl', 'darkley', 'darklord', 'darkseid', 'darksoul', 'darkstar', 'darl', 'darla', 'darren', 'dart', 'darth', 'darwin', 'dash', 'data', 'databas', 'date', 'daughter', 'dava', 'dave', 'davi', 'david', 'davo', 'dawn', 'daxamit', 'daximit', 'day', 'daydream', 'daylight', 'dayton', 'daze', 'dazzler', 'dc', 'dcu', 'de', 'de-ag', 'de-pow', 'deactiv', 'dead', 'deadli', 'deadliest', 'deadman', 'deadpool', 'deadpooli', 'deadshot', 'deafen', 'deag', 'deal', 'dealer', 'dealt', 'dean', 'dearli', 'death', 'death-stalk', 'death/archangel', 'deathangel', 'deathb', 'deathbird', 'deathcard', 'deathcri', 'deathli', 'deathlok', 'deathstorm', 'deathstrik', 'deathstrok', 'debacl', 'debat', 'debbi', 'debilit', 'deborah', 'debri', 'debt', 'debut', 'decad', 'decapit', 'decay', 'deceas', 'deceit', 'deceiv', 'decemb', 'decept', 'decid', 'decim', 'deciph', 'decis', 'deck', 'declar', 'declin', 'decommiss', 'decor', 'decoy', 'decre', 'decreas', 'dedic', 'deduc', 'deed', 'deem', 'deep', 'deeper', 'deepli', 'default', 'defeat', 'defect', 'defenc', 'defend', 'defens', 'defi', 'defianc', 'defiant', 'defin', 'definit', 'deflect', 'deform', 'defus', 'degaton', 'degener', 'degre', 'deimo', 'deiti', 'delay', 'deleg', 'delet', 'delfino', 'delgado', 'deliber', 'delight', 'delirium', 'deliv', 'deliveri', 'delta', 'deltit', 'delus', 'demand', 'demara', 'demeanor', 'dement', 'dementor', 'demis', 'demiurg', 'demiurgo', 'democrat', 'demogoblin', 'demolish', 'demolit', 'demolition-man', 'demon', 'demonstr', 'demot', 'den', 'deni', 'denial', 'denizen', 'denounc', 'dent', 'depart', 'departur', 'depend', 'depict', 'deplet', 'deploy', 'deport', 'depos', 'deposit', 'depow', 'depress', 'depriv', 'depth', 'deputi', 'derang', 'derek', 'derelict', 'deriv', 'desaad', 'descend', 'descent', 'describ', 'desert', 'deserv', 'design', 'desir', 'desk', 'desmond', 'despair', 'desper', 'despero', 'despis', 'despit', 'despond', 'despot', 'destabil', 'destin', 'destini', 'destroy', 'destruct', 'det', 'detach', 'detail', 'detect', 'detent', 'deter', 'deterior', 'determin', 'dethron', 'deton', 'detroit', 'devast', 'develop', 'deviant', 'devic', 'devil', 'devil-hulk', 'devilman', 'devilmen', 'devis', 'devlin', 'devo', 'devoid', 'devot', 'devour', 'dexter', 'dez', 'dh', 'dherain', 'diablo', 'diagnos', 'dialogu', 'diamond', 'diamondback', 'dian', 'diana', 'diari', 'diaz', 'dibacco', 'dibni', 'dick', 'dictat', 'didnt', 'die', 'diego', 'differ', 'difficult', 'difficulti', 'dig', 'digger', 'diggl', 'digit', 'dillard', 'dillon', 'dimens', 'dimension', 'diminish', 'diminut', 'dimpl', 'dinah', 'diner', 'dinner', 'dinosaur', 'diplomat', 'dire', 'direct', 'directli', 'director', 'dirt', 'dirti', 'disabl', 'disagr', 'disagre', 'disappear', 'disappoint', 'disapprov', 'disarm', 'disassembl', 'disast', 'disastr', 'disavow', 'disband', 'disc', 'discard', 'discern', 'discharg', 'discipl', 'disciplin', 'discomfort', 'disconnect', 'discorpor', 'discov', 'discoveri', 'discredit', 'discuss', 'disdain', 'diseas', 'disembodi', 'disfigur', 'disgrac', 'disgruntl', 'disguis', 'disgust', 'dishearten', 'disillus', 'disintegr', 'disinterest', 'disk', 'dislik', 'dismantl', 'dismay', 'dismemb', 'dismiss', 'disobey', 'disord', 'disori', 'disown', 'dispatch', 'dispel', 'dispers', 'displac', 'display', 'displeas', 'dispos', 'disput', 'disqualifi', 'disregard', 'disrupt', 'dissatisfi', 'dissect', 'dissip', 'dissolv', 'distanc', 'distant', 'distinct', 'distinguish', 'distort', 'distract', 'distraught', 'distress', 'distribut', 'district', 'distrust', 'disturb', 'ditch', 'dive', 'diverg', 'divers', 'divert', 'divid', 'divin', 'divis', 'divorc', 'djinjago', 'djinn', 'dna', 'doc', 'dock', 'doctor', 'document', 'dodd', 'dodg', 'dodon', 'dog', 'dolan', 'doll', 'dollar', 'dollmak', 'dolphin', 'dom', 'domain', 'dome', 'domest', 'domin', 'domino', 'dominu', 'domo', 'don', 'donalbain', 'donald', 'donat', 'done', 'donkey', 'donna', 'dooku', 'doom', 'doomguy', 'doomsday', 'door', 'doorbel', 'doorstep', 'doorway', 'doppelgang', 'doppler', 'dora', 'dori', 'dorm', 'dorma', 'dormammu', 'dormant', 'dorothi', 'dorsal', 'dose', 'dosu-roku', 'dotzler', 'doubl', 'double-cross', 'doubt', 'doug', 'dougla', 'dous', 'dove', 'down', 'downfal', 'download', 'downtown', 'dox', 'dozen', 'dr', 'dr.', 'draaga', 'dracula', 'draft', 'drag', 'drago', 'dragon', 'drain', 'drake', 'drama', 'dramat', 'drank', 'draper', 'drastic', 'draw', 'drawn', 'drax', 'dread', 'dream', 'dreiberg', 'dress', 'drew', 'dri', 'drift', 'drill', 'drink', 'drive', 'driven', 'driver', 'droid', 'drone', 'drop', 'drove', 'drown', 'drug', 'druid', 'drunk', 'drunken', 'du', 'dual', 'dub', 'duck', 'dud', 'due', 'duel', 'duela', 'dug', 'dugan', 'duke', 'dum', 'dumb', 'dumbledor', 'dummi', 'dump', 'duncan', 'duo', 'dupe', 'duplic', 'durabl', 'durat', 'duress', 'duro', 'dust', 'dutch', 'dutchman', 'duti', 'dwarf', 'dwarfstar', 'dwell', 'dweller', 'dwight', 'dwindl', 'dyna-mit', 'dynam', 'dynamo', 'dyne', 'dysfunct', 'dyspo', 'dyvyn', 'dzerchenko', 'e', 'e-mail', 'e.', 'eager', 'eagerli', 'eagl', 'ear', 'earli', 'earlier', 'earliest', 'earn', 'earth', 'earth-1', 'earth-2', 'earth-3', 'earth-3145', 'earth-4935', 'earth-616', 'earth-on', 'earth-prim', 'earth-realm', 'earth-thre', 'earth-two', 'earth-x', 'earthgov', 'earthl', 'earthli', 'earthquak', 'earthrealm', 'eas', 'easi', 'easier', 'easili', 'east', 'eastern', 'eat', 'eaten', 'eater', 'eboni', 'eccentr', 'ecclesia', 'echidna', 'echo', 'eck', 'eclips', 'eclipso', 'eco-terrorist', 'ecolog', 'economi', 'ed', 'eddard', 'eddi', 'eden', 'edg', 'edgar', 'edit', 'editor', 'editori', 'edna', 'educ', 'edward', 'edwin', 'eel', 'effect', 'effici', 'effort', 'effortlessli', 'egg', 'egghead', 'eggman', 'eggpawn', 'ego', 'egypt', 'egyptian', 'eidolon', 'eight', 'eighteen', 'eighth', 'eil', 'einherjar', 'either', 'eject', 'el', 'elabor', 'elain', 'elastigirl', 'elba', 'elder', 'elderli', 'eldest', 'elect', 'electr', 'electro', 'electro-psion', 'electrocut', 'electrocution', 'electromagnet', 'electron', 'elektra', 'element', 'elena', 'elev', 'eleven', 'elf', 'elfqueen', 'eli', 'elia', 'elimin', 'elis', 'elisabetha', 'elit', 'elixir', 'elizabeth', 'ell', 'ellen', 'elli', 'elliot', 'elong', 'elpizo', 'els', 'elsewher', 'elud', 'elv', 'eman', 'embark', 'embarrass', 'embassi', 'embed', 'ember', 'embezzl', 'embitt', 'emblem', 'embodi', 'embrac', 'embroil', 'embryo', 'emerald', 'emerg', 'emerl', 'emerson', 'emigr', 'emil', 'emili', 'emissari', 'emit', 'emma', 'emot', 'emotionless', 'emp', 'empath', 'emperor', 'empir', 'emplat', 'employ', 'employe', 'empow', 'empress', 'empti', 'empyrean', 'emul', 'en', 'enabl', 'enact', 'enamor', 'encas', 'enchant', 'enchantress', 'encount', 'encourag', 'end', 'endang', 'endeavor', 'endgam', 'endless', 'endors', 'endoskeleton', 'endow', 'endur', 'enemi', 'energi', 'enfant', 'enforc', 'engag', 'engin', 'england', 'english', 'engulf', 'enhanc', 'enigma', 'enigmat', 'enjoy', 'enlarg', 'enlighten', 'enlist', 'enmiti', 'enorm', 'enough', 'enrag', 'enrol', 'enslav', 'ensu', 'ensur', 'enter', 'enterpris', 'entertain', 'enthusiast', 'entir', 'entireti', 'entiti', 'entitl', 'entourag', 'entranc', 'entrap', 'entri', 'entropi', 'entrust', 'envelop', 'environ', 'environment', 'eobar', 'eobard', 'eon', 'epic', 'epiphani', 'episod', 'equal', 'equat', 'equip', 'equival', 'era', 'erad', 'eras', 'erazor', 'erdel', 'erect', 'eric', 'erik', 'ernest', 'eron', 'errant', 'errat', 'error', 'erupt', 'erwin', 'eryni', 'escal', 'escap', 'escort', 'eskimo', 'especi', 'espionag', 'essenc', 'essenti', 'essex', 'establish', 'estat', 'estrang', 'esva', 'etc', 'etern', 'ethan', 'ethic', 'ethnic', 'etrigan', 'etta', 'eugen', 'eurasia', 'europ', 'european', 'eva', 'evacu', 'evad', 'evan', 'eve', 'evelyn', 'even', 'evenli', 'event', 'eventu', 'ever', 'ever-flust', 'everett', 'everglad', 'everi', 'everybodi', 'everyday', 'everyon', 'everyth', 'everywher', 'evid', 'evil', 'evildo', 'evilhawk', 'evok', 'evolut', 'evolutionari', 'evolv', 'ex', 'ex-boyfriend', 'ex-girlfriend', 'ex-husband', 'ex-wif', 'exacerb', 'exact', 'exactli', 'examin', 'exampl', 'excalibur', 'excav', 'exceed', 'excel', 'except', 'excess', 'exchang', 'excit', 'exclus', 'excus', 'execut', 'execution', 'exemplar', 'exempt', 'exercis', 'exert', 'exhaust', 'exhibit', 'exhum', 'exil', 'exist', 'exit', 'exodu', 'exoner', 'exorc', 'exorcis', 'exorcist', 'expand', 'expans', 'expect', 'expel', 'expend', 'expens', 'experi', 'experienc', 'experiment', 'expert', 'expertis', 'expir', 'explain', 'explan', 'explicitli', 'explod', 'exploit', 'explor', 'explos', 'expos', 'exposur', 'express', 'expuls', 'extant', 'extend', 'extens', 'extent', 'extermin', 'extern', 'extinct', 'extinguish', 'extort', 'extra', 'extra-dimension', 'extract', 'extractor', 'extradimension', 'extradit', 'extraordinari', 'extraordinarili', 'extraterrestri', 'extrem', 'extremi', 'eye', 'ezekiel', 'ezio', 'f.b.i', 'fabian', 'fabl', 'fabric', 'facad', 'face', 'face-to-fac', 'facehugg', 'faceless', 'facial', 'facil', 'facilit', 'fact', 'faction', 'facto', 'factor', 'factori', 'fade', 'fail', 'fail-saf', 'failur', 'faint', 'fair', 'fairli', 'faith', 'fake', 'falcon', 'fall', 'fallen', 'fals', 'falsworth', 'faltin', 'fame', 'famili', 'familiar', 'famin', 'famou', 'fan', 'fanat', 'fandral', 'fang', 'fangpyr', 'fangtom', 'fantasi', 'fantast', 'fantomex', 'faora', 'far', 'faraday', 'farewel', 'farm', 'farmer', 'farouk', 'farther', 'fascin', 'fashion', 'fast', 'faster', 'fastest', 'fatal', 'fate', 'father', 'fatheri', 'fault', 'faulti', 'faust', 'faustu', 'favor', 'favorit', 'fawcett', 'fay', 'fbi', 'feanor', 'fear', 'fearless', 'fearsom', 'feat', 'feather', 'featur', 'februari', 'fed', 'feder', 'fee', 'feed', 'feel', 'feet', 'feign', 'felic', 'felicia', 'felin', 'felix', 'fell', 'fellow', 'felt', 'femal', 'fen', 'fenc', 'fend', 'feng-tu', 'fenri', 'feral', 'fermin', 'fernu', 'feroci', 'ferret', 'ferri', 'ferro', 'ferrouz', 'festiv', 'fett', 'feud', 'fever', 'fey', 'ff', 'fianc', 'fiance', 'fiction', 'field', 'fiend', 'fierc', 'fieri', 'fifteen', 'fifth', 'fifti', 'fight', 'fighter', 'figur', 'file', 'fill', 'film', 'fin', 'final', 'financ', 'financi', 'finarfin', 'find', 'fine', 'finest', 'finger', 'fingernail', 'fingerprint', 'fingolfin', 'finish', 'finn', 'finw', 'fiona', 'fire', 'firearm', 'firebal', 'firebird', 'firebrand', 'firefight', 'firefli', 'fireheart', 'firelord', 'firestar', 'firestorm', 'firm', 'firmli', 'first', 'first-born', 'firstborn', 'firstbourn', 'fish', 'fisherman', 'fisk', 'fissur', 'fist', 'fit', 'fitz', 'fitzgerald', 'fitzroy', 'five', 'fix', 'fixat', 'fixer', 'fixit', 'fiyero', 'flag', 'flagship', 'flame', 'flamebird', 'flamethrow', 'flare', 'flash', 'flashback', 'flashpoint', 'flat', 'flaw', 'fled', 'fledgl', 'flee', 'fleet', 'fleme', 'flesh', 'fletcher', 'flew', 'flexibl', 'fli', 'flicker', 'flicki', 'flight', 'fling', 'flint', 'flip', 'flirt', 'flirtat', 'float', 'flood', 'floodgat', 'floor', 'flore', 'florida', 'floron', 'flow', 'flower', 'flown', 'floyd', 'fluctuat', 'fluid', 'flung', 'flush', 'flute', 'focu', 'focus', 'foe', 'foggi', 'foil', 'fold', 'follow', 'foment', 'fond', 'food', 'fool', 'foolish', 'foom', 'foot', 'footag', 'footbal', 'footstep', 'forbad', 'forbid', 'forbidden', 'forbush', 'forc', 'force-field', 'force-sensit', 'forcibl', 'forearm', 'forehead', 'foreign', 'foremost', 'forerunn', 'forese', 'foreseen', 'foreshadow', 'forest', 'foretold', 'forev', 'forfeit', 'forg', 'forgav', 'forgeri', 'forget', 'forgiv', 'forgiven', 'forgot', 'forgotten', 'form', 'formal', 'format', 'formeno', 'former', 'formerli', 'formid', 'formul', 'formula', 'forrest', 'fort', 'forth', 'forti', 'fortifi', 'fortress', 'fortun', 'fortunato', 'forward', 'foster', 'foswel', 'fought', 'found', 'foundat', 'founder', 'foundri', 'fountain', 'four', 'fourarm', 'foursom', 'fourteen', 'fourth', 'fox', 'foxdi', 'foxhound', 'foxx', 'fraction', 'fractur', 'fragil', 'fragment', 'frail', 'frame', 'framework', 'franc', 'franci', 'francin', 'francisco', 'frank', 'frankenstein', 'franklin', 'fransisco', 'frantic', 'fratern', 'fraud', 'fray', 'freak', 'fred', 'freddi', 'free', 'freed', 'freedom', 'freelanc', 'freeman', 'freez', 'freeza', 'french', 'frenzi', 'frequenc', 'frequent', 'fresh', 'freshman', 'fri', 'friction', 'friend', 'friendli', 'friendship', 'frieza', 'frigga', 'fright', 'frighten', 'frodo', 'frog', 'frog-man', 'front', 'frontier', 'frontlin', 'frost', 'froze', 'frozen', 'fruit', 'fruition', 'frustrat', 'frye', 'fu', 'fuel', 'fugit', 'fujikawa', 'fulfil', 'full', 'full-fledg', 'full-forc', 'full-scal', 'full-tim', 'fullest', 'fulli', 'fulton', 'fun', 'function', 'fund', 'funer', 'funnel', 'funni', 'furi', 'furiou', 'furious', 'further', 'furthermor', 'fuse', 'fusion', 'futil', 'futur', 'futurist', 'g', 'g-merl', 'g.', 'g.u.n', 'ga', 'gaara', 'gabriel', 'gadget', 'gaea', 'gag', 'gahck', 'gaia', 'gain', 'galact', 'galactipool', 'galactu', 'galaxi', 'galeem', 'galleri', 'gallow', 'galvez', 'gambit', 'gambl', 'game', 'gamemna', 'gamesmast', 'gamma', 'gamma-pow', 'gamma-ray', 'gamma-spawn', 'gamora', 'gandalf', 'gang', 'gangbust', 'gangster', 'ganthet', 'ganymed', 'gap', 'gar', 'garag', 'garb', 'garbag', 'garden', 'gardner', 'garfield', 'gargan', 'gargoyl', 'gari', 'garma', 'garmadon', 'garmatron', 'garner', 'garokk', 'garrett', 'garrick', 'garrington', 'garth', 'gase', 'gate', 'gateway', 'gath', 'gather', 'gauntlet', 'gave', 'gay', 'gayl', 'gcpd', 'gear', 'gehenna', 'geist', 'gem', 'gemini', 'gemma', 'gemston', 'gender', 'gene', 'gener', 'genesi', 'genet', 'geneticist', 'geni', 'genis-vel', 'geniu', 'genocid', 'genom', 'genosha', 'genoshan', 'gentek', 'gentl', 'gentleman', 'genuin', 'geo-forc', 'geoffrey', 'georg', 'georgia', 'geotronik', 'gerald', 'gerber', 'german', 'germani', 'gestur', 'get', 'getaway', 'ghetto', 'ghost', 'ghostli', 'ghul', 'giant', 'giant-man', 'gideon', 'gift', 'gig', 'gigant', 'giganta', 'gilbert', 'gill', 'gim', 'ginni', 'girder', 'girdl', 'girl', 'girlfriend', 'giurescu', 'give', 'given', 'gizoid', 'glacier', 'glad', 'gladiat', 'gladiatori', 'gladli', 'gland', 'glass', 'glenn', 'glider', 'glimps', 'gloat', 'glob', 'global', 'globe', 'glori', 'glove', 'glow', 'glum', 'glyph', 'go', 'goad', 'goal', 'goblet', 'goblin', 'god', 'god-lik', 'goddess', 'godhood', 'godli', 'godlik', 'godsey', 'godship', 'godson', 'godwav', 'godzilla', 'goe', 'gog', 'gohan', 'goku', 'gold', 'golden', 'golgotha', 'goliath', 'gomi', 'gone', 'good', 'good-by', 'goodby', 'goodman', 'goon', 'gordon', 'gorgon', 'gorilla', 'got', 'gotham', 'gotten', 'govern', 'government-sponsor', 'grab', 'grace', 'grad', 'grade', 'gradual', 'graduat', 'graft', 'grain', 'grand', 'granddaught', 'grandfath', 'grandmast', 'grandmoth', 'grandpar', 'grandson', 'granger', 'granni', 'grant', 'graphic', 'grappl', 'grappler', 'grasp', 'grate', 'gratitud', 'grave', 'graverobb', 'graveyard', 'gravit', 'graviti', 'graviton', 'gravitonium', 'gray', 'graydon', 'graymalkin', 'grayson', 'great', 'great-grandfath', 'greater', 'greatest', 'greatli', 'greec', 'greedi', 'greek', 'green', 'green-skin', 'greenwich', 'greer', 'greet', 'gregor', 'grenad', 'grew', 'grey', 'grid', 'grief', 'grief-stricken', 'griev', 'griffin', 'griffith', 'grigori', 'grim', 'grimm', 'grin', 'grip', 'grodd', 'groot', 'grotesk', 'grotesqu', 'ground', 'group', 'grove', 'grover', 'grow', 'grown', 'grown-up', 'growth', 'groznyj', 'gru', 'grudg', 'grudgingli', 'gruesom', 'grundi', 'gryaznova', 'guard', 'guardian', 'guardsman', 'guardsmen', 'guerard', 'guerrilla', 'guess', 'guest', 'guid', 'guidanc', 'guido', 'guild', 'guilt', 'guilti', 'guinea', 'guis', 'gulf', 'gun', 'gunfir', 'gunman', 'gunn', 'gunpoint', 'gunrunn', 'gunshot', 'gurlukovich', 'gut', 'guthri', 'guy', 'gw', 'gwen', 'gym', 'gymnast', 'gypsi', 'gyrich', 'h', \"h'ylthri\", 'h.', 'h.a.m.m.e.r', 'h.i.v.', 'habit', 'hack', 'hacker', 'hade', 'hagen', 'hail', 'hair', 'haiti', 'haitian', 'hal', 'hala', 'hale', 'half', 'half-broth', 'half-human', 'half-sist', 'halfworld', 'hali', 'hall', 'haller', 'halli', 'halloween', 'hallucin', 'hallucinogen', 'hallway', 'halo', 'halt', 'halv', 'hamilton', 'hamir', 'hammer', 'hammerhead', 'hammond', 'han', 'hancock', 'hand', 'hand-to-hand', 'handcuf', 'handgun', 'handl', 'handler', 'handsom', 'hang', 'hank', 'happen', 'happi', 'happili', 'har', 'harass', 'harbing', 'harbor', 'hard', 'harden', 'harder', 'hardi', 'hardli', 'hardship', 'hardwar', 'hargrov', 'hark', 'harleen', 'harlem', 'harlequin', 'harley', 'harm', 'harmless', 'harmoni', 'harold', 'harper', 'harpi', 'harpoon', 'harpuia', 'harrald', 'harri', 'harriet', 'harrison', 'harsh', 'harshli', 'hart', 'hartley', 'harvard', 'harvest', 'harvey', 'hashirama', 'hast', 'hasti', 'hat', 'hatch', 'hate', 'hatr', 'haul', 'haunt', 'havoc', 'havok', 'hawaii', 'hawk', 'hawkey', 'hawkgirl', 'hawkin', 'hawkman', 'hayashi', 'hayden', 'haywir', 'he', 'head', 'headach', 'headband', 'headhunt', 'headlok', 'headmast', 'headmen', 'headmistress', 'headpool', 'headquart', 'heal', 'healer', 'health', 'healthi', 'hear', 'heard', 'heart', 'heartbroken', 'heat', 'heather', 'heaven', 'heavenli', 'heavi', 'heavili', 'hecat', \"hecat'\", 'hecatomb', 'hector', 'hed', 'hedgehog', 'heed', 'heel', 'height', 'heighten', 'heimdal', 'heinrich', 'heir', 'heiress', 'heist', 'hela', 'helcarax', 'held', 'helen', 'helena', 'helicarri', 'helicopt', 'hell', 'hell-lord', 'hellboy', 'hellcarri', 'hellcat', 'hellfir', 'hellion', 'hellish', 'hellspawn', 'hellstorm', 'hellstrom', 'helm', 'helmet', 'helmut', 'help', 'helpless', 'helplessli', 'hels', 'hem', 'henc', 'henchman', 'henchmen', 'hendri', 'henri', 'henshaw', 'hephaestu', 'hepzibah', 'heracl', 'herald', 'herb', 'hercul', 'herd', 'heritag', 'herm', 'herman', 'hermion', 'hermit', 'hero', 'heroic', 'heroin', 'heroism', 'hesit', 'hex', 'heywood', 'hezlet', 'hi-tech', 'hiatu', 'hibern', 'hid', 'hidalgo', 'hidden', 'hide', 'hideo', 'hideou', 'hideout', 'hierarchi', 'high', 'high-level', 'high-rank', 'high-tech', 'higher', 'highest', 'highfath', 'highli', 'highway', 'hijack', 'hill', 'himalaya', 'himon', 'hinata', 'hind', 'hinder', 'hindsight', 'hint', 'hip', 'hippolyta', 'hire', 'hiro', 'hiro-kala', 'hiroshima', 'hisako', 'histor', 'histori', 'hit', 'hit-girl', 'hit-monkey', 'hitch', 'hitchhik', 'hitler', 'hitman', 'hitmen', 'hive', 'ho', 'hoax', 'hobbi', 'hobgoblin', 'hodg', 'hogan', 'hogun', 'hogwart', 'hokag', 'hokuto', 'holcroft', 'hold', 'holden', 'hole', 'holi', 'holiday', 'holland', 'holli', 'hollow', 'hollywood', 'holm', 'holocaust', 'hologram', 'holograph', 'holt', 'home', 'homeland', 'homeless', 'homestead', 'hometown', 'homeworld', 'homicid', 'homo', 'homosexu', 'homunculu', 'hone', 'honeymoon', 'hong', 'honor', 'hood', 'hook', 'hope', 'hopeless', 'horcrux', 'hord', 'hormon', 'horn', 'hornet', 'horribl', 'horrif', 'horrifi', 'horror', 'hors', 'horseman', 'horsemen', 'horu', 'hospic', 'hospit', 'host', 'hostag', 'hostil', 'hot', 'hotel', 'hound', 'hour', 'hourman', 'hous', 'household', 'houston', 'howard', 'howev', 'howl', 'howlett', 'hq', 'hub', 'hudson', 'huey', 'hug', 'huge', 'hugh', 'hugo', 'hulk', 'hulk-lik', 'hulked-out', 'human', 'humanist', 'humanitarian', 'humankind', 'humanoid', 'humbl', 'humili', 'humor', 'hundr', 'hung', 'hungari', 'hunger', 'hunt', 'hunter', 'huntress', 'hurl', 'hurri', 'hurrican', 'hurt', 'hurtl', 'husband', 'hush', 'husk', 'hybrid', 'hyde', 'hydra', 'hydraul', 'hydro-man', 'hydrogen', 'hyperion', 'hyperspac', 'hypnobrai', 'hypnosi', 'hypnot', 'hyuga', 'ian', 'ibli', 'ice', 'iceman', 'ici', 'icon', 'id', 'idea', 'ideal', 'idealist', 'ident', 'identif', 'identifi', 'idol', 'idylist', 'ifrit', 'ignit', 'ignor', 'ii', 'iii', 'ill', 'ill-temp', 'ill.', 'illeg', 'illegitim', 'illinoi', 'illuminati', 'illus', 'illusori', 'illustr', 'illyana', 'ilsa', 'iluthin', 'imag', 'imagin', 'imbu', 'imei', 'imf', 'imit', 'immedi', 'immens', 'immers', 'immigr', 'immin', 'immobil', 'immort', 'immortu', 'immun', 'imogen', 'imp', 'impact', 'impal', 'impass', 'impati', 'impend', 'impenetr', 'imper', 'imperfect', 'imperi', 'imperiex', 'imperson', 'impervi', 'implac', 'implant', 'implement', 'impli', 'implic', 'implor', 'import', 'impos', 'imposs', 'impost', 'impostor', 'impregn', 'impress', 'imprint', 'imprison', 'improv', 'improvis', 'impuls', 'impur', 'imra', 'in-gam', 'inabl', 'inact', 'inadvert', 'inanim', 'inc.', 'incap', 'incapacit', 'incarcer', 'incarn', 'inch', 'incid', 'inciner', 'inclin', 'includ', 'incom', 'incompet', 'incorpor', 'increas', 'increasingli', 'incred', 'incrimin', 'incubu', 'incurs', 'inde', 'indebt', 'indel', 'indelicato', 'independ', 'indestruct', 'index', 'indi', 'india', 'indian', 'indiana', 'indic', 'indiffer', 'indigo', 'indigo-1', 'indirectli', 'indiscrimin', 'individu', 'indoctrin', 'induc', 'induct', 'indulg', 'industri', 'industrialist', 'ineffect', 'inert', 'inertia', 'inevit', 'inexor', 'inexperienc', 'inexplic', 'infam', 'infanc', 'infant', 'infantino', 'infantri', 'infatu', 'infect', 'infectia', 'inferior', 'infern', 'inferno', 'infest', 'infiltr', 'infin', 'infinit', 'infirmari', 'inflict', 'influenc', 'info', 'inform', 'information-silk', 'infuri', 'infus', 'ingest', 'inhabit', 'inher', 'inherit', 'inheritor', 'inhibit', 'inhuman', 'initi', 'inject', 'injur', 'injuri', 'injustic', 'ink', 'inmat', 'innat', 'inner', 'innoc', 'innov', 'input', 'inquir', 'inquisitor', 'insan', 'insect', 'insectoid', 'insecur', 'insert', 'insid', 'insight', 'insignia', 'insist', 'inspect', 'inspector', 'inspir', 'instabl', 'instal', 'instanc', 'instant', 'instantli', 'instead', 'instig', 'instil', 'instinct', 'institut', 'institution', 'instruct', 'instructor', 'instrument', 'insuffici', 'insult', 'insur', 'insurg', 'intact', 'intang', 'integr', 'intel', 'intellect', 'intellig', 'intelligencia', 'intend', 'intens', 'intensifi', 'intent', 'inter-dimension', 'interact', 'interbreed', 'intercept', 'interdimension', 'interest', 'interf', 'interfac', 'interfer', 'intergalact', 'intergang', 'interim', 'interlop', 'intern', 'internet', 'interpol', 'interpret', 'interrog', 'interrupt', 'interven', 'intervent', 'interview', 'intim', 'intimid', 'intoler', 'intox', 'intrigu', 'introduc', 'introduct', 'introvert', 'intrud', 'intuit', 'invad', 'invalu', 'invas', 'invent', 'inventor', 'invert', 'invest', 'investig', 'invinc', 'invis', 'invit', 'invok', 'involv', 'invulner', 'ion', 'iq', 'iraq', 'iraqi', 'ireland', 'iren', 'iri', 'irish', 'iron', 'ironi', 'irradi', 'irrat', 'irrit', 'irv', 'irwin', 'isaac', 'ishmael', 'isi', 'isl', 'island', 'isol', 'isotop', 'israel', 'issu', 'itachi', 'itali', 'italian', 'item', 'itsu', 'iv', 'ivan', 'ivanova', 'ive', 'ivi', 'ivo', 'ix', 'izaya', \"j'onn\", \"j'onzz\", \"j'son\", 'j.', 'jabba', 'jace', 'jacen', 'jack', 'jack-jack', 'jackal', 'jacket', 'jacki', 'jackson', 'jacob', 'jacobi', 'jacquelin', 'jade', 'jaeger', 'jagi', 'jahad', 'jai', 'jail', 'jailbreak', 'jaim', 'jain', 'jake', 'jakeem', 'jakku', 'jakob', 'jallakuntilliokan', 'jam', 'jamaan', 'jamaica', 'jamanakai', 'jambo', 'jame', 'jameson', 'jami', 'jane', 'janeiro', 'janet', 'janey', 'janic', 'janin', 'janitor', 'janu', 'januari', 'japan', 'japanes', 'jar', 'jarella', 'jarvi', 'jason', 'jasper', 'java', 'javelin', 'jaw', 'jawa', 'jax', 'jay', 'jazz', 'jc', 'jd', 'jealou', 'jealousi', 'jean', 'jean-luc', 'jean-paul', 'jeanne-mari', 'jeb', 'jedi', 'jeep', 'jefferson', 'jeffrey', 'jeffri', 'jellyfish', 'jemma', 'jenkin', 'jenni', 'jennif', 'jensen', 'jeremiah', 'jericho', 'jerom', 'jerri', 'jersey', 'jess', 'jessica', 'jessn', 'jestro', 'jesu', 'jet', 'jettison', 'jew', 'jewel', 'jewelri', 'jewish', 'jiay', 'jigsaw', 'jihad', 'jill', 'jim', 'jimmi', 'jinchuriki', 'jinmen', 'jinn', 'jip', 'jiraiya', 'jiren', 'jitter', 'jiw', 'jj', 'jla', 'jli', 'joan', 'joann', 'joanna', 'job', 'jocasta', 'jock', 'joe', 'joey', 'jog', 'johann', 'john', 'johnni', 'johnsmey', 'johnson', 'join', 'joint', 'joke', 'joker', 'jokingli', 'jolt', 'jon', 'jona', 'jonah', 'jonathan', 'jone', 'jonin', 'jono', 'jonson', 'jor-el', 'jordan', 'jorgenson', 'joseph', 'josh', 'joshua', 'josiah', 'jotunheim', 'journal', 'journalist', 'journey', 'joy', 'joystick', 'jr.', 'jsa', 'jubile', 'judd', 'judg', 'judgement', 'judgment', 'judi', 'judson', 'juggernaut', 'juli', 'julia', 'juliana', 'julien', 'juliu', 'jump', 'jumper', 'jumpstart', 'jun', 'june', 'jungl', 'junior', 'junk', 'junkpil', 'junkyard', 'jupit', 'juri', 'juspeczyk', 'just', 'justic', 'justifi', 'justin', 'juvenil', 'k', \"k'ad-mon\", \"k'un-lun\", 'k-2so', 'k.', 'ka-zar', 'kabuto', 'kadabra', 'kaeciliu', 'kahn', 'kahndaq', 'kahser', 'kai', 'kaim', 'kain', 'kaishek', 'kakarot', 'kakashi', 'kako', 'kal-el', 'kal-l', 'kale', 'kali', 'kalista', 'kallark', 'kallig', 'kaluu', 'kamehameha', 'kamekeri', 'kan', 'kandor', 'kandorian', 'kane', 'kang', 'kansa', 'kanto', 'kapat', 'kapau', 'kara', 'karat', 'karen', 'karia', 'karima', 'karin', 'karl', 'karla', 'karma', 'karn', 'karnak', 'karnilla', 'karshon', 'kat', 'katana', 'katarthan', 'kataru', 'kate', 'katherin', 'kati', 'kato', 'kayoco', 'kazuhira', 'keen', 'keep', 'keeper', 'keewazi', 'kefla', 'kelex', 'keller', 'kelli', 'ken', 'kendra', 'kenji', 'kennedi', 'kenneth', 'kenobi', 'kenshiro', 'kent', 'kenya', 'kept', 'ketch', 'kettol', 'kevin', 'key', 'keyston', 'kgb', 'kgbeast', 'khadir', 'khan', 'khandaq', 'khonshu', 'khufu', 'khund', 'ki', 'kick', 'kick-ass', 'kid', 'kidnap', 'kidnapp', 'kilgrav', 'kiligrav', 'kill', 'killebrew', 'killer', 'killgrav', 'killian', 'killmong', 'kilowog', 'kim', 'kimora', 'kin', 'kincaid', 'kind', 'kinder', 'kindli', 'kindr', 'kinet', 'king', 'kingdom', 'kingpin', 'kingsguard', 'kinney', 'kinsmen', 'kinsolv', 'kirbi', 'kirk', 'kiss', 'kit', 'kitana', 'kitchen', 'kitti', 'kittridg', 'klarion', 'klaue', 'klaw', 'knee', 'knew', 'knife', 'knight', 'knighton', 'knive', 'knock', 'knockout', 'knot', 'know', 'knowher', 'knowledg', 'known', 'knox', 'knuckl', 'kobra', 'koko', \"komand'r\", 'kombat', 'kon-el', 'kong', 'konoha', 'konohagakur', 'kool-aid', 'koopal', 'kopetski', 'korbal', 'korbinit', 'kord', 'kordax', 'korea', 'korean', 'kori', \"koriand'r\", 'korrek', 'korugar', 'korvu', 'koryak', 'kosmo', 'kosmosian', 'kotal', 'koth', 'kovac', 'kozo', 'kozu', 'krahn', 'krakoa', 'krang', 'krato', 'krau', 'krauser', 'kraven', 'kravinoff', 'kray', 'kree', 'kree-skrul', 'krieger', 'kril', 'krol', 'krona', 'kronika', 'krono', 'krosaki', 'kruncha', 'kruun', 'krux', 'krypto', 'krypton', 'kryptonian', 'kryptonit', 'krystalin', 'kuasa', 'kubik', 'kung', 'kunoichi', 'kurio', 'kurt', 'kurtzberg', 'kuurth', 'kwannon', 'kwesi', 'kworri', 'kyle', 'kyllian', 'kyln', 'l', 'l.a.', 'la', 'lab', 'label', 'labor', 'laboratori', 'labyrinth', 'lace', 'lack', 'lackey', 'lad', 'ladi', 'laforg', 'lago', 'lagoon', 'laid', 'lair', 'laira', 'lake', 'lama', 'lame', 'lament', 'lamp', 'lan', 'lana', 'lanc', 'land', 'landau', 'lander', 'landlord', 'landmark', 'lando', 'lane', 'lang', 'langdon', 'langkowski', 'langowski', 'langstrom', 'languag', 'languish', 'lannist', 'lantern', 'lao', 'lapd', 'laps', 'lar', 'lara', 'larfleez', 'larg', 'larger', 'largest', 'larri', 'larsen', 'laser', 'lash', 'lashina', 'lass', 'lasso', 'last', 'latch', 'late', 'latent', 'later', 'latest', 'latex', 'latter', 'latveria', 'latverian', 'laufey', 'laugh', 'launch', 'launcher', 'laura', 'laurel', 'laurenc', 'lauri', 'lava', 'laveau', 'lavecchia', 'law', 'lawn', 'lawson', 'lawton', 'lawyer', 'lay', 'layla', 'laynia', 'lazaer', 'lazar', 'lazaru', 'lb', 'le', 'lead', 'leader', 'leadership', 'leaf', 'leagu', 'leaguer', 'leak', 'lean', 'leap', 'leapt', 'learn', 'least', 'leather', 'leav', 'lebeau', 'lectur', 'led', 'ledg', 'lee', 'leech', 'left', 'leg', 'legaci', 'legal', 'legend', 'legendari', 'legion', 'legionnair', 'legitim', 'lego', 'lehnsherr', 'lei', 'leia', 'leir', 'lemuria', 'len', 'lena', 'lend', 'length', 'lengthen', 'lengthi', 'lenni', 'lenor', 'lens', 'lent', 'leo', 'leon', 'leonard', 'leper', 'leron', 'lesbian', 'lesli', 'less', 'lesser', 'lesson', 'lest', 'let', 'lethal', 'letter', 'level', 'leverag', 'leviathan', 'lewi', 'lex', 'lexcorp', 'liaison', 'lian', 'liber', 'liberti', 'libra', 'librari', 'licens', 'lie', 'lieuten', 'life', 'life-forc', 'life-form', 'life-model', 'lifeform', 'lifeless', 'lifelong', 'lifespan', 'lifestyl', 'lifetim', 'lift', 'light', 'lighthous', 'lightn', 'lightsab', 'lightweight', 'like', 'likewis', 'lil', 'lila', 'lilandra', 'lili', 'lilin', 'lilith', 'lillian', 'limb', 'limbo', 'limit', 'limitless', 'limousin', 'lin', 'lincoln', 'linda', 'linderman', 'lindi', 'lindsay', 'line', 'lineag', 'linger', 'link', 'lion', 'lionel', 'lip', 'liquid', 'liquor', 'lisa', 'list', 'listen', 'liter', 'literatur', 'lithium', 'litterbug', 'littl', 'littlefing', 'liu', 'liuchow', 'live', 'live-act', 'liverpool', 'livewir', 'liz', 'lizard', 'llan', 'lloyd', 'llyra', 'lmd', 'lo', 'loa', 'load', 'loan', 'lobbi', 'lobe', 'lobo', 'lobotom', 'lobster', 'local', 'locat', 'lock', 'locker', 'locket', 'lockhe', 'lockjaw', 'lockley', 'locomot', 'lodeston', 'lodg', 'loeb', 'loft', 'log', 'logan', 'logic', 'logist', 'logo', 'loi', 'loki', 'loma', 'london', 'lone', 'loneli', 'loner', 'long', 'long-dead', 'long-lost', 'long-term', 'long-thought', 'long-tim', 'longer', 'longev', 'longo', 'longshot', 'longstand', 'longtim', 'lonni', 'look', 'loomworld', 'looni', 'loop', 'loos', 'loose-knit', 'loot', 'lor-zod', 'lord', 'lore', 'lorelei', 'lorena', 'lori', 'lorna', 'lose', 'loser', 'loss', 'lost', 'lot', 'lotho', 'lotteri', 'lotu', 'loud', 'loudli', 'loui', 'louis', 'louisiana', 'love', 'lover', 'low', 'low-down', 'low-level', 'lower', 'lowli', 'loyal', 'loyalist', 'loyalti', 'loyd', 'lt.', 'luca', 'luci', 'lucia', 'lucid', 'lucif', 'luciu', 'luck', 'lucki', 'luckili', 'luckman', 'lucr', 'luggag', 'lugman', 'luigi', 'luke', 'lukin', 'luma', 'lumina', 'luna', 'lunar', 'lunatica', 'lunatik', 'lunch', 'lung', 'lupe', 'lupin', 'lure', 'lurk', 'lurker', 'lust', 'luther', 'luthor', 'luxuri', 'lyja', 'lyko', 'lylla', 'lynx', 'lyon', 'lyra', 'lysa', 'lysandra', \"m'baku\", \"m'gann\", \"m'kraan\", \"m'krann\", \"m'nagalah\", \"m'rinn\", 'm-day', 'm.', 'm.l.f.', 'm.o.d.o.k', 'mac', 'mace', 'macendal', 'machin', 'machineri', 'machu', 'mackenzi', 'mactaggart', 'mactaggert', 'mad', 'madam', 'madara', 'madden', 'maddi', 'maddick', 'made', 'madelin', 'madelyn', 'madison', 'madman', 'madmen', 'madnar', 'madonna', 'madripoor', 'madrox', 'maelstrom', 'maestro', 'maev', 'mafia', 'magazin', 'magda', 'mage', 'mageddon', 'maggi', 'maggia', 'magic', 'magician', 'magick', 'magik', 'magistr', 'magma', 'magnet', 'magneto', 'magnifi', 'magnu', 'magnum', 'magu', 'maid', 'maiden', 'mail', 'maim', 'main', 'mainfram', 'mainland', 'mainli', 'mainlin', 'mainstay', 'mainstream', 'maintain', 'majesti', 'majestor', 'majin', 'major', 'make', 'maker', 'makeshift', 'makeup', 'maki', 'makimura', 'makkari', 'makluan', 'maksai', 'malankov', 'malcolm', 'male', 'malebolgia', 'malekith', 'malevol', 'malfunct', 'malic', 'malici', 'malign', 'mall', 'mallori', 'mallu', 'malu', 'mama', 'mamba', 'mammal', 'mammon', 'man', 'man-bat', 'man-beast', 'man-th', 'man-wolf', 'manag', 'manchest', 'mandalor', 'mandalorian', 'mandarin', 'mandat', 'mandi', 'mando', 'maneuv', 'manfredi', 'manga', 'mangl', 'mangog', 'manhattan', 'manhunt', 'mani', 'maniac', 'manifest', 'manipul', 'mankind', 'mannequin', 'manner', 'manor', 'manserv', 'mansion', 'manslaught', 'manstalk', 'manta', 'manti', 'mantl', 'manual', 'manuel', 'manufactur', 'map', 'mar', 'mar-vel', 'mara', 'maraud', 'march', 'marci', 'marco', 'marcu', 'mardon', 'marduk', 'marg', 'margali', 'margaret', 'mari', 'maria', 'mariah', 'mariko', 'marin', 'mario', 'marion', 'marit', 'mariu', 'marj', 'mark', 'market', 'marko', 'marksman', 'marku', 'marlen', 'marliz', 'marlo', 'maroni', 'maroon', 'marov', 'marr', 'marri', 'marriag', 'marrina', 'marrow', 'marshal', 'marston', 'martha', 'martial', 'martian', 'martin', 'martynec', 'martyr', 'marv', 'marvel', 'marvin', 'masa', 'masamun', 'mascot', 'maseo', 'mask', 'mason', 'masqu', 'masquerad', 'mass', 'massachusett', 'massacr', 'massiv', 'master', 'masteri', 'mastermind', 'masterson', 'mastodon', 'matango', 'match', 'mate', 'materi', 'matern', 'mathia', 'matrix', 'matt', 'matter', 'matthew', 'matti', 'matur', 'maul', 'maverick', 'maw', 'max', 'maxam', 'maxi', 'maxim', 'maxima', 'maximoff', 'maximu', 'maximum', 'maxin', 'maxwel', 'may', 'maya', 'mayb', 'mayer', 'mayfield', 'mayfli', 'mayhem', 'maykr', 'mayor', 'maze', 'mcbride', 'mccabe', 'mccoy', 'mcculloch', 'mckenzi', 'mcnider', 'meachum', 'meal', 'mean', 'meanstreak', 'meant', 'meantim', 'meanwhil', 'measur', 'meat', 'mech', 'mecha', 'mechan', 'mechaniloid', 'medal', 'medallion', 'meddl', 'media', 'medic', 'medicin', 'mediev', 'medit', 'medium', 'medusa', 'meek', 'meet', 'mega', 'megalomaniac', 'megan', 'meggan', 'mekt', 'melani', 'meld', 'mele', 'melinda', 'melisandr', 'melissa', 'melita', 'melkor', 'melt', 'meltdown', 'meltmassif', 'member', 'membership', 'memori', 'men', 'menac', 'menalipp', 'mend', 'menial', 'mental', 'mentallo', 'mention', 'mento', 'mentor', 'meowthra', 'mephil', 'mephisto', 'mera', 'merc', 'merced', 'mercenari', 'mercer', 'merchandis', 'merci', 'merciless', 'mercuri', 'mere', 'meredith', 'merg', 'merger', 'merit', 'merlin', 'merlina', 'merlok', 'merlyn', 'meryl', 'mesmer', 'mesmero', 'mess', 'messag', 'messeng', 'messiah', 'met', 'meta', 'meta-human', 'metabol', 'metagen', 'metahuman', 'metal', 'metalhead', 'metallo', 'metamorph', 'metamorpho', 'metaphys', 'meteor', 'meteorit', 'meteortech', 'meter', 'method', 'metro', 'metron', 'metropoli', 'metrovil', 'mettl', 'mexican', 'mexico', 'meyer', 'mi-6', 'mi13', 'mi6', 'mia', 'miami', 'micah', 'michael', 'michel', 'mick', 'micro', 'micron', 'microscop', 'microvers', 'microwav', 'mid', 'mid-air', 'mid-nit', 'middl', 'middle-ag', 'middle-earth', 'midgard', 'midnight', 'midst', 'midtown', 'midway', 'midwest', 'midwestern', 'midwif', 'might', 'mighti', 'mightiest', 'migrat', 'miguel', 'mikaal', 'mikalek', 'mike', 'mikel', 'mikhail', 'miki', 'milaj', 'mildli', 'mile', 'mileena', 'militari', 'militia', 'mill', 'millennia', 'millennia-old', 'millennium', 'miller', 'million', 'millionair', 'milo', 'milton', 'mimet', 'mimi', 'mimic', 'mimick', 'mina', 'mind', 'mind-control', 'mind-wip', 'mindless', 'mindset', 'mindwip', 'mine', 'miner', 'minerva', 'mini', 'mini-seri', 'miniatur', 'minim', 'minimum', 'minion', 'miniseri', 'minist', 'ministri', 'minor', 'minut', 'minutemen', 'miracl', 'miraclo', 'miracul', 'mirag', 'miranda', 'miriam', 'mirror', 'misako', 'miscalcul', 'miscarriag', 'mischief', 'misde', 'miser', 'miseri', 'misfit', 'misfortun', 'misguid', 'misread', 'miss', 'missil', 'mission', 'mississippi', 'missouri', 'mist', 'mistak', 'mistaken', 'mistakenli', 'mister', 'misti', 'mistook', 'mistreat', 'mistress', 'mistrust', 'misunderstand', 'misus', 'mix', 'mixtur', 'mj', 'mjolnir', 'mk', 'mk.ii', 'mo', 'mob', 'mobil', 'mobiu', 'mobster', 'mock', 'mockingbird', 'mode', 'model', 'modern', 'modern-day', 'modif', 'modifi', 'modok', 'modr', 'modu', 'modul', 'mogo', 'mogol', 'mohind', 'moira', 'moistur', 'mojav', 'mojo', 'mojovers', 'mojoworld', 'mokk', 'mold', 'mole', 'molecul', 'molecular', 'molecularli', 'molest', 'molten', 'mom', 'moment', 'momentari', 'momentarili', 'momentum', 'mon-el', 'monarch', 'monasteri', 'monet', 'monetari', 'money', 'monger', 'mongrel', 'mongul', 'monica', 'monik', 'monitor', 'monk', 'monkey', 'monna', 'monolith', 'monopol', 'monro', 'monster', 'monstros', 'monstrou', 'monstrox', 'montana', 'montesi', 'montgomeri', 'month', 'montoya', 'montreal', 'monument', 'mood', 'moon', 'moon-boy', 'moondragon', 'moonshad', 'moonstar', 'moonston', 'moor', 'mop', 'mope', 'moral', 'moran', 'morbiu', 'mordo', 'moreau', 'moreov', 'morg', 'morgain', 'morgan', 'morgoth', 'morgu', 'moriarti', 'morley', 'morlock', 'morlun', 'morn', 'morningstar', 'morph', 'morpheu', 'morphogenet', 'morri', 'morrison', 'morro', 'morrow', 'mors', 'mort', 'mortal', 'mose', 'mostli', 'motel', 'moth', 'mother', 'mothership', 'motif', 'motion', 'motiv', 'motor', 'motorcycl', 'motorhead', 'mount', 'mountain', 'mourn', 'mous', 'mouth', 'move', 'movement', 'mover', 'movi', 'mr', 'mr.', 'mrs.', 'ms.', 'msf', 'mt', 'much', 'mud', 'mug', 'mugger', 'muir', 'muller', 'multi-billion', 'multipl', 'multipli', 'multitud', 'multivers', 'mumbai', 'munich', 'munit', 'munni', 'munro', 'murad', 'muramasa', 'murder', 'murderworld', 'murdock', 'murphi', 'muscl', 'muscular', 'muse', 'museum', 'mushroom', 'music', 'must', 'mutagen', 'mutant', 'mutant-hunt', 'mutant-kil', 'mutant-kind', 'mutantkind', 'mutat', 'mute', 'mutil', 'muto', 'mutual', 'mvp', 'mxi', 'mxyzptlk', 'mxyztplk', 'myndi', 'myra', 'mysteri', 'mysterio', 'mystic', 'mystiqu', 'myth', 'mythic', 'mytholog', 'n', \"n'astirh\", \"n'garai\", \"n'jadaka\", \"n'jobu\", \"n't\", 'na', 'naboo', 'nabu', 'nadakhan', 'nadira', 'nagato', 'nail', 'naiv', 'nake', 'name', 'namek', 'nameless', 'namor', 'namora', 'namorita', 'nanda', 'nanit', 'nanni', 'nanomachin', 'nanto', 'naomi', 'nap', 'narcot', 'narrowli', 'naruto', 'narya', 'nasa', 'nascent', 'natasha', 'nate', 'nathan', 'nathaniel', 'nation', 'nativ', 'nato', 'natsumi', 'natu', 'natur', 'naught', 'naval', 'navi', 'navig', 'naze', 'nazi', 'near', 'near-death', 'near-fat', 'nearbi', 'nearest', 'nearli', 'nebraska', 'nebula', 'nebulon', 'necess', 'necessari', 'neck', 'necklac', 'necrom', 'necromanc', 'necroplasm', 'necropoli', 'necrosha', 'ned', 'need', 'needl', 'nefari', 'nefaria', 'neg', 'nega', 'nega-band', 'negason', 'negat', 'neglect', 'negoti', 'neig', 'neighbor', 'neighborhood', 'neither', 'nekra', 'nekron', 'nelson', 'nemes', 'nemesi', 'neo', 'neon', 'neophyt', 'nephew', 'neramani', 'nergal', 'neron', 'nerv', 'nervou', 'nest', 'net', 'nether', 'netherworld', 'network', 'neural', 'neutral', 'neutron', 'nevada', 'never', 'neverland', 'nevertheless', 'new', 'new-found', 'newborn', 'newcastl', 'newer', 'newest', 'newfound', 'newli', 'newly-form', 'newlyw', 'news', 'newsboy', 'newspap', 'newsstand', 'next', 'nextwav', 'nexu', 'nicaragua', 'nice', 'nichola', 'nick', 'nicknam', 'nicol', 'nicolosi', 'niec', 'niganda', 'nigel', 'nigh', 'night', 'night-slay', 'nightclub', 'nightcrawl', 'nighthawk', 'nightmar', 'nightshad', 'nightw', 'nihilist', 'nihilu', 'nijo', 'nike', 'niki', 'nimrod', 'nimu', 'nindroid', 'nine', 'nine-tail', 'nineteen', 'ninja', 'ninjago', 'nite', 'nite-owl', 'nitro', 'nitrogen', 'nixon', 'no-on', 'noah', 'nobel', 'nobl', 'nobleman', 'nobodi', 'noc', 'nocturn', 'nocturna', 'nocturnu', 'noir', 'nois', 'noldor', 'nomad', 'nomanisan', 'nomin', 'non', 'non-interfer', 'non-leth', 'non-mut', 'non-team', 'none', 'nonetheless', 'nonexist', 'nora', 'nord', 'norm', 'normal', 'norman', 'normi', 'norn', 'nornheim', 'norri', 'norrisss', 'nors', 'north', 'northern', 'northstar', 'norton', 'nostromo', 'notabl', 'note', 'noth', 'nothing', 'notic', 'notifi', 'notion', 'notori', 'notorieti', 'nova', 'novel', 'novelist', 'novemb', 'novic', 'nowher', 'nsa', 'nth', 'nuada', 'nuclear', 'nuisanc', 'nuke', 'null', 'nullifi', 'number', 'numer', 'nuptial', 'nur', 'nurs', 'nuso', 'nut', 'nya', 'nyc', 'nypd', 'nyssa', \"o'donnel\", \"o'reilli\", 'o.e.', 'o.z', 'oa', 'oan', 'oann', 'oath', 'obadiah', 'obeah', 'obedi', 'oberhaus', 'oberon', 'obes', 'obey', 'obi-wan', 'obito', 'object', 'oblig', 'obliter', 'oblivi', 'oblivion', 'obrien', 'obscur', 'observ', 'observatori', 'obsess', 'obsidian', 'obsolet', 'obstacl', 'obtain', 'obviou', 'obvious', 'occas', 'occasion', 'occult', 'occultist', 'occup', 'occupi', 'occur', 'ocean', 'ocelot', 'ocsh', 'octaviu', 'octob', 'octopu', 'odd', 'oddli', 'odessa', 'odin', 'odinson', 'odym', 'odyssey', 'off-guard', 'off-planet', 'offend', 'offens', 'offer', 'offic', 'offici', 'offshoot', 'offspr', 'often', 'ogashira', 'ogdru', 'oge', 'ogr', 'ogun', 'ohio', 'oil', 'oilix', 'okay', 'oklahoma', 'olantern', 'old', 'older', 'oldest', 'olga', 'oliv', 'olivia', 'olli', 'olnar', 'olsen', 'olson', 'olymp', 'olympian', 'olympu', 'omac', 'omega', 'omen', 'omicron', 'omin', 'omnidroid', 'omnipot', 'omnisci', 'omnitrix', 'omnivers', 'onaga', 'onboard', 'oncom', 'one', 'one-above-al', 'one-man', 'one-on-on', 'one-shot', 'one-tim', 'ongo', 'oni', 'onlook', 'onset', 'onslaught', 'onto', 'onward', 'oolong', 'op', 'opal', 'open', 'openli', 'oper', 'opinion', 'oppon', 'opportun', 'oppos', 'opposit', 'oppress', 'opt', 'optic', 'optim', 'optimist', 'option', 'optitron', 'oracl', 'orang', 'orb', 'orbit', 'orbot', 'orchestr', 'ord', 'ordeal', 'order', 'orderli', 'ordinari', 'organ', 'organis', 'orient', 'origin', 'orin', 'orion', 'orko', 'orlean', 'orm', 'orochimaru', 'ororo', 'orphan', 'orphan-mak', 'orphanag', 'orrgo', 'orson', 'osborn', 'oscorp', 'osgood', 'osiri', 'oss', 'osterman', 'oswald', 'otacon', 'other', 'other-dimension', 'otherdimension', 'otherwis', 'otherworld', 'otherworldli', 'ottawa', 'otto', 'oust', 'out', 'outback', 'outbreak', 'outcast', 'outcom', 'outer', 'outfit', 'outing', 'outlaw', 'outlet', 'outlook', 'outmatch', 'outnumb', 'outpost', 'outrag', 'outright', 'outsid', 'outskirt', 'outsmart', 'outward', 'outwardli', 'outwit', 'outworld', 'overal', 'overboard', 'overcam', 'overcom', 'overdos', 'overgirl', 'overhead', 'overhear', 'overheard', 'overjoy', 'overlap', 'overli', 'overload', 'overlook', 'overlord', 'overnight', 'overpow', 'overprotect', 'overrid', 'overrun', 'oversaw', 'overse', 'oversea', 'overtak', 'overtaken', 'overthrew', 'overthrow', 'overthrown', 'overtkil', 'overwhelm', 'owe', 'owen', 'owl', 'own', 'owner', 'ownership', 'oxford', 'oxygen', 'oyama', 'ozymandia', \"p'tah\", 'p.i.x.a.l', 'pa', 'pacif', 'pacifist', 'pack', 'packag', 'paco', 'pact', 'pad', 'padawan', 'pagan', 'page', 'paibok', 'paid', 'paig', 'pain', 'paint', 'pair', 'palac', 'paladin', 'pale', 'palm', 'palmer', 'palpatin', 'pamela', 'pan', 'pan-galact', 'pandemonium', 'pandora', 'panel', 'panic', 'panick', 'pant', 'pantha', 'pantheon', 'panther', 'papa', 'paper', 'para-med', 'parachut', 'parad', 'parademon', 'paradis', 'paradox', 'parallax', 'parallel', 'paralysi', 'paralyz', 'paramed', 'paramilitari', 'paranoia', 'paranoid', 'paranorm', 'parapleg', 'parasit', 'parbat', 'pardon', 'parent', 'parentag', 'pari', 'pariah', 'park', 'parker', 'parliament', 'parnel', 'parodi', 'parol', 'parr', 'part', 'part-tim', 'partak', 'parti', 'partial', 'particip', 'particl', 'particular', 'particularli', 'partli', 'partner', 'partnership', 'paso', 'pass', 'passag', 'passeng', 'passion', 'passiv', 'passport', 'past', 'pastor', 'pat', 'patch', 'patent', 'patern', 'path', 'pathway', 'patienc', 'patient', 'patriarch', 'patrick', 'patriot', 'patrol', 'patron', 'patronag', 'patsi', 'pattern', 'patterson', 'patti', 'paul', 'paus', 'pave', 'pawn', 'paxton', 'pay', 'payment', 'paz', 'peac', 'peacekeep', 'peach', 'peak', 'pearl', 'peel', 'peer', 'pegasu', 'peggi', 'peliali', 'pen', 'pena', 'penal', 'penanc', 'penchant', 'pend', 'pendant', 'penetr', 'penguin', 'peninsula', 'penitentiari', 'penniless', 'pennsylvania', 'pennyworth', 'pentagon', 'pentagram', 'penthous', 'peopl', 'pepper', 'per', 'perceiv', 'percent', 'percept', 'perci', 'perciv', 'perez', 'perfect', 'perfectli', 'perform', 'perhap', 'peril', 'perimet', 'period', 'perish', 'perman', 'permiss', 'permit', 'perpetr', 'perpetu', 'perri', 'persecut', 'persephon', 'persist', 'person', 'persona', 'personi', 'personif', 'personnel', 'perspect', 'persuad', 'persuas', 'pervers', 'pestil', 'pet', 'pete', 'peter', 'peterson', 'petit', 'petrelli', 'petrifi', 'petti', 'pettigrew', 'petyr', 'ph.d.', 'phaedra', 'phaethon', 'phalanx', 'phantom', 'pharaoh', 'pharmaceut', 'phase', 'phelp', 'phenomenon', 'pheromon', 'phi', 'phil', 'philadelphia', 'philanthropi', 'philip', 'phillip', 'phillipu', 'philosoph', 'philosophi', 'phinea', 'phobo', 'phoenix', 'phone', 'phoni', 'photo', 'photograph', 'photon', 'phrase', 'phyla', 'phyla-vel', 'physic', 'physician', 'physicist', 'physiolog', 'physiqu', 'picard', 'piccolo', 'pick', 'pickl', 'picnic', 'pictur', 'pie', 'piec', 'piecem', 'pier', 'pierc', 'pierrot', 'pieter', 'pietro', 'pig', 'pike', 'piko', 'pile', 'pilgrim', 'pilgrimag', 'pill', 'pillag', 'pillar', 'pilot', 'pimp', 'pin', 'pineda', 'pinehearst', 'pink', 'piotr', 'pip', 'pipe', 'piper', 'pirat', 'pirina', 'pistol', 'pit', 'pitch', 'pitcher', 'piti', 'pitrel', 'pittsburgh', 'pivot', 'pixi', 'pizza', 'pla', 'place', 'placement', 'plaga', 'plagu', 'plain', 'plaincloth', 'plan', 'plane', 'planet', 'planet.fil', 'plant', 'plantman', 'plasma', 'plastic', 'plastiqu', 'plate', 'platform', 'play', 'playabl', 'playboy', 'player', 'playmat', 'plaza', 'plea', 'plead', 'pleas', 'pleasant', 'pleasur', 'pledg', 'plight', 'pliskin', 'plot', 'plott', 'ploy', 'plu', 'pluck', 'plug', 'plummet', 'plunder', 'plung', 'pluto', 'pmc', 'poacher', 'pocket', 'pocket-dimens', 'pod', 'poindext', 'point', 'point-blank', 'pointless', 'pois', 'poison', 'poke', 'pokolistan', 'poland', 'polar', 'polari', 'polaris/malic', 'pole', 'polemachu', 'polestar', 'polic', 'policeman', 'policemen', 'polici', 'polish', 'polit', 'politician', 'pollut', 'poln', 'polyalloy', 'pond', 'ponder', 'pool', 'poor', 'poorli', 'pop', 'popul', 'populac', 'popular', 'porcupin', 'porker', 'porm', 'porsch', 'port', 'portal', 'portion', 'portray', 'pose', 'poseidon', 'poseidoni', 'posit', 'positron', 'poss', 'possess', 'possessor', 'possibl', 'post', 'post-crisi', 'post-war', 'posthum', 'postpon', 'pot', 'potara', 'potent', 'potenti', 'potion', 'pott', 'potter', 'pouch', 'pound', 'pour', 'poverti', 'powder', 'powel', 'power', 'power-dampen', 'powerhous', 'powerless', 'pr', 'practic', 'practition', 'praetor', 'pragu', 'prairi', 'prais', 'prank', 'pratt', 'praxagora', 'pray', 'prayer', 'pre-crisi', 'preach', 'preacher', 'preced', 'precinct', 'preciou', 'preciouston', 'precis', 'precognit', 'predat', 'predecessor', 'predestin', 'predetermin', 'predica', 'predict', 'preemin', 'preemptiv', 'prefer', 'pregnanc', 'pregnant', 'prematur', 'premier', 'prentiss', 'preoccupi', 'prep', 'prepar', 'presenc', 'present', 'preserv', 'presid', 'presidenti', 'press', 'pressur', 'prestigi', 'presum', 'preteen', 'pretend', 'pretens', 'pretext', 'pretti', 'prevail', 'prevent', 'previou', 'previous', 'prey', 'prez', 'pri', 'price', 'pride', 'priest', 'priestess', 'primari', 'primarili', 'primatech', 'prime', 'primev', 'primit', 'primros', 'primu', 'princ', 'princess', 'princeton', 'princip', 'principl', 'print', 'prior', 'prioriti', 'prisca', 'priscilla', 'prison', 'privaci', 'privat', 'privileg', 'prix', 'prize', 'pro-mut', 'pro-registr', 'proactiv', 'probabl', 'probe', 'problem', 'problemat', 'proce', 'procedur', 'proceed', 'process', 'processor', 'proclaim', 'procur', 'prod', 'prodigi', 'produc', 'product', 'prof.', 'profess', 'profession', 'professor', 'profici', 'profil', 'profit', 'profound', 'progenitor', 'program', 'progress', 'project', 'projector', 'prolong', 'prometheu', 'promin', 'promis', 'promot', 'prompt', 'promptli', 'prone', 'pronounc', 'proof', 'propaganda', 'propel', 'proper', 'properli', 'properti', 'propheci', 'prophesi', 'prophet', 'proport', 'propos', 'proposit', 'propuls', 'prosecut', 'prosh', 'prospect', 'prosper', 'prosthes', 'prosthet', 'prostitut', 'protagonist', 'protect', 'protector', 'proteg', 'protest', 'proteu', 'protocol', 'prototyp', 'protract', 'proud', 'proudstar', 'prove', 'proven', 'provid', 'provinc', 'provok', 'prowess', 'prowl', 'proxi', 'proxim', 'proxima', 'pryde', 'pryor', 'pryor-summ', 'pseudoderm', 'pseudonym', 'psi', 'psi-borg', 'psi-shield', 'psion', 'psionic', 'psych', 'psychiatr', 'psychiatrist', 'psychic', 'psycho', 'psycho-man', 'psycho-pir', 'psycholog', 'psychologist', 'psychopath', 'psychot', 'psylock', 'pub', 'puberti', 'public', 'publicli', 'publish', 'puck', 'pull', 'pulp', 'puls', 'puma', 'pummel', 'pump', 'pumpkin', 'punch', 'punish', 'pupil', 'puppet', 'purchas', 'pure', 'purg', 'purifi', 'puriti', 'purpl', 'purpos', 'purs', 'pursu', 'pursuer', 'pursuit', 'push', 'pushkin', 'put', 'puzzl', 'pyg', 'pyko', 'pym', 'pyramid', 'pyro', 'pyrokinesi', 'pyrokinet', 'pythia', 'python', 'pythor', 'quadrant', 'quak', 'qualifi', 'qualiti', 'quan', 'quanhooga', 'quantum', 'quarantin', 'quark', 'quarrel', 'quarri', 'quarter', 'quartermain', 'quartet', 'quasar', 'quasi-son', 'quatermain', 'queen', 'queen/green', 'quell', 'quentin', 'querl', 'quest', 'question', 'quick', 'quickli', 'quicksilv', 'quiet', 'quietli', 'quill', 'quinci', 'quinjet', 'quinn', 'quinzel', 'quit', 'quiver', 'qurac', 'qward', 'r', 'r2-d2', 'ra', 'rabbit', 'raccoon', 'race', 'racer', 'rachel', 'racial', 'racist', 'racket', 'radar', 'radcliff', 'radd', 'radiant', 'radiat', 'radic', 'radio', 'radioact', 'raditz', 'radiu', 'raft', 'rag', 'rage', 'ragnarok', 'ragtag', 'rahn', 'rahul', 'raid', 'raiden', 'rail', 'railroad', 'rain', 'rainbow', 'rais', 'rajaki', 'ralli', 'ralph', 'ram', 'rama', 'rama-tut', 'raman', 'rambeau', 'rambo', 'rames', 'ramon', 'rampag', 'rampant', 'rams', 'ramsey', 'ran', 'rand', \"rand-k'ai\", 'randal', 'randolph', 'random', 'rang', 'ranger', 'rank', 'rann', 'rannian', 'ransack', 'ransom', 'rant', 'ranx', 'rao', 'raoh', 'rape', 'raphael', 'rapid', 'rapidli', 'raptor', 'raptur', 'rare', 'rasber', 'rash', 'rasputin', 'rat', 'ratcatch', 'rate', 'ratha', 'rathaway', 'rather', 'ration', 'ravag', 'rave', 'raven', 'ravencroft', 'ravonna', 'raw', 'rawhid', 'rawlin', 'raxalu', 'raxton', 'ray', 'raya', 'raymond', 'rayner', 'raza', 'raze', 'razor', 'razor-fist', 'razorback', 'razorfist', 're-activ', 're-appear', 're-captur', 're-creat', 're-emerg', 're-establish', 're-form', 're-integr', 're-merg', 're-open', 're-pow', 'reabsorb', 'reach', 'react', 'reaction', 'reactiv', 'reactor', 'reactron', 'read', 'reader', 'readi', 'readili', 'real', 'real-lif', 'realis', 'realist', 'realiti', 'reality-alt', 'realiz', 'realli', 'realm', 'reanim', 'reaper', 'reappear', 'rear', 'reardon', 'reason', 'reassembl', 'reassert', 'reassign', 'reassur', 'reaver', 'reawaken', 'rebar', 'rebecca', 'rebel', 'rebelli', 'rebellion', 'rebirth', 'reboot', 'reborn', 'rebuf', 'rebuild', 'rebuilt', 'recal', 'recaptur', 'receiv', 'recent', 'recept', 'receptor', 'recharg', 'rechristen', 'reciev', 'recipi', 'reciproc', 'recit', 'reckless', 'reclaim', 'reclus', 'recogn', 'recognis', 'recognit', 'recogniz', 'recollect', 'recommend', 'recon', 'reconcil', 'reconcili', 'reconfigur', 'reconnaiss', 'reconnect', 'reconsid', 'reconstitut', 'reconstruct', 'reconven', 'record', 'recount', 'recov', 'recoveri', 'recreat', 'recruit', 'recuper', 'recur', 'red', 'red-and-blu', 'red-head', 'redbird', 'reded', 'redeem', 'redempt', 'redesign', 'redfield', 'redip', 'redirect', 'rediscov', 'reduc', 'redund', 'reec', 'reed', 'reef', 'reemerg', 'rees', 'reestablish', 'refer', 'referenc', 'refin', 'reflect', 'reflex', 'refocus', 'reform', 'refrain', 'refriger', 'refug', 'refuge', 'refus', 'regain', 'regard', 'regardless', 'regener', 'regim', 'regimen', 'regiment', 'region', 'regist', 'registr', 'regress', 'regret', 'regroup', 'regular', 'regularli', 'rehabilit', 'reich', 'reid', 'reign', 'reignfir', 'reilli', 'rein', 'reincarn', 'reinforc', 'reinhardt', 'reinstat', 'reintegr', 'reinvent', 'reiter', 'reject', 'rejoin', 'rejuven', 'rekindl', 'rel', 'relaps', 'relat', 'relationship', 'relax', 'releas', 'releg', 'relent', 'reli', 'relic', 'relief', 'reliev', 'religi', 'religion', 'relinquish', 'relish', 'reliv', 'reloc', 'reluct', 'reluctantli', 'remain', 'remaind', 'remak', 'remand', 'remark', 'rematch', 'rememb', 'remi', 'remind', 'reminisc', 'remnant', 'remors', 'remot', 'remov', 'ren', 'renam', 'render', 'rendezv', 'rene', 'reneg', 'renegad', 'renew', 'renounc', 'renown', 'rent', 'reopen', 'reorgan', 'repair', 'repeal', 'repeat', 'repeatedli', 'repel', 'repent', 'replac', 'replenish', 'repli', 'replic', 'replica', 'repliforc', 'reploid', 'report', 'reportedli', 'repres', 'represent', 'repress', 'reprimand', 'reproduc', 'reproduct', 'reprogram', 'reptil', 'reptilian', 'republ', 'repuls', 'repulsor', 'reput', 'request', 'requir', 'rescu', 'research', 'resembl', 'resent', 'reserv', 'reservist', 'reset', 'reshap', 'resid', 'residu', 'resign', 'resili', 'resist', 'resolv', 'resort', 'resourc', 'respect', 'respond', 'respons', 'rest', 'restart', 'restaur', 'restor', 'restrain', 'restraint', 'restrict', 'restructur', 'result', 'resum', 'resurfac', 'resurg', 'resurrect', 'resuscit', 'retain', 'retak', 'retali', 'retcon', 'rethink', 'retir', 'retort', 'retrac', 'retract', 'retreat', 'retribut', 'retriev', 'return', 'reunion', 'reunit', 'rev', 'revamp', 'reve', 'reveal', 'revel', 'reveng', 'rever', 'reverbium', 'reverend', 'revers', 'reverse-flash', 'revert', 'revis', 'revit', 'reviv', 'revok', 'revolt', 'revolut', 'revolutionari', 'revolv', 'reward', 'rewrit', 'rex', 'rey', 'reynold', 'rhaegar', 'rhane', 'rhapsodi', 'rhino', 'rhode', 'rhodey', 'rhyme', 'rib', 'ribbon', 'rican', 'ricardo', 'rice', 'rich', 'richard', 'richmond', 'richter', 'rick', 'ricki', 'ricochet', 'rictor', 'rid', 'riddl', 'riddler', 'ride', 'rider', 'ridicul', 'rifl', 'rift', 'rig', 'rigellian', 'right', 'right-hand', 'right-w', 'rigor', 'riker', 'rikki', 'rinehart', 'ring', 'ringmast', 'rintrah', 'rio', 'riot', 'rip', 'ripe', 'ripper', 'riptid', 'rise', 'risen', 'risk', 'risqu', 'rita', 'ritchi', 'rite', 'ritual', 'rival', 'rivalri', 'river', 'riverrun', 'rnr', 'road', 'roam', 'roar', 'rob', 'robber', 'robberi', 'robbi', 'robbin', 'robe', 'robern', 'robert', 'roberta', 'roberto', 'robertson', 'robin', 'robinson', 'robot', 'robotman', 'robotnik', 'rocca', 'roch', 'rock', 'rocket', 'rocki', 'rod', 'rode', 'rodor', 'rodriguez', 'roger', 'rogu', \"roh'kar\", 'role', 'roll', 'rom', 'roma', 'roman', 'romanc', 'romani', 'romanoff', 'romant', 'rome', 'romeo', 'romulu', 'ron', 'ronald', 'ronan', 'ronin', 'ronni', 'roof', 'rooftop', 'rook', \"rook'shir\", 'rooki', 'room', 'roommat', 'roosevelt', 'root', 'rope', 'rori', 'rorschach', 'rosa', 'rosalina', 'rosalind', 'rose', 'rosemari', 'rosenberg', 'rosewood', 'roshi', 'rosi', 'ross', 'roster', 'rot', 'rotat', 'roth', 'rothstein', 'rottwel', 'roug', 'rough', 'roughli', 'roughous', 'roulett', 'round', 'rourk', 'rous', 'rout', 'routin', 'rowland', 'roxxon', 'roy', 'royal', 'royalti', 'roz', 'rubber', 'rubbl', 'rubi', 'rucku', 'rude', 'rudi', 'rudimentari', 'ruin', 'rule', 'ruler', 'rumekistan', 'rumor', 'run', 'run-in', 'runaway', 'rune', 'runner', 'ruptur', 'rusch', 'ruse', 'rush', 'russel', 'russia', 'russian', 'russo', 'rusti', 'ruthless', 'ruthlessli', 'rutland', 'ruve', 'ryan', 'ryker', 'rynda', 'ryo', 'ryuken', 'ryuko', \"s'ym\", 's.h.i.e.l.d', 's.h.i.e.l.d.', 's.h.i.e.l.d..', 's.o.', 's.t.a.r', 's.t.a.r.', 's.t.r.i.k.', 's.t.r.i.p.', 's.w.o.r.d', 'sabah', 'saber', 'sabina', 'sabl', 'sabotag', 'sabra', 'sabretooth', 'sachiko', 'sack', 'sacorria', 'sacr', 'sacrif', 'sacrific', 'sad', 'sadden', 'sadi', 'sadist', 'sadli', 'safe', 'safe-hous', 'safeguard', 'safehous', 'safekeep', 'safer', 'safeti', 'saga', 'sage', 'sahara', 'sai', 'said', 'saigon', 'saiko', 'sail', 'saint', 'saint-clair', 'sainte-cloud', 'saitama', 'saiyajin', 'saiyan', 'sakaar', 'sake', 'sakura', 'sal', 'salamand', 'sale', 'salem', 'salli', 'salom', 'saloon', 'salt', 'salvador', 'salvag', 'salvat', 'sam', 'sampl', 'sampson', 'samson', 'samuel', 'samukai', 'samurai', 'san', 'sanction', 'sanctorum', 'sanctuari', 'sanctum', 'sand', 'sandal', 'sander', 'sandi', 'sandman', 'sandov', 'sandra', 'sandsmark', 'sangtre', 'saniti', 'sank', 'sannin', 'santa', 'santo', 'saonel', 'sapien', 'sapper', 'sapphir', 'sara', 'sarah', 'sarcast', 'sarg', 'sargon', 'sasha', 'sasquatch', 'sasuk', 'sat', 'satan', 'satana', 'satannish', 'sate', 'satellit', 'satisfact', 'satisfi', 'saturn', 'saturnyn', 'saunder', 'sauron', 'savag', 'save', 'savior', 'savitar', 'saw', 'sawyer', 'say', 'sazia', 'scabbard', 'scale', 'scam', 'scan', 'scandal', 'scar', 'scarab', 'scare', 'scarecrow', 'scarfac', 'scari', 'scarlet', 'scarlett', 'scatter', 'scaveng', 'scenario', 'scene', 'scent', 'scepter', 'schedul', 'scheme', 'schexnayd', 'schiff', 'schism', 'schist', 'schmidt', 'scholar', 'scholarship', 'school', 'schorr', 'schott', 'schultz', 'scienc', 'scientif', 'scientist', 'scimitar', 'scold', 'scoop', 'scorch', 'score', 'scorpia', 'scorpion', 'scotland', 'scott', 'scotti', 'scour', 'scourg', 'scout', 'scr-hd', 'scrambl', 'scrap', 'scrapper', 'scratch', 'scream', 'screen', 'scroll', 'scuffl', 'sculptur', \"scy'ar\", 'sea', 'seagat', 'seal', 'sean', 'seanc', 'search', 'season', 'seat', 'seattl', 'sebastian', 'seclud', 'seclus', 'second', 'second-in-command', 'secondari', 'secreci', 'secret', 'secretari', 'secretli', 'sect', 'section', 'sector', 'secur', 'sedat', 'seduc', 'see', 'seed', 'seek', 'seeker', 'seem', 'seemingli', 'seen', 'seer', 'seismic', 'seiz', 'select', 'selen', 'self', 'self-defens', 'self-destruct', 'self-impos', 'self-styl', 'selfish', 'selflessli', 'selina', 'sell', 'selv', 'selys', 'semblanc', 'semest', 'semi-act', 'semi-retir', 'senat', 'send', 'senior', 'senju', 'sens', 'sensat', 'sensei', 'sensit', 'sensor', 'sensori', 'sent', 'sentenc', 'sentienc', 'sentient', 'sentiment', 'sentinel', 'sentri', 'separ', 'septemb', 'sequenc', 'sequest', 'ser', 'seraph', 'serbian', 'sergeant', 'sergei', 'seri', 'serial', 'seriesedit', 'seriou', 'serious', 'serpent', 'serpentin', 'serpentina', 'sersi', 'serum', 'serv', 'servant', 'servic', 'servitud', 'session', 'set', 'setback', 'seth', 'settl', 'settlement', 'seven', 'seventeen', 'sever', 'severu', 'sew', 'sewer', 'sex', 'sexual', 'sgt', 'shackl', 'shade', 'shado', 'shadow', 'shadowcat', 'shadowi', 'shadowpact', 'shadowqueen', 'shaft', 'shagohod', 'shahra', 'shaitan', 'shakari', 'shake', 'shaken', 'shall', 'sham', 'shaman', 'shambl', 'shame', 'shang', 'shang-chi', 'shanghai', 'shannon', 'shanoa', 'shao', 'shaolin', 'shapanka', 'shape', 'shape-chang', 'shape-shift', 'shaper', 'shapeshift', 'shard', 'share', 'sharingan', 'shark', 'sharon', 'sharp', 'sharra', 'shatter', 'shatterstar', 'shave', 'shaw', 'shay', 'shazam', 'shdb', 'she-dragon', 'she-hulk', 'shear', 'sheath', 'shed', 'sheenarian', 'sheer', 'sheerah', 'sheila', 'shell', 'shelley', 'shelter', 'shepherd', 'sheridan', 'sheriff', 'sherman', 'sheva', 'shi', \"shi'ar\", 'shialmar', 'shiar', 'shield', 'shift', \"shim'tar\", 'shimura', 'shin', 'shinagawa', 'shine', 'shingen', 'shinken', 'shinobi', 'ship', 'shipment', 'shireen', 'shirle', 'shirt', 'shiva', 'shmidt', 'shock', 'shocker', 'shoe', 'shogun', 'shondra', 'shook', 'shoot', 'shootout', 'shop', 'shore', 'short', 'short-circuit', 'short-liv', 'shorten', 'shortli', 'shot', 'shotgun', 'shou-lao', 'shoulder', 'shout', 'shove', 'show', 'showdown', 'shower', 'shown', 'shrank', 'shrapnel', 'shred', 'shriek', 'shrink', 'shroud', 'shrug', 'shrunk', 'shrunken', 'shu', 'shuffl', 'shuma-gorath', 'shun', 'shunt', 'shuri', 'shuriken', 'shut', 'shuttl', 'si', 'siberia', 'sibl', 'sicili', 'sick', 'side', 'side-by-sid', 'side-effect', 'sidekick', 'sidelin', 'sider', 'sidewind', 'sidiou', 'sidri', 'sieg', 'siegfri', 'siegmund', 'sif', 'sight', 'sigil', 'sigint', 'sigma', 'sign', 'signal', 'signatur', 'signific', 'significantli', 'silenc', 'silent', 'silicon', 'silk', 'silmaril', 'silver', 'silverclaw', 'silverman', 'sim', 'similar', 'similarli', 'simmon', 'simon', 'simpl', 'simpli', 'simpson', 'simul', 'simultan', 'sin', 'sinc', 'sincer', 'sinclair', 'sindel', 'sinestro', 'sing', 'singapor', 'singer', 'singl', 'single-handedli', 'singular', 'sinist', 'sink', 'sinner', 'siobhan', 'siphon', 'sir', 'sire', 'siredam', 'siren', 'siriu', 'siryn', 'sister', 'sisterhood', 'sit', 'site', 'sith', 'situat', 'sivana', 'six', 'sixteen', 'sixth', 'size', 'size-chang', 'skaar', 'skadi', 'skale', 'skater', 'skeet', 'skelet', 'skeleton', 'skeptic', 'skewer', 'ski', 'skid', 'skill', 'skin', 'skinless', 'skip', 'skirmish', 'skornn', 'skreet', 'skrull', 'skulkin', 'skull', 'skullfir', 'skurg', 'skuttlebutt', 'sky', 'skye', 'skynet', 'skyscrap', 'skywalk', 'slab', 'slabsid', 'slade', 'slag', 'slain', 'slam', 'slap', 'slapstick', 'slash', 'slasher', 'slatteri', 'slaughter', 'slave', 'slaver', 'slaveri', 'slay', 'slayback', 'slayer', 'slaymast', 'sledg', 'sleep', 'sleeper', 'slender', 'slept', 'slew', 'slice', 'slide', 'slideway', 'slight', 'slightli', 'slip', 'slit', 'slither', 'slithraa', 'slizzath', 'sloan', 'slow', 'slowli', 'slug', 'sluggo', 'slum', 'smack', 'small', 'smaller', 'smallvil', 'smart', 'smart-mouth', 'smartest', 'smash', 'smasher', 'smear', 'smell', 'smile', 'smiley', 'smite', 'smith', 'smither', 'smitti', 'smoak', 'smoke', 'smuggl', 'smyth', 'snag', 'snake', 'snake-ey', 'snakeroot', 'snap', 'snape', 'snart', 'snatch', 'sneak', 'sneer', 'sniper', 'snow', 'snowbird', 'snuck', 'so-cal', 'soar', 'sobek', 'sobrieti', 'soccer', 'social', 'socialit', 'societi', 'sociopath', 'sodam', 'soft', 'softwar', 'soil', 'sokolov', 'sokovia', 'sol', 'solac', 'solar', 'solari', 'solarr', 'sold', 'soldier', 'sole', 'soleanna', 'solid', 'solidu', 'solitari', 'solitud', 'solli', 'solo', 'solomon', 'solovar', 'solut', 'solv', 'someday', 'somehow', 'someon', 'somer', 'someth', 'sometim', 'somewhat', 'somewher', 'son', 'sonar', 'sondheim', 'songbird', 'sonic', 'sonya', 'soon', 'sooner', 'soong', 'sooth', 'sop', 'sophi', 'sophist', 'soranik', 'sorcer', 'sorceress', 'sorceri', 'sorri', 'sorrow', 'sort', 'soto', 'sought', 'soul', 'soul-gem', 'soulgem', 'soulless', 'soulsword', 'sound', 'soundli', 'sour', 'sourc', 'south', 'southeast', 'souther', 'southern', 'souvenir', 'sovereign', 'soviet', 'space', 'space-st', 'space-tim', 'spacecraft', 'spaceknight', 'spaceport', 'spacer', 'spaceship', 'spaceway', 'spacewheel', 'spain', 'span', 'spanish', 'spar', 'spare', 'spark', 'sparrow', 'spartan', 'spartax', 'spartoi', 'spat', 'spawn', 'speak', 'spear', 'spearhead', 'speci', 'special', 'specialist', 'specialti', 'specif', 'specimen', 'spectacular', 'spectat', 'spector', 'spectr', 'spectral', 'spectrum', 'specul', 'sped', 'speech', 'speechless', 'speed', 'speedbal', 'speedboyz', 'speeder', 'speedi', 'speedster', 'speedsuit', 'spell', 'spencer', 'spend', 'spent', 'sphere', 'sphinx', 'spi', 'spider', 'spider-armi', 'spider-girl', 'spider-island', 'spider-lik', 'spider-man', 'spider-sens', 'spider-totem', 'spider-trac', 'spider-uk', 'spider-woman', 'spider-women', 'spidey', 'spike', 'spill', 'spin', 'spin-off', 'spinal', 'spine', 'spineless', 'spinjitzu', 'spinner', 'spiral', 'spire', 'spirit', 'spiritu', 'spit', 'spite', 'spitfir', 'spivot', 'splice', 'splinter', 'split', 'spoil', 'spoiler', 'spoke', 'spoken', 'sponsor', 'spontan', 'spook', 'sporad', 'spore', 'sport', 'spot', 'spotlight', 'spout', 'sprang', 'spray', 'spread', 'spree', 'spring', 'springdal', 'sprint', 'sprite', 'sprixi', 'sprout', 'sprung', 'spurn', 'spyke', 'spymast', 'squad', 'squadron', 'squar', 'squeez', 'squidboy', 'squir', 'squirrel', 'sr.', 'ssangyong', 'ssr', 'st', 'st.', 'stab', 'stabil', 'stabl', 'staci', 'stack', 'staff', 'stage', 'stagg', 'stain', 'stair', 'stake', 'stalem', 'stalk', 'stalker', 'stall', 'stalwart', 'stamford', 'stamina', 'stamped', 'stan', 'stanc', 'stand', 'standard', 'standstil', 'stane', 'stanni', 'star', 'star-lord', 'star-shark', 'star-spangl', 'starbolt', 'stardriv', 'stardust', 'stare', 'starfir', 'starfox', 'stargirl', 'stargod', 'starhawk', 'starjamm', 'stark', 'stark-fujikawa', 'starl', 'starlight', 'starlord', 'starman', 'starr', 'starro', 'starship', 'starsmor', 'start', 'startl', 'starv', 'stasi', 'state', 'state-of-the-art', 'statement', 'statesman', 'static', 'station', 'statu', 'statur', 'staunch', 'stave', 'stay', 'stead', 'steadi', 'steadili', 'steal', 'stealth', 'steam', 'steed', 'steel', 'steelwork', 'steer', 'stefan', 'stein', 'stellar', 'stellarax', 'stellarium', 'stem', 'step', 'step-broth', 'stepbroth', 'stepfath', 'stepford', 'stephani', 'stephen', 'stepmoth', 'steppenwolf', 'steril', 'stern', 'steve', 'steven', 'stevi', 'stewart', 'stick', 'still', 'stillman', 'stilt-man', 'stimul', 'stimuli', 'sting', 'stingare', 'stint', 'stir', 'stirk', 'stock', 'stockpil', 'stoke', 'stole', 'stolen', 'stomach', 'stomp', 'stone', 'stoneworld', 'stood', 'stop', 'storag', 'store', 'stori', 'stork', 'storm', 'stormblud', 'stormbreak', 'stormi', 'stormtroop', 'storylin', 'storytel', 'stow', 'straight', 'straighten', 'strain', 'strand', 'strang', 'strangelov', 'stranger', 'strangl', 'strap', 'strateg', 'strategi', 'strategist', 'stray', 'streak', 'stream', 'street', 'street-level', 'street-smart', 'strength', 'strengthen', 'stress', 'stretch', 'stricken', 'strict', 'strictli', 'strife', 'strike', 'strikeforc', 'string', 'strip', 'stroke', 'stromm', 'strong', 'stronger', 'strongest', 'stronghold', 'strongli', 'strontia', 'strontian', 'struck', 'strucker', 'structur', 'struggl', 'strut', 'stryfe', 'stryker', 'stuart', 'stubborn', 'stuck', 'student', 'studi', 'studio', 'stuff', 'stumbl', 'stun', 'stunt', 'stuntman', 'stupor', 'style', 'styx', 'su', 'sub', 'sub-marin', 'sub-zero', 'subatom', 'subcon', 'subconsci', 'subdu', 'subject', 'subjug', 'sublim', 'sublimin', 'submarin', 'submerg', 'submiss', 'submit', 'subordin', 'subsequ', 'subservi', 'substanc', 'substanti', 'substitut', 'subterranean', 'subtl', 'subtli', 'suburb', 'subvers', 'subvert', 'subway', 'succe', 'succeed', 'success', 'successor', 'succubu', 'succumb', 'suck', 'sudan', 'sudden', 'suddenli', 'sue', 'suffer', 'suffici', 'suffoc', 'suggest', 'suicid', 'suit', 'suitabl', 'sum', 'suma-ket', 'summarili', 'summer', 'summit', 'summon', 'sun', 'sunday', 'sunder', 'sunderland', 'sunfir', 'sunglass', 'sunk', 'sunken', 'sunlight', 'sunni', 'sunnydal', 'sunris', 'sunset', 'sunspot', 'sunston', 'super', 'super-ag', 'super-b', 'super-crimin', 'super-gang', 'super-hero', 'super-human', 'super-pow', 'super-skrul', 'super-soldi', 'super-spe', 'super-spi', 'super-strength', 'super-strong', 'super-team', 'super-villain', 'superb', 'superboy', 'superboy-prim', 'superflu', 'supergirl', 'superhero', 'superheroin', 'superhuman', 'superhumanli', 'superia', 'superior', 'superman', 'superman-prim', 'supermen', 'supernatur', 'supernova', 'superpatriot', 'superpow', 'superspe', 'supersuit', 'supervillain', 'supervis', 'superwoman', 'supplant', 'supplement', 'suppli', 'support', 'suppos', 'supposedli', 'suppress', 'suprem', 'supremaci', 'sur', 'sure', 'suresh', 'surfac', 'surface-dwel', 'surfer', 'surg', 'surgeon', 'surgeri', 'surgic', 'surli', 'surmis', 'surpass', 'surpris', 'surprisingli', 'surrend', 'surreptiti', 'surrog', 'surround', 'surtur', 'surveil', 'surviv', 'survivor', 'susan', 'suscept', 'suspect', 'suspend', 'suspens', 'suspici', 'suspicion', 'sustain', 'sutter', 'suwan', 'suzi', 'svartalfheim', 'swagman', 'swallow', 'swamp', 'swan', 'swann', 'swap', 'swarm', 'swat', 'sway', 'swear', 'sweatshop', 'swell', 'swept', 'swift', 'swiftli', 'swim', 'swing', 'swirl', 'swiss', 'switch', 'switzerland', 'sword', 'swordsman', 'swore', 'sworn', 'swung', 'sydney', 'sylar', 'symbiot', 'symbol', 'sympath', 'sympathet', 'sympathi', 'symptom', 'synch', 'syndic', 'syndrom', 'syng', 'synn', 'synthes', 'synthet', 'synthezoid', 'syntho-ste', 'syphon', 'syphonn', 'system', 'systemat', 'szardo', \"t'chaka\", \"t'challa\", \"t'korr\", 't-1000', 't-1001', 't-800', 't-ray', 't-shirt', 't-veronica', 't-viru', 't-x', 'tab', 'tabitha', 'tabl', 'tablet', 'tabula', 'tabur', 'tabuu', 'tachyon', 'tackl', 'tactic', 'tactician', 'tag', 'tail', 'tailor', 'taint', 'take', 'taken', 'takeov', 'taki', 'takion', 'tal', 'talan', 'talbot', 'tale', 'talent', 'talia', 'talisman', 'talk', 'tall', 'talon', 'talzin', 'tam', 'tamaran', 'tame', 'tamper', 'tanaraq', 'tandi', 'tank', 'tanker', 'tanner', 'tantu', 'tap', 'tape', 'tara', 'tarantula', 'tare', 'taren', 'targaryen', 'target', 'tarot', 'tartaru', 'taryn', 'taser', 'tasha', 'task', 'taskmast', 'tast', 'tatanga', 'tatooin', 'tatsu', 'tatter', 'tattoo', 'taught', 'taunt', 'tax', 'taxi', 'taylor', 'tea', 'teach', 'teacher', 'team', 'team-up', 'teamed-up', 'teammat', 'teamwork', 'teapot', 'tear', 'teas', 'tech', 'technarchi', 'technet', 'techni', 'technic', 'technician', 'techniqu', 'techno', 'techno-organ', 'technolog', 'ted', 'teen', 'teenag', 'teeth', 'tef', 'telekinesi', 'telekinet', 'telepath', 'telepathi', 'teleport', 'teleri', 'televis', 'tell', 'telo', 'temper', 'tempera', 'temperatur', 'tempest', 'templ', 'templar', 'templat', 'tempor', 'temporari', 'temporarili', 'tempt', 'temptat', 'ten', 'tend', 'tendenc', 'tender', 'tendra', 'tengu', 'tennyson', 'tens', 'tension', 'tent', 'tentacl', 'tenth', 'tenur', 'term', 'termin', 'termineu', 'terminu', 'termit', 'terra', 'terraform', 'terrax', 'terri', 'terribl', 'terrif', 'terrifi', 'terrigen', 'terrigenesi', 'territori', 'terror', 'terrorist', 'tesseract', 'test', 'testament', 'testifi', 'testimoni', 'teth-adam', 'tether', 'texa', 'text', 'thaddeu', 'thalia', 'thame', 'thanagar', 'thanagarian', 'thanato', 'thank', 'thanksgiv', 'thano', 'thanosi', 'thar', 'thara', 'thaw', 'thawn', 'thawne/reverse-flash', 'thea', 'theater', 'theatr', 'theft', 'theme', 'themyscara', 'themyscira', 'then-curr', 'thena', 'theo', 'theoret', 'theori', 'theoriz', 'therapi', 'therapist', 'thereaft', 'therebi', 'therefor', 'theresa', 'thesi', 'thesili', 'thessali', 'theta', 'thick', 'thief', 'thiev', 'thin', 'thing', 'think', 'thinker', 'third', 'thirst', 'thirteen', 'thirti', 'thog', 'thoma', 'thompkin', 'thompson', 'thor', 'thori', 'thornn', 'thoro', 'thoroughli', 'though', 'thought', 'thousand', 'thrall', 'thrasher', 'threat', 'threaten', 'three', 'three-way', 'threw', 'thrill', 'throat', 'throne', 'throneworld', 'throttl', 'throughout', 'throw', 'thrown', 'thrust', 'thu', 'thug', 'thuggish', 'thunder', 'thunderbird', 'thunderbolt', 'thunderclap', 'thunderstorm', 'thunderstrik', 'thundra', 'thurman', 'thwart', 'tiara', 'tibet', 'tick', 'ticket', 'tidal', 'tide', 'tie', 'tier', 'tiger', 'tigra', 'tikal', 'tim', 'timber', 'time', 'time-displac', 'time-keep', 'time-spac', 'time-travel', 'timebrok', 'timelin', 'timepoint', 'timeslip', 'timestream', 'timid', 'timothi', 'tina', 'tini', 'tinker', 'tip', 'tire', 'tirion', 'tissu', 'titan', 'titania', 'titanian', 'titanium', 'titl', 'titu', 'tivan', 'tiwaz', 'toad', 'toadsworth', 'toast', 'tobi', 'tobia', 'tod', 'today', 'todd', 'toddler', 'toe', 'togeth', 'token', 'toki', 'tokyo', 'told', 'toler', 'toll', 'tolliv', 'tom', 'toma', 'tomb', 'tombston', 'tome', 'tommi', 'tomorrow', 'ton', 'tone', 'tongu', 'toni', 'took', 'tool', 'toom', 'top', 'top-secret', 'topaz', 'topic', 'toppl', 'torch', 'tore', 'torment', 'tormentor', 'torn', 'tornado', 'toro', 'torpedo', 'torso', 'tortur', 'toss', 'tot', 'total', 'totem', 'touch', 'tough', 'tour', 'tournament', 'tourney', 'tow', 'toward', 'tower', 'town', 'townhous', 'townspeopl', 'toxic', 'toxin', 'toy', 'toyman', 'toynbe', 'trace', 'tracer', 'traci', 'track', 'tracker', 'tractor', 'trade', 'trademark', 'trader', 'tradit', 'traffic', 'traffick', 'tragedi', 'tragic', 'trail', 'train', 'traine', 'trainer', 'trait', 'traitor', 'tranc', 'tranquil', 'transact', 'transbelvia', 'transfer', 'transform', 'transfus', 'transia', 'transigen', 'transit', 'translat', 'transmiss', 'transmit', 'transmitt', 'transmod', 'transmut', 'transpar', 'transpir', 'transplant', 'transport', 'transylvania', 'trap', 'trapper', 'trash', 'trask', 'trauma', 'traumat', 'travel', 'travers', 'traya', 'traynor', 'treacher', 'treacheri', 'treadmil', 'treason', 'treasur', 'treat', 'treati', 'treatment', 'tree', 'trek', 'tremend', 'tremont', 'trench', 'trenchcoat', 'trestl', 'trevor', 'tri', 'trial', 'triangl', 'tribb', 'tribe', 'tribun', 'tribut', 'tricel', 'trick', 'trickshot', 'trickster', 'trident', 'trigger', 'trigon', 'trini', 'triniti', 'trio', 'trip', 'tripl', 'trish', 'triton', 'tritoni', 'triumph', 'triumphant', 'triumvir', 'trogg', 'troi', 'troll', 'trolley', 'troop', 'trooper', 'trophi', 'troubl', 'troy', 'troyjan', 'truce', 'truck', 'true', 'truli', 'trust', 'trustworthi', 'truth', 'tselinoyarsk', 'tsung', 'tsurayaba', 'tube', 'tula', 'tumolo', 'tumor', 'tumulo', 'tumultu', 'tune', 'tunnel', 'turbin', 'turbo', 'turbul', 'turkey', 'turmoil', 'turn', 'turnbul', 'turtl', 'tussl', 'tutelag', 'tutor', 'tv', 'twain', 'twelv', 'twenti', 'twentieth', 'twenty-first', 'twice', 'twilight', 'twin', 'twist', 'twister', 'twitch', 'two', 'two-fac', 'two-gun', 'tyannan', 'tyger', 'tyler', 'tyme', 'type', 'typhoid', 'typic', 'tyrahn', 'tyrann', 'tyrannu', 'tyrant', 'tyrion', 'tyro', 'tyron', 'tywin', 'tzu', 'u-men', 'u.k.', 'u.n.', 'u.s.', 'uac', 'ualac', 'uatu', 'uchiha', 'ugli', 'uk', 'ultim', 'ultimo', 'ultra', 'ultron', 'ulyss', 'umar', 'umbrella', 'umbridg', 'un', 'una', 'unabl', 'unaffect', 'unansw', 'unauthor', 'unawar', 'unbalanc', 'unbeknown', 'unbeknownst', 'unborn', 'unbreak', 'uncanni', 'uncertain', 'uncertainti', 'unchang', 'uncharacterist', 'unchart', 'uncheck', 'uncl', 'unclear', 'uncomfort', 'unconsci', 'uncontrol', 'unconvent', 'uncov', 'uncreat', 'undaunt', 'undead', 'undercov', 'underestim', 'undergo', 'undergon', 'undergradu', 'underground', 'underl', 'undermin', 'underneath', 'undersea', 'understand', 'understood', 'undertak', 'undertaken', 'undertook', 'underw', 'underwat', 'underway', 'underwear', 'underwood', 'underworld', 'undi', 'undisclos', 'undo', 'undon', 'uneas', 'uneasi', 'unemploy', 'unexpect', 'unexpectedli', 'unexplain', 'unfamiliar', 'unfaz', 'unfeel', 'unfold', 'unforese', 'unfortun', 'ungoli', 'unharm', 'unhing', 'unholi', 'uni-pow', 'unicorn', 'unicron', 'unidentifi', 'unifi', 'uniform', 'unintent', 'uninterest', 'union', 'uniqu', 'unit', 'uniti', 'univers', 'unknowingli', 'unknown', 'unleash', 'unless', 'unlik', 'unlimit', 'unliv', 'unlock', 'unmask', 'unmov', 'unnam', 'unnot', 'unoffici', 'unpreced', 'unpredict', 'unprepar', 'unravel', 'unregist', 'unresolv', 'unrest', 'unrev', 'unscath', 'unseen', 'unsheath', 'unspecifi', 'unstabl', 'unstopp', 'unsuccess', 'unsuit', 'unsur', 'unsurpris', 'unsuspect', 'unternet', 'untim', 'untold', 'untouch', 'unu', 'unus', 'unusu', 'unveil', 'unwant', 'unwil', 'unwilling', 'unwit', 'unwittingli', 'unworthi', 'up', 'up-and-com', 'upbring', 'upcom', 'updat', 'upgrad', 'uphold', 'upload', 'upon', 'upper', 'upris', 'uproot', 'upset', 'upsid', 'upstat', 'uranium', 'urban', 'urg', 'urich', 'uroboro', 'ursa', 'urthona', 'uru', 'us', 'usa', 'usag', 'use', 'useless', 'user', 'usher', 'uss', 'ussr', 'usual', 'usurp', 'utah', 'utgard-loki', 'util', 'utopia', 'utopian', 'utter', 'utterli', 'uub', 'uzumaki', 'v', 'v-battalion', 'vacant', 'vacat', 'vaccin', 'vacuum', 'vader', 'vagabond', 'vagrant', 'vagu', 'vain', 'val', 'valar', 'valdez', 'vale', 'valentin', 'valeri', 'valeria', 'valeska', 'valet', 'valhalla', 'valid', 'validu', 'valinor', 'valkyri', 'valley', 'valu', 'valuabl', 'valyrian', 'vamp', 'vampir', 'van', 'vanc', 'vandal', 'vanessa', 'vanguard', 'vanilla', 'vanish', 'vaniti', 'vanko', 'vanquish', 'vapor', 'varga', 'vari', 'variant', 'variat', 'varieti', 'variou', 'various', 'vase', 'vast', 'vastli', 'vat', 'vault', 'vega', 'veget', 'vegeta', 'vehicl', 'veidt', 'velocipod', 'vendetta', 'veng', 'vengeanc', 'venic', 'venom', 'vent', 'ventriloquist', 'ventur', 'venu', 'verbal', 'verd', 'verg', 'verifi', 'vermillion', 'vermin', 'vermont', 'veronica', 'version', 'vertigo', 'vessel', 'veteran', 'vex', 'via', 'viabl', 'vial', 'vibe', 'vibranium', 'vibrat', 'vibratori', 'vic', 'vice', 'vicin', 'viciou', 'vicious', 'vicki', 'victim', 'victor', 'victori', 'victoria', 'video', 'vietnam', 'view', 'viewpoint', 'vigilant', 'vigma', 'vike', 'vile', 'vilgax', 'villa', 'villag', 'villai', 'villain', 'villaini', 'vincent', 'vindic', 'violat', 'violenc', 'violent', 'violet', 'viper', 'virago', 'viral', 'virginia', 'virtual', 'viru', 'virus', 'vishanti', 'visibl', 'vision', 'visit', 'visitor', 'visual', 'vita', 'vital', 'vitamin', 'vivian', 'vixen', 'vizier', 'vlad', 'vladimir', 'vlava', 'vocal', 'voic', 'void', 'vol', 'volatil', 'volcan', 'volcano', 'voldemort', 'volgin', 'volstagg', 'volum', 'volunt', 'voluntarili', 'vomit', 'von', 'vong', 'voodoo', 'vortex', 'vote', 'vow', 'vril', 'vs.', 'vulcan', 'vulcann', 'vulko', 'vulner', 'vultur', 'vung', 'w', 'w.', 'wade', 'wage', 'wager', 'wagner', 'waist', 'wait', 'waitress', 'wakanda', 'wakandan', 'wake', 'walk', 'walker', 'wall', 'wall-crawl', 'waller', 'walli', 'walru', 'walsh', 'walter', 'wand', 'wanda', 'wander', 'wane', 'wannab', 'want', 'war', 'war-torn', 'warbird', 'warbound', 'ward', 'warden', 'wardrob', 'warehous', 'warfar', 'warhawk', 'warhead', 'wari', 'warlock', 'warlord', 'warm', 'warn', 'warp', 'warpath', 'warrant', 'warren', 'warrior', 'warsaw', 'warship', 'warstar', 'wartim', 'warwolv', 'warworld', 'wash', 'washington', 'washout', 'wasnt', 'wasp', 'wast', 'wasteland', 'watch', 'watchdog', 'watcher', 'watchmak', 'watchmen', 'watchtow', 'water', 'waterbear', 'waterfal', 'waterfront', 'watkin', 'watson', 'wauer', 'wave', 'waverid', 'way', 'way-open', 'wayfind', 'waylon', 'wayn', 'wca', 'we', 'weak', 'weaken', 'weaker', 'weakest', 'wealth', 'wealthi', 'weapon', 'weaponri', 'wear', 'wearer', 'weari', 'weasel', 'weather', 'weaver', 'web', 'web-sling', 'webster', 'wed', 'week', 'weekend', 'weep', 'weigh', 'weight', 'weil', 'weird', 'welcom', 'welfar', 'well', 'well-b', 'well-known', 'wench', 'wendel', 'wendigo', 'went', 'went-on', 'werehog', 'werewolf', 'werewolv', 'werner', 'wesker', 'wesley', 'west', 'westchest', 'western', 'westero', 'westlak', 'wet', 'whale', 'whatev', 'wheel', 'wheelchair', 'wheelchair-bound', 'wheeler', 'whenev', 'wherea', 'whereabout', 'wherein', 'whereupon', 'wherev', 'whether', 'whilst', 'whim', 'whip', 'whirlwind', 'whisk', 'whisker', 'whisper', 'whitbi', 'white', 'whitecloud', 'whitman', 'whitmor', 'whole', 'wholli', 'whose', 'wiccan', 'wide', 'wideawak', 'widespread', 'widget', 'widow', 'wield', 'wielder', 'wife', 'wig', 'wight', 'wild', 'wildcat', 'wildebeest', 'wilder', 'wildfir', 'wildheart', 'wile', 'wilhelm', 'wili', 'wilkin', 'will', 'willi', 'william', 'willing', 'willingli', 'willow', 'willpow', 'wilma', 'wilson', 'wilsoni', 'win', 'winchest', 'wind', 'window', 'wine', 'wing', 'wingfoot', 'wink', 'winner', 'winston', 'winter', 'wintergreen', 'wipe', 'wire', 'wisconsin', 'wisdom', 'wise', 'wise-crack', 'wisecrack', 'wish', 'wisp', 'wit', 'witch', 'witchcraft', 'withdraw', 'withdrawn', 'withdrew', 'within', 'without', 'withstand', 'witter', 'wizard', 'wizardri', 'wo', 'woke', 'wolf', 'wolfgang', 'wolfl', 'wolfsban', 'wolv', 'wolverin', 'woman', 'womb', 'women', 'wonder', 'wong', 'wong-chu', 'woo', 'wood', 'wooden', 'woodru', 'woozi', 'word', 'wore', 'work', 'worker', 'workshop', 'world', 'world-devour', 'world-wid', 'worldmind', 'worldship', 'worldwid', 'worm', 'wormhol', 'worn', 'worri', 'wors', 'worsen', 'worship', 'worshipp', 'worst', 'worth', 'worthi', 'worthington', 'would', 'would-b', 'wound', 'wrack', 'wraith', 'wrap', 'wrath', 'wreak', 'wreck', 'wreckag', 'wrest', 'wrestl', 'wrestler', 'wright', 'wrist', 'write', 'writer', 'written', 'wrong', 'wrongli', 'wrote', 'wrought', 'wu', 'wundagor', 'wunderkind', 'wwhulk.jpg', 'wwii', 'wyatt', 'wyndham', 'wynn', 'x', 'x-23', 'x-51', 'x-babi', 'x-club', 'x-corp', 'x-corpor', 'x-factor', 'x-forc', 'x-hunter', 'x-jet', 'x-man', 'x-mansion', 'x-men', 'x-nation', 'x-termin', 'x-treme', 'x.', 'x.s.e', 'x4', 'x5', 'x6', 'xandar', 'xandarian', 'xander', 'xavier', 'xebel', 'xenomorph', \"xi'an\", 'xian', 'xii', 'xof', 'xorn', 'xs', 'y2k', \"ya'wara\", 'yacht', 'yacker', 'yaguchi', 'yahweh', 'yakuza', 'yamanaka', 'yamashiro', 'yandroth', 'yang', 'yann', 'yard', 'yashida', 'yashiori', 'yat', 'yavin', 'ye', 'year', 'yearn', 'yell', 'yellow', 'yellowjacket', 'yet', 'yeti', 'yggdrasil', 'yield', 'yin', 'yinsen', 'ymir', 'yo-yo', 'yoda', 'yon-rogg', 'yondu', 'york', 'yoshi', 'yoshioka', 'young', 'younger', 'youngest', 'youngster', 'youth', 'yu', 'yu-ti', 'yukio', 'yukon', 'yuria', 'yuriko', 'yuuzhan', 'yvett', 'z', \"z'nox\", 'z-saber', 'zail', 'zaladan', 'zane', 'zann', 'zanzibar', 'zaratho', 'zarek', 'zatanna', 'zatara', 'zath', 'zator', 'zauber', 'zavok', 'zazz', 'zeal', 'zealot', 'zebediah', 'zebra', 'zed', 'zeena', 'zeke', 'zemo', 'zennon', 'zeno', 'zero', 'zeta', 'zeta-beam', 'zeti', 'zeu', 'zhao', 'zhered-na', 'zinco', 'zoann', 'zod', 'zodiac', 'zoe', 'zoiray', 'zola', 'zolomon', 'zom', 'zombi', 'zomom', 'zone', 'zoo', 'zoom', 'zor', 'zor-el', 'zor-l', 'zsaji', 'zsasz', 'zucco', 'zuel', 'zzzax']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhnVkgiG3Gvg",
        "outputId": "f5fe26db-fad4-4a63-8ab6-0bd783000a71"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "atributos_de_interes = ['intelligence_score', 'strength_score', 'speed_score', 'durability_score', 'power_score', 'combat_score']\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(df_comics[atributos_de_interes])\n",
        "scaler.transform(df_comics[atributos_de_interes])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.85, 0.3 , 0.6 , 0.6 , 0.4 , 0.7 ],\n",
              "       [0.8 , 1.  , 0.8 , 1.  , 1.  , 0.8 ],\n",
              "       [0.8 , 0.5 , 0.55, 0.45, 1.  , 0.55],\n",
              "       ...,\n",
              "       [0.95, 0.5 , 1.  , 0.75, 1.  , 0.8 ],\n",
              "       [0.75, 0.1 , 1.  , 0.3 , 1.  , 0.3 ],\n",
              "       [0.45, 0.8 , 0.75, 0.95, 0.8 , 0.5 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzHaBU7Q8EHj"
      },
      "source": [
        "ColumnTransformer(\n",
        "    transformers=[\n",
        "                    ('bow', CountVectorizer(\n",
        "                    tokenizer=LemmaTokenizer(),\n",
        "                    lowercase=True,  # Transformamos todo a min煤suculas.\n",
        "                    max_features=10000,  # Dejamos solo las 10000 palabras m谩s frecuentes,\n",
        "                    ngram_range=(1, 2)\n",
        "                    ), \n",
        "                    'history_text'),\n",
        "                    ('scaler', MinMaxScaler(), \n",
        "                    ['intelligence_score', 'strength_score', 'speed_score', 'durability_score', 'power_score', 'combat_score'])\n",
        "                  ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stHncQ-A-j4I"
      },
      "source": [
        "## 1.2 Dise帽o de Pipeline y  Primer Entrenamiento [1.5 puntos]\n",
        "\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://pa1.narvii.com/6374/9eaec1b7bf9157334151452a669516f9a78b954c_hq.gif\" width=\"300\">\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeMiptpQ_EWb"
      },
      "source": [
        "A continuaci贸n, genere un Pipeline con las caracteristicas solicitadas en la secci贸n 1.1, a帽adiendo un reductor de dimensionalidad llamado `TruncatedSVD()` ajustando el n煤mero de componentes en 1000 (este reducto de dimensionalidad es similar al PCA pero funciona para vectores dispersos) y un clasificador `MultinomialNB()` por defecto.  Luego, separe el conjunto de datos en un conjunto de entrenamiento y prueba, donde el etiquetado vendr谩 dado por el atributo `alignment`. Finalmente entrene el modelo y reporte el desempe帽o con un `classification_report`. 驴 Nos recomendar铆a predecir la alineaci贸n de BatCow con este clasificador?.\n",
        "\n",
        "**Nota:** Debido al desbalance que existe entre las clases, puede ser util aplicar m茅todo de [`imbalanced-learn`](https://github.com/scikit-learn-contrib/imbalanced-learn) como RandomOverSampler sobre los datos de entrenamiento. \n",
        "\n",
        "**To-DO:**\n",
        "- [ ] Realizar un pipeline con las caracteristicas solicitadas en 1.1,aplicar un reductor de dimensionalidad `TruncatedSVD` y aplicar un clasificador  `MultinomialNB()`.\n",
        "- [ ] Entrenar el pipeline.\n",
        "- [ ] (Opcional - **0.5 bonus**) Utilizar t茅cnicas de Sampling para balancear los datos de entrenamiento.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nYoOucGDEZj"
      },
      "source": [
        "X = df_comics[['history_text','intelligence_score', 'strength_score', 'speed_score', 'durability_score', 'power_score', 'combat_score']]\n",
        "y = df_comics['alignment']"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0QIpm56DB7v"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.30, random_state=12)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fivqr52OF5yx",
        "outputId": "b9b795c7-5396-4545-9256-916924557a07"
      },
      "source": [
        "# Balanceamos clases.\n",
        "over = RandomOverSampler(random_state=1)\n",
        "X_train_balanced, y_train_balanced = over.fit_resample(X_train, y_train)\n",
        "X_train_balanced = pd.DataFrame(X_train_balanced)\n",
        "y_train_balanced = pd.Series(y_train_balanced)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWavGybV6A3_"
      },
      "source": [
        "index_ = ['history_text','intelligence_score', 'strength_score', 'speed_score', 'durability_score', 'power_score', 'combat_score']\n",
        "X_train_balanced.columns = index_"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMwJgg3G5nhY",
        "outputId": "df3d89e0-fc56-425f-a6de-e373d135684f"
      },
      "source": [
        "# Aca vemos que esta balanceado\n",
        "y_train_balanced.value_counts()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Neutral    525\n",
              "Good       525\n",
              "Bad        525\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhwgMg_A-Ug9",
        "outputId": "e19fb8f6-bd87-474f-d2a3-c224cef1c178"
      },
      "source": [
        "preprocessing_transformer = ColumnTransformer(\n",
        "    transformers=[\n",
        "                    ('bow', CountVectorizer(\n",
        "                    tokenizer=LemmaTokenizer(),\n",
        "                    lowercase=True,  # Transformamos todo a min煤suculas.\n",
        "                    max_features=10000,  # Dejamos solo las 10000 palabras m谩s frecuentes,\n",
        "                    ngram_range=(1, 2)\n",
        "                    ), \n",
        "                    'history_text'),\n",
        "                    ('scaler', MinMaxScaler(), \n",
        "                    ['intelligence_score', 'strength_score', 'speed_score', 'durability_score', 'power_score', 'combat_score'])\n",
        "                  ]\n",
        ")\n",
        "\n",
        "pipe = Pipeline(steps=[\n",
        "                       ('preprocessing', preprocessing_transformer),\n",
        "                       ('clf', MultinomialNB() )\n",
        "                       ]\n",
        "                )\n",
        "# Probamos desbalanceado\n",
        "pipe.fit(X_train, y_train)\n",
        "y_pred = pipe.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         Bad       0.52      0.59      0.55       133\n",
            "        Good       0.70      0.71      0.71       218\n",
            "     Neutral       0.08      0.03      0.04        35\n",
            "\n",
            "    accuracy                           0.61       386\n",
            "   macro avg       0.43      0.44      0.43       386\n",
            "weighted avg       0.58      0.61      0.59       386\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJg_kqy67p_g",
        "outputId": "33170623-1f47-4ca2-fa5e-f3ef9ac040c8"
      },
      "source": [
        "# Balanceado\n",
        "pipe.fit(X_train_balanced, y_train_balanced)\n",
        "y_pred = pipe.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         Bad       0.60      0.56      0.58       133\n",
            "        Good       0.69      0.79      0.73       218\n",
            "     Neutral       0.36      0.11      0.17        35\n",
            "\n",
            "    accuracy                           0.65       386\n",
            "   macro avg       0.55      0.49      0.50       386\n",
            "weighted avg       0.63      0.65      0.63       386\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZJBWQ5XjXRR"
      },
      "source": [
        "Podemos notar que al balancear las clases tenemos mejores resultados, sobretodo en la clase neutral"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfm7I2B7_rfB"
      },
      "source": [
        "## 1.3 Entrenamiento con Grid Search [2 Puntos]\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media1.tenor.com/images/70fdfeea52a8e2e4505498c230a0d2f9/tenor.gif?itemid=5134219\" width=\"250\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14siiavzK67p"
      },
      "source": [
        "No conformes con el rendimiento obtenido en la secci贸n 1.2, el cuerpo docente les pide que realicen una b煤squeda de grilla de los mejores hiperpar谩metros utilizando `GridSearchCV`. \n",
        "\n",
        "Para esto, se le solicita que defina al menos 3 configuraciones de hiperpar谩metros e intente obtener mejores resultados que los obtenidos en la secci贸n anterior. \n",
        "\n",
        "A continuaci贸n, un ejemplo de parametros para GridSearch:\n",
        "\n",
        "```python\n",
        "params = [\n",
        "  # esta es la configuraci贸n de una busqueda en particular\n",
        "  # con el clasificador classificator1.\n",
        "  # en este caso se entrenar谩 el clasificador 1 con combinaciones de todos los \n",
        "  # par谩metros de bow__max_features, bow__ngram_range, clf__n_estimators \n",
        "  # y se seleccionar谩 la mejor combinaci贸n.\n",
        "  {\n",
        "  'bow__max_features': [5000, 10000, ...],\n",
        "  'bow__ngram_range': [(1, 1), (1, 2), (1,3)],\n",
        "  ...,\n",
        "  'clf': [classificator1()],\n",
        "  'clf__n_estimators': [200]\n",
        "  },\n",
        "  # esta es la configuraci贸n de una busqueda en particular\n",
        "  # con el clasificador classificator2:\n",
        "  {'clf': [classificator2()],\n",
        "   'clf__penalty': ['ovr'],\n",
        "   'clf__multi_class': ['liblinear']\n",
        "  },\n",
        "  # esta es la configuraci贸n de una busqueda en particular\n",
        "  # con el clasificador classificator3:\n",
        "  {'clf': [classificator3()]\n",
        "  }\n",
        "             ]\n",
        "```\n",
        "\n",
        "Adem谩s, note que puede obtener todos los par谩metros configurables de un pipeline invocando sobre este el m茅todo `.get_params()`.\n",
        "\n",
        "**Nota:** El GridSearch puede tomar tiempos de b煤squeda exorbitantes, por lo que se le recomienda dejar corriendo el c贸digo y tomarse un tecito."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7HkTmLEJZ4g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84fa7cf4-8476-4ce0-c4a6-bcaa494c7898"
      },
      "source": [
        "MAX_FEATURES = [5000, 10000, 15000]\n",
        "NGRAM_RANGE = [(1,1), (1,2), (1,3)]\n",
        "FIT_PRIOR = [True, False]\n",
        "\n",
        "param_grid = [\n",
        "    {\n",
        "        'preprocessing__bow__max_features': MAX_FEATURES,\n",
        "        'preprocessing__bow__ngram_range': NGRAM_RANGE,\n",
        "        'clf__fit_prior': FIT_PRIOR\n",
        "    }\n",
        "]\n",
        "\n",
        "grid = GridSearchCV(pipe, n_jobs=1, param_grid=param_grid)\n",
        "grid.fit(X_train, y_train)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('preprocessing',\n",
              "                                        ColumnTransformer(n_jobs=None,\n",
              "                                                          remainder='drop',\n",
              "                                                          sparse_threshold=0.3,\n",
              "                                                          transformer_weights=None,\n",
              "                                                          transformers=[('bow',\n",
              "                                                                         CountVectorizer(analyzer='word',\n",
              "                                                                                         binary=False,\n",
              "                                                                                         decode_error='strict',\n",
              "                                                                                         dtype=<class 'numpy.int64'>,\n",
              "                                                                                         encoding='utf-8',\n",
              "                                                                                         input='content',\n",
              "                                                                                         lowercase=True,\n",
              "                                                                                         ma...\n",
              "                                                          verbose=False)),\n",
              "                                       ('clf',\n",
              "                                        MultinomialNB(alpha=1.0,\n",
              "                                                      class_prior=None,\n",
              "                                                      fit_prior=True))],\n",
              "                                verbose=False),\n",
              "             iid='deprecated', n_jobs=1,\n",
              "             param_grid=[{'clf__fit_prior': [True, False],\n",
              "                          'preprocessing__bow__max_features': [5000, 10000,\n",
              "                                                               15000],\n",
              "                          'preprocessing__bow__ngram_range': [(1, 1), (1, 2),\n",
              "                                                              (1, 3)]}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OP99gl-NB0ip",
        "outputId": "ce647f47-b596-4cf2-9f79-ecbb63fe4974"
      },
      "source": [
        "grid.cv_results_"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mean_fit_time': array([11.35334992, 12.9886426 , 15.67488885, 11.53019567, 13.00671043,\n",
              "        15.66645136, 11.41127267, 13.0250483 , 15.60156465, 11.32597909,\n",
              "        13.09207902, 15.72181764, 11.31367903, 13.03388176, 15.54173608,\n",
              "        11.38321776, 13.00598016, 15.61596208]),\n",
              " 'mean_score_time': array([2.82793999, 2.8926703 , 2.95835223, 2.898067  , 2.89173384,\n",
              "        2.97508488, 2.82097616, 2.89638553, 2.96557498, 2.84230852,\n",
              "        2.90539422, 2.99474072, 2.81216578, 2.89034452, 2.96713762,\n",
              "        2.81964698, 2.89325004, 2.97543402]),\n",
              " 'mean_test_score': array([0.62736189, 0.62401614, 0.62625078, 0.64404718, 0.64292986,\n",
              "        0.64848541, 0.65962135, 0.64849783, 0.64962135, 0.61845438,\n",
              "        0.60735568, 0.61180633, 0.6262694 , 0.62956549, 0.62734947,\n",
              "        0.64961515, 0.63515208, 0.6451707 ]),\n",
              " 'param_clf__fit_prior': masked_array(data=[True, True, True, True, True, True, True, True, True,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_preprocessing__bow__max_features': masked_array(data=[5000, 5000, 5000, 10000, 10000, 10000, 15000, 15000,\n",
              "                    15000, 5000, 5000, 5000, 10000, 10000, 10000, 15000,\n",
              "                    15000, 15000],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_preprocessing__bow__ngram_range': masked_array(data=[(1, 1), (1, 2), (1, 3), (1, 1), (1, 2), (1, 3), (1, 1),\n",
              "                    (1, 2), (1, 3), (1, 1), (1, 2), (1, 3), (1, 1), (1, 2),\n",
              "                    (1, 3), (1, 1), (1, 2), (1, 3)],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'params': [{'clf__fit_prior': True,\n",
              "   'preprocessing__bow__max_features': 5000,\n",
              "   'preprocessing__bow__ngram_range': (1, 1)},\n",
              "  {'clf__fit_prior': True,\n",
              "   'preprocessing__bow__max_features': 5000,\n",
              "   'preprocessing__bow__ngram_range': (1, 2)},\n",
              "  {'clf__fit_prior': True,\n",
              "   'preprocessing__bow__max_features': 5000,\n",
              "   'preprocessing__bow__ngram_range': (1, 3)},\n",
              "  {'clf__fit_prior': True,\n",
              "   'preprocessing__bow__max_features': 10000,\n",
              "   'preprocessing__bow__ngram_range': (1, 1)},\n",
              "  {'clf__fit_prior': True,\n",
              "   'preprocessing__bow__max_features': 10000,\n",
              "   'preprocessing__bow__ngram_range': (1, 2)},\n",
              "  {'clf__fit_prior': True,\n",
              "   'preprocessing__bow__max_features': 10000,\n",
              "   'preprocessing__bow__ngram_range': (1, 3)},\n",
              "  {'clf__fit_prior': True,\n",
              "   'preprocessing__bow__max_features': 15000,\n",
              "   'preprocessing__bow__ngram_range': (1, 1)},\n",
              "  {'clf__fit_prior': True,\n",
              "   'preprocessing__bow__max_features': 15000,\n",
              "   'preprocessing__bow__ngram_range': (1, 2)},\n",
              "  {'clf__fit_prior': True,\n",
              "   'preprocessing__bow__max_features': 15000,\n",
              "   'preprocessing__bow__ngram_range': (1, 3)},\n",
              "  {'clf__fit_prior': False,\n",
              "   'preprocessing__bow__max_features': 5000,\n",
              "   'preprocessing__bow__ngram_range': (1, 1)},\n",
              "  {'clf__fit_prior': False,\n",
              "   'preprocessing__bow__max_features': 5000,\n",
              "   'preprocessing__bow__ngram_range': (1, 2)},\n",
              "  {'clf__fit_prior': False,\n",
              "   'preprocessing__bow__max_features': 5000,\n",
              "   'preprocessing__bow__ngram_range': (1, 3)},\n",
              "  {'clf__fit_prior': False,\n",
              "   'preprocessing__bow__max_features': 10000,\n",
              "   'preprocessing__bow__ngram_range': (1, 1)},\n",
              "  {'clf__fit_prior': False,\n",
              "   'preprocessing__bow__max_features': 10000,\n",
              "   'preprocessing__bow__ngram_range': (1, 2)},\n",
              "  {'clf__fit_prior': False,\n",
              "   'preprocessing__bow__max_features': 10000,\n",
              "   'preprocessing__bow__ngram_range': (1, 3)},\n",
              "  {'clf__fit_prior': False,\n",
              "   'preprocessing__bow__max_features': 15000,\n",
              "   'preprocessing__bow__ngram_range': (1, 1)},\n",
              "  {'clf__fit_prior': False,\n",
              "   'preprocessing__bow__max_features': 15000,\n",
              "   'preprocessing__bow__ngram_range': (1, 2)},\n",
              "  {'clf__fit_prior': False,\n",
              "   'preprocessing__bow__max_features': 15000,\n",
              "   'preprocessing__bow__ngram_range': (1, 3)}],\n",
              " 'rank_test_score': array([11, 15, 14,  7,  8,  5,  1,  4,  2, 16, 18, 17, 13, 10, 12,  3,  9,\n",
              "         6], dtype=int32),\n",
              " 'split0_test_score': array([0.59444444, 0.57222222, 0.58333333, 0.63888889, 0.58888889,\n",
              "        0.6       , 0.65      , 0.62777778, 0.61666667, 0.58333333,\n",
              "        0.57222222, 0.56666667, 0.60555556, 0.58888889, 0.57222222,\n",
              "        0.63888889, 0.59444444, 0.6       ]),\n",
              " 'split1_test_score': array([0.61111111, 0.61111111, 0.60555556, 0.61111111, 0.63888889,\n",
              "        0.64444444, 0.63333333, 0.62222222, 0.62777778, 0.60555556,\n",
              "        0.58888889, 0.59444444, 0.58888889, 0.63888889, 0.63333333,\n",
              "        0.62222222, 0.61111111, 0.63333333]),\n",
              " 'split2_test_score': array([0.65555556, 0.67222222, 0.66666667, 0.67222222, 0.67777778,\n",
              "        0.67222222, 0.66666667, 0.67777778, 0.67777778, 0.64444444,\n",
              "        0.63333333, 0.63888889, 0.66111111, 0.64444444, 0.63888889,\n",
              "        0.66666667, 0.67222222, 0.67222222]),\n",
              " 'split3_test_score': array([0.65      , 0.65      , 0.65      , 0.65555556, 0.67222222,\n",
              "        0.68888889, 0.68888889, 0.66666667, 0.66666667, 0.65      ,\n",
              "        0.62222222, 0.63333333, 0.63333333, 0.66666667, 0.67777778,\n",
              "        0.66666667, 0.66111111, 0.66666667]),\n",
              " 'split4_test_score': array([0.62569832, 0.61452514, 0.62569832, 0.6424581 , 0.63687151,\n",
              "        0.63687151, 0.65921788, 0.64804469, 0.65921788, 0.60893855,\n",
              "        0.62011173, 0.62569832, 0.6424581 , 0.60893855, 0.61452514,\n",
              "        0.65363128, 0.63687151, 0.65363128]),\n",
              " 'std_fit_time': array([0.17076712, 0.28074693, 0.37258161, 0.30241825, 0.25358515,\n",
              "        0.26003492, 0.2598707 , 0.26815769, 0.3294906 , 0.18235748,\n",
              "        0.29340779, 0.35186939, 0.23606583, 0.23660171, 0.34167442,\n",
              "        0.2637196 , 0.21005373, 0.33464555]),\n",
              " 'std_score_time': array([0.19413924, 0.22680918, 0.21922999, 0.2000463 , 0.21363164,\n",
              "        0.22165262, 0.23420569, 0.21097316, 0.22058919, 0.20571325,\n",
              "        0.21367643, 0.21154516, 0.22948277, 0.22703206, 0.23066018,\n",
              "        0.18790901, 0.2210392 , 0.22532739]),\n",
              " 'std_test_score': array([0.0230555 , 0.0344622 , 0.02989306, 0.02019997, 0.03176753,\n",
              "        0.03065265, 0.01838488, 0.02148188, 0.0234033 , 0.0251437 ,\n",
              "        0.02295191, 0.02730893, 0.02589318, 0.02744035, 0.03439609,\n",
              "        0.01710592, 0.02927833, 0.02625246])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iUUmpd1IpNa",
        "outputId": "e1405cf6-d651-4191-8606-392833cc6ff3"
      },
      "source": [
        "\n",
        "over = RandomOverSampler(random_state=1)\n",
        "X_balanced, y_balanced = over.fit_resample(X, y)\n",
        "X_balanced = pd.DataFrame(X_train_balanced)\n",
        "y_balanced = pd.Series(y_train_balanced)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x31Nub9WGdy3",
        "outputId": "1bfada4d-93db-448b-e20d-979522a2a26b"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "MAX_FEATURES = [5000, 10000, 15000]\n",
        "NGRAM_RANGE = [(1,1), (1,2), (1,3)]\n",
        "FIT_PRIOR = [True, False]\n",
        "\n",
        "param_grid = [\n",
        "    {\n",
        "        'preprocessing__bow__max_features': MAX_FEATURES,\n",
        "        'preprocessing__bow__ngram_range': NGRAM_RANGE,\n",
        "        'clf__fit_prior': FIT_PRIOR\n",
        "    },\n",
        "    {\n",
        "        'clf': [LogisticRegression()],\n",
        "        'clf__multi_class': ['multinomial']\n",
        "    },\n",
        "    {\n",
        "        'clf': [DecisionTreeClassifier()],\n",
        "        'clf__criterion': ['gini', 'entropy']\n",
        "    }\n",
        "]\n",
        "\n",
        "grid_2 = GridSearchCV(pipe, n_jobs=1, param_grid=param_grid)\n",
        "grid_2.fit(X_balanced, y_balanced)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('preprocessing',\n",
              "                                        ColumnTransformer(n_jobs=None,\n",
              "                                                          remainder='drop',\n",
              "                                                          sparse_threshold=0.3,\n",
              "                                                          transformer_weights=None,\n",
              "                                                          transformers=[('bow',\n",
              "                                                                         CountVectorizer(analyzer='word',\n",
              "                                                                                         binary=False,\n",
              "                                                                                         decode_error='strict',\n",
              "                                                                                         dtype=<class 'numpy.int64'>,\n",
              "                                                                                         encoding='utf-8',\n",
              "                                                                                         input='content',\n",
              "                                                                                         lowercase=True,\n",
              "                                                                                         ma...\n",
              "                                                         criterion='gini',\n",
              "                                                         max_depth=None,\n",
              "                                                         max_features=None,\n",
              "                                                         max_leaf_nodes=None,\n",
              "                                                         min_impurity_decrease=0.0,\n",
              "                                                         min_impurity_split=None,\n",
              "                                                         min_samples_leaf=1,\n",
              "                                                         min_samples_split=2,\n",
              "                                                         min_weight_fraction_leaf=0.0,\n",
              "                                                         presort='deprecated',\n",
              "                                                         random_state=None,\n",
              "                                                         splitter='best')],\n",
              "                          'clf__criterion': ['gini', 'entropy']}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        },
        "id": "HH0v2F8oUddU",
        "outputId": "7c5f334e-f27f-4f34-c9af-8fa92c526f04"
      },
      "source": [
        "pd.concat([pd.DataFrame(grid_2.cv_results_[\"params\"]),pd.DataFrame(grid_2.cv_results_[\"mean_test_score\"], columns=[\"Accuracy\"])],axis=1)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clf__fit_prior</th>\n",
              "      <th>preprocessing__bow__max_features</th>\n",
              "      <th>preprocessing__bow__ngram_range</th>\n",
              "      <th>clf</th>\n",
              "      <th>clf__multi_class</th>\n",
              "      <th>clf__criterion</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>True</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.770159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>True</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.716825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>True</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>(1, 3)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.715556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>True</td>\n",
              "      <td>10000.0</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.831111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>True</td>\n",
              "      <td>10000.0</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.765079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>True</td>\n",
              "      <td>10000.0</td>\n",
              "      <td>(1, 3)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.742222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>True</td>\n",
              "      <td>15000.0</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.840000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>True</td>\n",
              "      <td>15000.0</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.765079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>True</td>\n",
              "      <td>15000.0</td>\n",
              "      <td>(1, 3)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.751111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>False</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.770159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>False</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.716825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>False</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>(1, 3)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.715556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>False</td>\n",
              "      <td>10000.0</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.831111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>False</td>\n",
              "      <td>10000.0</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.765079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>False</td>\n",
              "      <td>10000.0</td>\n",
              "      <td>(1, 3)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.742222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>False</td>\n",
              "      <td>15000.0</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.840000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>False</td>\n",
              "      <td>15000.0</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.765079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>False</td>\n",
              "      <td>15000.0</td>\n",
              "      <td>(1, 3)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.751111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
              "      <td>multinomial</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.885714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>DecisionTreeClassifier(ccp_alpha=0.0, class_we...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>gini</td>\n",
              "      <td>0.806349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>DecisionTreeClassifier(ccp_alpha=0.0, class_we...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>entropy</td>\n",
              "      <td>0.794921</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   clf__fit_prior  preprocessing__bow__max_features  ... clf__criterion  Accuracy\n",
              "0            True                            5000.0  ...            NaN  0.770159\n",
              "1            True                            5000.0  ...            NaN  0.716825\n",
              "2            True                            5000.0  ...            NaN  0.715556\n",
              "3            True                           10000.0  ...            NaN  0.831111\n",
              "4            True                           10000.0  ...            NaN  0.765079\n",
              "5            True                           10000.0  ...            NaN  0.742222\n",
              "6            True                           15000.0  ...            NaN  0.840000\n",
              "7            True                           15000.0  ...            NaN  0.765079\n",
              "8            True                           15000.0  ...            NaN  0.751111\n",
              "9           False                            5000.0  ...            NaN  0.770159\n",
              "10          False                            5000.0  ...            NaN  0.716825\n",
              "11          False                            5000.0  ...            NaN  0.715556\n",
              "12          False                           10000.0  ...            NaN  0.831111\n",
              "13          False                           10000.0  ...            NaN  0.765079\n",
              "14          False                           10000.0  ...            NaN  0.742222\n",
              "15          False                           15000.0  ...            NaN  0.840000\n",
              "16          False                           15000.0  ...            NaN  0.765079\n",
              "17          False                           15000.0  ...            NaN  0.751111\n",
              "18            NaN                               NaN  ...            NaN  0.885714\n",
              "19            NaN                               NaN  ...           gini  0.806349\n",
              "20            NaN                               NaN  ...        entropy  0.794921\n",
              "\n",
              "[21 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItbNfY9tVCtc",
        "outputId": "26780706-9df2-4779-ca1e-cc1ba98a97e5"
      },
      "source": [
        "MAX_FEATURES = [5000, 10000, 15000]\n",
        "NGRAM_RANGE = [(1,1), (1,2), (1,3)]\n",
        "\n",
        "param_grid = [\n",
        "    {\n",
        "        'preprocessing__bow__max_features': MAX_FEATURES,\n",
        "        'preprocessing__bow__ngram_range': NGRAM_RANGE,\n",
        "        'clf': [LogisticRegression()],\n",
        "        'clf__multi_class': ['multinomial']\n",
        "    }\n",
        "]\n",
        "\n",
        "grid_3 = GridSearchCV(pipe, n_jobs=1, param_grid=param_grid)\n",
        "grid_3.fit(X_balanced, y_balanced)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('preprocessing',\n",
              "                                        ColumnTransformer(n_jobs=None,\n",
              "                                                          remainder='drop',\n",
              "                                                          sparse_threshold=0.3,\n",
              "                                                          transformer_weights=None,\n",
              "                                                          transformers=[('bow',\n",
              "                                                                         CountVectorizer(analyzer='word',\n",
              "                                                                                         binary=False,\n",
              "                                                                                         decode_error='strict',\n",
              "                                                                                         dtype=<class 'numpy.int64'>,\n",
              "                                                                                         encoding='utf-8',\n",
              "                                                                                         input='content',\n",
              "                                                                                         lowercase=True,\n",
              "                                                                                         ma...\n",
              "                                                     multi_class='multinomial',\n",
              "                                                     n_jobs=None, penalty='l2',\n",
              "                                                     random_state=None,\n",
              "                                                     solver='lbfgs', tol=0.0001,\n",
              "                                                     verbose=0,\n",
              "                                                     warm_start=False)],\n",
              "                          'clf__multi_class': ['multinomial'],\n",
              "                          'preprocessing__bow__max_features': [5000, 10000,\n",
              "                                                               15000],\n",
              "                          'preprocessing__bow__ngram_range': [(1, 1), (1, 2),\n",
              "                                                              (1, 3)]}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "XSarZnmWbRU3",
        "outputId": "a7d08e83-e5cf-49db-f184-09e92530f799"
      },
      "source": [
        "pd.concat([pd.DataFrame(grid_3.cv_results_[\"params\"]),pd.DataFrame(grid_3.cv_results_[\"mean_test_score\"], columns=[\"Accuracy\"])],axis=1)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clf</th>\n",
              "      <th>clf__multi_class</th>\n",
              "      <th>preprocessing__bow__max_features</th>\n",
              "      <th>preprocessing__bow__ngram_range</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
              "      <td>multinomial</td>\n",
              "      <td>5000</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>0.871111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
              "      <td>multinomial</td>\n",
              "      <td>5000</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>0.873016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
              "      <td>multinomial</td>\n",
              "      <td>5000</td>\n",
              "      <td>(1, 3)</td>\n",
              "      <td>0.866667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
              "      <td>multinomial</td>\n",
              "      <td>10000</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>0.874286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
              "      <td>multinomial</td>\n",
              "      <td>10000</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>0.885714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
              "      <td>multinomial</td>\n",
              "      <td>10000</td>\n",
              "      <td>(1, 3)</td>\n",
              "      <td>0.883175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
              "      <td>multinomial</td>\n",
              "      <td>15000</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>0.869841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
              "      <td>multinomial</td>\n",
              "      <td>15000</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>0.880000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
              "      <td>multinomial</td>\n",
              "      <td>15000</td>\n",
              "      <td>(1, 3)</td>\n",
              "      <td>0.881905</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 clf  ...  Accuracy\n",
              "0  LogisticRegression(C=1.0, class_weight=None, d...  ...  0.871111\n",
              "1  LogisticRegression(C=1.0, class_weight=None, d...  ...  0.873016\n",
              "2  LogisticRegression(C=1.0, class_weight=None, d...  ...  0.866667\n",
              "3  LogisticRegression(C=1.0, class_weight=None, d...  ...  0.874286\n",
              "4  LogisticRegression(C=1.0, class_weight=None, d...  ...  0.885714\n",
              "5  LogisticRegression(C=1.0, class_weight=None, d...  ...  0.883175\n",
              "6  LogisticRegression(C=1.0, class_weight=None, d...  ...  0.869841\n",
              "7  LogisticRegression(C=1.0, class_weight=None, d...  ...  0.880000\n",
              "8  LogisticRegression(C=1.0, class_weight=None, d...  ...  0.881905\n",
              "\n",
              "[9 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ag2XHuGZbUbx",
        "outputId": "a91adf50-9ecc-4540-c0c8-141dce5917ad"
      },
      "source": [
        "grid_3.best_estimator_"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('preprocessing',\n",
              "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
              "                                   sparse_threshold=0.3,\n",
              "                                   transformer_weights=None,\n",
              "                                   transformers=[('bow',\n",
              "                                                  CountVectorizer(analyzer='word',\n",
              "                                                                  binary=False,\n",
              "                                                                  decode_error='strict',\n",
              "                                                                  dtype=<class 'numpy.int64'>,\n",
              "                                                                  encoding='utf-8',\n",
              "                                                                  input='content',\n",
              "                                                                  lowercase=True,\n",
              "                                                                  max_df=1.0,\n",
              "                                                                  max_features=10000,\n",
              "                                                                  min_df=1,\n",
              "                                                                  ngram_rang...\n",
              "                                                   'strength_score',\n",
              "                                                   'speed_score',\n",
              "                                                   'durability_score',\n",
              "                                                   'power_score',\n",
              "                                                   'combat_score'])],\n",
              "                                   verbose=False)),\n",
              "                ('clf',\n",
              "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    l1_ratio=None, max_iter=100,\n",
              "                                    multi_class='multinomial', n_jobs=None,\n",
              "                                    penalty='l2', random_state=None,\n",
              "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                    warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9TXQK3Hi0Kz"
      },
      "source": [
        "#### 1.3.1 Mejor configuraci贸n [0.5]\n",
        "\n",
        "Comente cual fue la mejor configuraci贸n obtenida por Grid Search y por qu茅 cree que esta fue la mejor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzMu7kU_jJsB"
      },
      "source": [
        "Podemos observar que en el primer Grid Search que se computo el mejor resultado para el Accuracy se obtuvo con el modelo de clasificaci贸n Logit en su versi贸n multiclase, y luego en el segundo Grid Search que se computo utilizando este clasificador, se observa que los mejores parametros para el preprocesamiento de texto son un ngram_range = (1,2) y max_features = 10000.\n",
        "Nos resulta extra帽o que el modelo Logit sea el que tiene mejor desempe帽o, ya que este asume que la distribuci贸n de los atributos es gaussiana y esto es un poco contraintuitivo, ya que los artistas al crear un personaje probablemente no piensen en que los personajes distribuyan de forma gaussiana, en el sentido de que tengan atributos similares para cada clase, es decir, un artista no se pone a pensar cuales son los atributos cl谩sicos para un hereo, villano o neutral a la hora de crearlo. Posiblemente Logit sea el que mejor funciona en este caso debido a la forma de los datos, que se encuentran entre 0 y 1 debido a la normalizaci贸n, lo que puede generar que el output de cada observacion este entre 0 y 1, y sabemos que Logit es un modelo que funciona bastante bien cuando la variable de salida es binaria (0 o 1)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmQUw2aZ_6z2"
      },
      "source": [
        "## 1.4 Predicci贸n del datos sin etiquetado\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://pbs.twimg.com/media/DolotxUUYAAbg7f.jpg\" width=\"350\">\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cj0ERBgTBFWN"
      },
      "source": [
        "Llego el momento de predecir cual es la verdadera alineaci贸n de `Batcow`. Para esto, deben escoger el mejor pipeline obtenido en las secciones anteriores y predecir la alineaci贸n de todos los datos presentes en `df_comics_no_label`.Luego, anexen las alineaciones obtenidas a su correspondiente columna  del dataframe original (atributo `alignment`) y busquen a los flamantes personajes `Batcow`, `Vergil`, y `Gorilla Girl'. Presente los resultados en un `Dataframe`.\n",
        "\n",
        "**Nota:** Recuerde que pueden existir campos vacios en `history_text`, por lo que se les recomienda borrar los nan."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3irRF18cj_E"
      },
      "source": [
        "df_comics_no_label = df_comics_no_label.dropna(subset=['history_text'])\n",
        "df_comics_no_label = df_comics_no_label.drop_duplicates()\n",
        "X_predict = df_comics_no_label[['history_text','intelligence_score', 'strength_score', 'speed_score', 'durability_score', 'power_score', 'combat_score']]"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-mizeQZaLUY"
      },
      "source": [
        "preprocessing_transformer = ColumnTransformer(\n",
        "    transformers=[\n",
        "                    ('bow', CountVectorizer(\n",
        "                    tokenizer=LemmaTokenizer(),\n",
        "                    lowercase=True,  # Transformamos todo a min煤suculas.\n",
        "                    max_features=10000,  # Dejamos solo las 10000 palabras m谩s frecuentes,\n",
        "                    ngram_range=(1, 2)\n",
        "                    ), \n",
        "                    'history_text'),\n",
        "                    ('scaler', MinMaxScaler(), \n",
        "                    ['intelligence_score', 'strength_score', 'speed_score', 'durability_score', 'power_score', 'combat_score'])\n",
        "                  ]\n",
        ")\n",
        "\n",
        "pipe_logit = Pipeline(steps=[\n",
        "                       ('preprocessing', preprocessing_transformer),\n",
        "                       ('clf', LogisticRegression(multi_class = 'multinomial', max_iter = 1000))\n",
        "                       ]\n",
        "                )\n",
        "\n",
        "pipe_logit.fit(X_balanced, y_balanced)\n",
        "y_pred = pipe_logit.predict(X_predict)"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auVQl1WTdKKI"
      },
      "source": [
        "df_comics_no_label['alignment'] = y_pred"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "P-Sss4wLdcQc",
        "outputId": "9cfcda14-cc0c-42a0-9566-83c30d175ebd"
      },
      "source": [
        "entes_poderosos = ['Batcow', 'Vergil', 'Gorilla Girl']\n",
        "  \n",
        "df_comics_no_label[df_comics_no_label['name'].isin(entes_poderosos)]"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>name</th>\n",
              "      <th>real_name</th>\n",
              "      <th>full_name</th>\n",
              "      <th>overall_score</th>\n",
              "      <th>history_text</th>\n",
              "      <th>powers_text</th>\n",
              "      <th>intelligence_score</th>\n",
              "      <th>strength_score</th>\n",
              "      <th>speed_score</th>\n",
              "      <th>durability_score</th>\n",
              "      <th>power_score</th>\n",
              "      <th>combat_score</th>\n",
              "      <th>superpowers</th>\n",
              "      <th>alter_egos</th>\n",
              "      <th>aliases</th>\n",
              "      <th>place_of_birth</th>\n",
              "      <th>first_appearance</th>\n",
              "      <th>creator</th>\n",
              "      <th>alignment</th>\n",
              "      <th>occupation</th>\n",
              "      <th>base</th>\n",
              "      <th>teams</th>\n",
              "      <th>relatives</th>\n",
              "      <th>gender</th>\n",
              "      <th>type_race</th>\n",
              "      <th>height</th>\n",
              "      <th>weight</th>\n",
              "      <th>eye_color</th>\n",
              "      <th>hair_color</th>\n",
              "      <th>skin_color</th>\n",
              "      <th>img</th>\n",
              "      <th>has_electrokinesis</th>\n",
              "      <th>has_energy_constructs</th>\n",
              "      <th>has_mind_control_resistance</th>\n",
              "      <th>has_matter_manipulation</th>\n",
              "      <th>has_telepathy_resistance</th>\n",
              "      <th>has_mind_control</th>\n",
              "      <th>has_enhanced_hearing</th>\n",
              "      <th>has_dimensional_travel</th>\n",
              "      <th>...</th>\n",
              "      <th>has_fire_resistance</th>\n",
              "      <th>has_fire_control</th>\n",
              "      <th>has_dexterity</th>\n",
              "      <th>has_reality_warping</th>\n",
              "      <th>has_illusions</th>\n",
              "      <th>has_energy_beams</th>\n",
              "      <th>has_peak_human_condition</th>\n",
              "      <th>has_shapeshifting</th>\n",
              "      <th>has_heat_resistance</th>\n",
              "      <th>has_jump</th>\n",
              "      <th>has_self-sustenance</th>\n",
              "      <th>has_energy_absorption</th>\n",
              "      <th>has_cold_resistance</th>\n",
              "      <th>has_magic</th>\n",
              "      <th>has_telekinesis</th>\n",
              "      <th>has_toxin_and_disease_resistance</th>\n",
              "      <th>has_telepathy</th>\n",
              "      <th>has_regeneration</th>\n",
              "      <th>has_immortality</th>\n",
              "      <th>has_teleportation</th>\n",
              "      <th>has_force_fields</th>\n",
              "      <th>has_energy_manipulation</th>\n",
              "      <th>has_endurance</th>\n",
              "      <th>has_longevity</th>\n",
              "      <th>has_weapon-based_powers</th>\n",
              "      <th>has_energy_blasts</th>\n",
              "      <th>has_enhanced_senses</th>\n",
              "      <th>has_invulnerability</th>\n",
              "      <th>has_stealth</th>\n",
              "      <th>has_marksmanship</th>\n",
              "      <th>has_flight</th>\n",
              "      <th>has_accelerated_healing</th>\n",
              "      <th>has_weapons_master</th>\n",
              "      <th>has_intelligence</th>\n",
              "      <th>has_reflexes</th>\n",
              "      <th>has_super_speed</th>\n",
              "      <th>has_durability</th>\n",
              "      <th>has_stamina</th>\n",
              "      <th>has_agility</th>\n",
              "      <th>has_super_strength</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>122</td>\n",
              "      <td>Batcow</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>3</td>\n",
              "      <td>Bat-Cow was originally a cow that was found by...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>70</td>\n",
              "      <td>10</td>\n",
              "      <td>25</td>\n",
              "      <td>20</td>\n",
              "      <td>10</td>\n",
              "      <td>20</td>\n",
              "      <td>['Animal Attributes', 'Animal Oriented Powers']</td>\n",
              "      <td>['Milkman Man', 'Red Torpedo', 'Red Volcano']</td>\n",
              "      <td>[\"Battlin' Bovine\"]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>DC Comics</td>\n",
              "      <td>Good</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Wayne Manor</td>\n",
              "      <td>[]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Animal</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>/pictures2/portraits/11/050/13425.jpg?v=157425...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>529</td>\n",
              "      <td>Gorilla Girl</td>\n",
              "      <td>Fahnbullah Eddy</td>\n",
              "      <td>Fahnbullah Eddy</td>\n",
              "      <td>7</td>\n",
              "      <td>A carnival performer with the ability to turn ...</td>\n",
              "      <td>Gorilla Girl can transform into a talking gori...</td>\n",
              "      <td>90</td>\n",
              "      <td>35</td>\n",
              "      <td>60</td>\n",
              "      <td>60</td>\n",
              "      <td>45</td>\n",
              "      <td>100</td>\n",
              "      <td>['Agility', 'Jump', 'Super Strength', 'Transfo...</td>\n",
              "      <td>[]</td>\n",
              "      <td>['Gorilla Woman']</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Marvel Comics</td>\n",
              "      <td>Good</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>1368</td>\n",
              "      <td>Vergil</td>\n",
              "      <td>Vergil Sparda</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16</td>\n",
              "      <td>Vergil, later also known as Nelo Angelo, is on...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>90</td>\n",
              "      <td>75</td>\n",
              "      <td>95</td>\n",
              "      <td>90</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>['Accelerated Healing', 'Agility', 'Duplicatio...</td>\n",
              "      <td>[]</td>\n",
              "      <td>['Gilver, Nelo Angelo, Son of Sparda, The Dark...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Devil May Cry</td>\n",
              "      <td>Capcom</td>\n",
              "      <td>Good</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>Sparda (father) ,Eva (mother) ,Dante (Brother)...</td>\n",
              "      <td>Male</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6'3  191 cm</td>\n",
              "      <td>207 lb  93 kg</td>\n",
              "      <td>Blue</td>\n",
              "      <td>White</td>\n",
              "      <td>NaN</td>\n",
              "      <td>/pictures2/portraits/10/050/11657.jpg?v=154990...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows  82 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    Unnamed: 0          name  ... has_agility has_super_strength\n",
              "16         122        Batcow  ...         0.0                0.0\n",
              "40         529  Gorilla Girl  ...         1.0                1.0\n",
              "78        1368        Vergil  ...         1.0                1.0\n",
              "\n",
              "[3 rows x 82 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDhCWnJReUMQ"
      },
      "source": [
        "Se observa que los tres entes poderosos son clasificados como buenos h茅roes :D.\n",
        "Aplicando san Google pudimos confirmar que tanto Batcow como Gorilla Girl son efectivamente h茅roes, pero por otro lado, Vergil al ser un antagonista del juego Devil May Cry probablemente sea villano (o por lo menos no un h茅roe bueno).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BF1beoqllTj"
      },
      "source": [
        "### Wordclouds [Opcional- 0,5] \n",
        "\n",
        "Una buena pero informal forma de comunicar los resultados del trabajo con texto es generar Wordclouds. Este tipo de visualizaciones nos informan de forma gr谩fica cuales son las palabras m谩s frecuentes seg煤n el tama帽o de estas al ser posicionadas en un lienzo.\n",
        "<center>\n",
        "<img alt='Ejemplo de una Wordcloud de Starwars' src='https://amueller.github.io/word_cloud/_images/sphx_glr_a_new_hope_001.png' width=400/>\n",
        "\n",
        "Ejemplo de una Wordcloud de Starwars\n",
        "\n",
        "</center>\n",
        "Dicho esto, como equipo docente nos encantar铆a conocer cuales son las palabras que caracterizan tanto a heroes como neutrales y a villanos y cuales son sus principales diferencias. Por esta raz贸n, les pedimos como 煤ltima tarea generar una wordcloud con las historias de cada personaje seg煤n cada alineamiento (clase). Pueden ocupar el dataset completo para esto. \n",
        "\n",
        "\n",
        "**Nota:** Recuerde eliminar las stopwords. Gu铆as completas para generar las wordclouds, eliminar las stopwords y configurar los par谩metros de las nubes creadas pueden ser encontradas en su [documentaci贸n oficial](https://amueller.github.io/word_cloud/) y en [datacamp](https://www.datacamp.com/community/tutorials/wordcloud-python).\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBdONTJZnLbd"
      },
      "source": [
        "#### Wordcloud para heroes ####"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-IiZ7PXnLfS"
      },
      "source": [
        "#### Wordcloud para neutrales ####"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVV1M-osnLnj"
      },
      "source": [
        "#### Wordcloud para villanos ####"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HljnDhRcoK83"
      },
      "source": [
        "Comente las principales diferencias entre las tres wordclouds.\n",
        "驴Hay palabras que caracterizen a los grupos y que no aparezcan en los otros?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tM1jthVRoY93"
      },
      "source": [
        "---> Comente aqu铆 <---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rg4ZMq8ezAH6"
      },
      "source": [
        "# Conclusi贸n\n",
        "Eso ha sido todo para el lab de hoy, recuerden que el laboratorio tiene un plazo de entrega de una semana y que **los d铆as de atraso no se pueden utilizar para entregas de lab, solo para tareas**. Cualquier duda del laboratorio, no duden en contactarnos por mail o U-cursos.\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media1.tenor.com/images/fb5bf7cc5a4acb91b4177672886a88ba/tenor.gif?itemid=5591338\">\n",
        "</p>"
      ]
    }
  ]
}