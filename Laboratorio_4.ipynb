{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Tabla de Contenidos",
      "title_sidebar": "Contenidos",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "241.867px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "enunciado_Laboratorio4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUZ1dFPHzAHl"
      },
      "source": [
        "<h1><center>Laboratorio 4: ¿Superhéroe o Villano? 🦸</center></h1>\n",
        "\n",
        "<center><strong>MDS7202: Laboratorio de Programación Científica para Ciencia de Datos</strong></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UD8X1uhGzAHq"
      },
      "source": [
        "### Cuerpo Docente:\n",
        "\n",
        "- Profesor: Pablo Badilla\n",
        "- Auxiliar: Ignacio Meza D.\n",
        "- Ayudante: Diego Irarrázaval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FG8a9z-YjDv4"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXflExjqzAHr"
      },
      "source": [
        "### Equipo: SUPER IMPORTANTE - notebooks sin nombre no serán revisados\n",
        "\n",
        "- Nombre de alumno 1: Constanza Peña\n",
        "- Nombre de alumno 2: Benjamín Tejeda\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AD-V0bbZzAHr"
      },
      "source": [
        "### **Link de repositorio de GitHub:** `https://github.com/constanzaps/laboratorios_LDS`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcnsiQMkzAHr"
      },
      "source": [
        "### Indice \n",
        "\n",
        "1. [Temas a tratar](#Temas-a-tratar:)\n",
        "3. [Descripcción del laboratorio](#Descripción-del-laboratorio.)\n",
        "4. [Desarrollo](#Desarrollo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uBLPj1PzAHs"
      },
      "source": [
        "# Temas a tratar\n",
        "\n",
        "- Clasificación con texto.\n",
        "- Clasificación en `scikit-learn`.\n",
        "- Modelos a través del uso de `pipeline`.\n",
        "- Optimización de modelos usando `GridSearchCV`.\n",
        "\n",
        "## Reglas:\n",
        "\n",
        "- Fecha de entrega: 4/06/2021\n",
        "- **Grupos de 2 personas**\n",
        "- **Ausentes** deberán realizar la actividad solos. \n",
        "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente serán respondidos por este medio.\n",
        "- Prohibidas las copias. \n",
        "- Pueden usar cualquer matrial del curso que estimen conveniente.\n",
        "\n",
        "### Objetivos principales del laboratorio\n",
        "\n",
        "- Aplicar las ventajas que nos ofrece crear un pipeline.\n",
        "- Obtener caracteristicas desde texto.\n",
        "- Crear modelos de clasificación de texto.\n",
        "- Optimizar la clasificación de texto usando wordclouds.\n",
        "- Usar herramientas de visualización de texto como las wordclouds.\n",
        "\n",
        "El laboratorio deberá ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al máximo las funciones optimizadas que nos entrega `pandas`, las cuales vale mencionar, son bastante más eficientes que los iteradores nativos sobre DataFrames."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhISwri4zAHy"
      },
      "source": [
        "#Importamos librerias utiles 😸"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-29T00:08:16.884674Z",
          "start_time": "2021-03-29T00:08:16.349846Z"
        },
        "id": "uyc33dKdzAHy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0098aa61-dfc1-4188-b6b0-1804391c2164"
      },
      "source": [
        "# Librería Core del lab.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.model_selection import train_test_split \n",
        "\n",
        "# Pre-procesamiento\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Clasifación\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "# Metricas de evaluación\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "# Librería para plotear\n",
        "!pip install --upgrade plotly\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Proyecciones en baja dimensionalidad: UMAP\n",
        "!pip install umap-learn\n",
        "\n",
        "# Librería para NLP\n",
        "!pip install nltk\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize  \n",
        "from nltk.stem import PorterStemmer\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting plotly\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/f6/bd3c17c8003b6641df1228e80e1acac97ed8402635e46c2571f8e1ef63af/plotly-4.14.3-py2.py3-none-any.whl (13.2MB)\n",
            "\u001b[K     |████████████████████████████████| 13.2MB 202kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly) (1.3.3)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from plotly) (1.15.0)\n",
            "Installing collected packages: plotly\n",
            "  Found existing installation: plotly 4.4.1\n",
            "    Uninstalling plotly-4.4.1:\n",
            "      Successfully uninstalled plotly-4.4.1\n",
            "Successfully installed plotly-4.14.3\n",
            "Collecting umap-learn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/69/85e7f950bb75792ad5d666d86c5f3e62eedbb942848e7e3126513af9999c/umap-learn-0.5.1.tar.gz (80kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 2.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (1.4.1)\n",
            "Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (0.51.2)\n",
            "Collecting pynndescent>=0.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/65/8189298dd3a05bbad716ee8e249764ff8800e365d8dc652ad2192ca01b4a/pynndescent-0.5.2.tar.gz (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 15.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22->umap-learn) (1.0.1)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn) (57.0.0)\n",
            "Building wheels for collected packages: umap-learn, pynndescent\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.1-cp37-none-any.whl size=76569 sha256=2ebf64187dbdcb64d3b3cfa8d4dfe9f55db53517a5d54ad0c0c7b670d370af19\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/df/d5/a3691296ff779f25cd1cf415a3af954b987fb53111e3392cf4\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynndescent: filename=pynndescent-0.5.2-cp37-none-any.whl size=51362 sha256=b39ccbc5c4303e738e469921c5068b9269005dba76dd1ef74289a4f447bf2c78\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/52/4e/4c28d04d144a28f89e2575fb63628df6e6d49b56c5ddd0c74e\n",
            "Successfully built umap-learn pynndescent\n",
            "Installing collected packages: pynndescent, umap-learn\n",
            "Successfully installed pynndescent-0.5.2 umap-learn-0.5.1\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpOTbQcxbSiy"
      },
      "source": [
        "# 1. ¿Quien es Bat Cow?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Q93vbNS25bM"
      },
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"https://static.wikia.nocookie.net/p__/images/a/a2/Bat-Cow.jpg/revision/latest?cb=20180108185037&path-prefix=protagonist\" width=\"350\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnmZfFpxTTYX"
      },
      "source": [
        "En vez de estar oprotunamente desarrollando las tareas y las evaluaciones correspondientes al curso, su profesor de catedra y su auxiliar discuten acerca la alineación del personaje de ficción *Bat-Cow*. \n",
        "\n",
        "El cuerpo docente, no logra ponerse de acuerdo acerca de la alineación del personaje, es decir, si lucha junto a las fuerzas del bien, si neutral a cualquier eventualidad o derechamente es un villano.\n",
        "El auxiliar plantea (de forma superficial) que *Bat-cow* posee una siniestra mirada, común característica de los personajes malvados. \n",
        "Por otra parte, extendiendo las ideas de Rousseau, el profesor (*se cree filósofo... y*) plantea que tal como los humanos no nacen malos, no existe motivo por el cual un rumiante humanizado con superpoderes deba serlo.\n",
        "\n",
        "Sin embargo, ambos concuerdan en es difícil estimar la alineación solo usando los atributos físicos, por lo que creen el análisis debe ser complementado aún más antes de comunicarle los resultados a su estudiantado. Buscando más información, ambos sujetos se percatan de la existencia de un excelente antecedente para estimar la alineación: la historia personal de cada superhéroe o villano.\n",
        "\n",
        "Es por esto le solicitan que construya y optimice un clasificador basado en texto el cual analice la alineación de cada personaje basado en su historia personal.\n",
        "\n",
        "Para este laboratorio deben trabajar con los datos `df_comics.csv` y `comics_no_label.csv` subidos a u-cursos. El primero es un conjunto de datos que les servirá para entrenar un modelo de clasificación, mientras que el segundo es un dataset con personajes de ficción no etiquetados a predecir (sí, aquí está la misteriosa Batcow).\n",
        "\n",
        "Para iniciar este laboratorio, cargue los dataset señalados y visualice a través de la función `head` los atributos que poseen cada uno de los dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jqq-s010Iwl1",
        "outputId": "c422a4fc-a03f-4968-8708-e2b09f9828cb"
      },
      "source": [
        "# Usar solamente si utilizan Collab.\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "dir = '//content//drive//My Drive//Otoño 2021//Laboratorio//Lab 4//'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bED3w3tDbSCf"
      },
      "source": [
        "df_comics = pd.read_csv(dir+'df_comics.csv')\n",
        "df_comics_no_label = pd.read_csv(dir+'comics_no_label.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4tFPrFA4_O5"
      },
      "source": [
        "## 1.1 Obtención de Features [2 puntos]\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media0.giphy.com/media/eIUpSyzwGp0YhAMTKr/200.gif\" width=\"300\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_4NF0_V5XZ-"
      },
      "source": [
        "Su primera tarea consiste en generar un vector de características para el atributo `history_text`. En este atributo se presenta una breve descripción de la historia de cada uno de los personajes de ficción presentes en el dataset (si un personaje tiene este atributo nulo, elimínelo). Luego, para obtener características de texto aplique el modelo de conteo `bag of words` de la siguiente forma:\n",
        "\n",
        "- Utilice `CountVectorized` junto al tokenizador (que le proveemos) `LemmaTokenizer`.\n",
        "- Obtenga caracteristicas de los 1-gramas y 2-gramas del texto (ver clase).\n",
        "- Fijar un maximo de 10.000 caracteristicas para el vector de salida.\n",
        "\n",
        "Finalmente, aplique `MinMaxScaler()` sobre `atributos_de_interes` y concatene el valor obtenido con el matriz de caracteristicas obtenidas con bag of words.\n",
        "\n",
        "```python\n",
        "atributos_de_interes = ['intelligence_score', 'strength_score', 'speed_score', 'durability_score', 'power_score', 'combat_score']\n",
        "```\n",
        "\n",
        "No es necesario que obtenga un dataframe en concreto con las características solicitadas. Se le recomienda generar un `ColumnTransformer()` para aplicar las transformaciones solicitadas en un pipeline.\n",
        "\n",
        "**To-Do:**\n",
        "- [ ] Obtener a traves de bag of words caracteristicas del resumen de historia de cada personaje.\n",
        "- [ ] Aplicar MinMaxScaler sobre los atributos de interes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ay080DunHcOS"
      },
      "source": [
        "#### Código aquí ####\n",
        "df_comics = df_comics.dropna(subset=['history_text'])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixmI9S6poGDm"
      },
      "source": [
        "stop_words = stopwords.words('english')\n",
        "\n",
        "class LemmaTokenizer:\n",
        "    def __init__(self):\n",
        "        self.ps = PorterStemmer()\n",
        "    def __call__(self, doc):\n",
        "        doc_tok = word_tokenize(doc)\n",
        "        doc_tok = [t for t in doc_tok if t not in stop_words]\n",
        "        return [self.ps.stem(t) for t in doc_tok]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIBeBtUz2IDj"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer(tokenizer=LemmaTokenizer(),\n",
        "                             lowercase=True,\n",
        "                             max_features=10000,\n",
        "                             strip_accents=\"ascii\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bGBC_SP0XJ-"
      },
      "source": [
        "bow = vectorizer.fit_transform(df_comics[\"history_text\"])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TL_0D9a04C_",
        "outputId": "434198ce-ac44-4f9e-d1e8-2a71ac84ab48"
      },
      "source": [
        "print(vectorizer.get_feature_names())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['!', '#', '$', '%', '&', \"'\", \"''\", \"'d\", \"'it\", \"'ll\", \"'m\", \"'other-realm\", \"'power\", \"'re\", \"'real\", \"'s\", \"'the\", \"'ve\", '(', ')', ',', '-', '--', '-sign-', '.', '...', '/', '/b', '/h', '/i', '030', '1', '10', '100', '1000', '11', '12', '1200', '12th', '13', '14', '142', '15', '16', '17', '18', '19', '1920', '1930', '1936', '1938', '1940', '1940.', '1941', '1942', '1943', '1944', '1945', '1946', '1947', '1949', '1950', '1953', '1954', '1958', '1959', '1960', '1961', '1962', '1963', '1964', '1970', '1972', '1973', '1975', '1976', '1977', '198', '1980', '1983', '1984', '1985', '1990', '1991', '1992', '1995', '1997', '1999', '19th', '1st', '2', '2.', '20', '2000', '2001', '2002', '2003', '2004', '2005', '2006', '2011', '2012', '2014', '2015', '2016', '2017', '2018', '2099', '20th', '21', '21st', '22', '23', '24', '25', '25th', '26', '2nd', '3', '3,000', '3.', '30', '3000', '30th', '31st', '34', '4', '4.', '40', '42', '5', '5,000', '50', '52', '6', '60', '616', '64th', '7', '70', '8', '9', '90', ':', ';', '?', '[', ']', '``', 'a-bomb', 'a.d.', 'a.i.m', 'a.i.m.', 'a.k.a', 'a.r.g.u.', 'aa', 'aaron', 'abandon', 'abbi', 'abbott', 'abdic', 'abdol', 'abduct', 'abe', 'abi', 'abigail', 'abil', 'abin', 'abl', 'ablaz', 'abner', 'abnorm', 'aboard', 'abomin', 'aborigin', 'abort', 'abra', 'abraham', 'abraxa', 'abroad', 'abruptli', 'absenc', 'absent', 'absolut', 'absorb', 'absorpt', 'abstract', 'abus', 'abyss', 'academ', 'academi', 'acanti', 'acceler', 'accept', 'access', 'accid', 'accident', 'acclaim', 'accommod', 'accompani', 'accomplic', 'accomplish', 'accord', 'accordingli', 'accost', 'account', 'accumul', 'accuraci', 'accus', 'ace', 'achiev', 'achil', 'acid', 'acknowledg', 'acolyt', 'acotilletta2', 'acquaint', 'acquir', 'acrobat', 'across', 'act', 'action', 'activ', 'activist', 'actor', 'actress', 'actual', 'ad', 'ada', 'adam', 'adamantium', 'adapt', 'add', 'adder', 'addict', 'addit', 'addl', 'address', 'adelin', 'adept', 'adher', 'adjust', 'administ', 'administr', 'admir', 'admit', 'adolesc', 'adolf', 'adopt', 'ador', 'adrenalin', 'adrian', 'adrienn', 'adrift', 'adult', 'adulthood', 'advanc', 'advantag', 'advent', 'adventur', 'adversari', 'advertis', 'advic', 'advis', 'advisor', 'aegi', 'aeri', 'aerial', 'aerospac', 'aether', 'affair', 'affect', 'affection', 'affili', 'afflict', 'afford', 'afghanistan', 'afoul', 'afraid', 'africa', 'african', 'african-american', 'afterlif', 'aftermath', 'afternoon', 'afterward', 'afterword', 'agamemnon', 'agamotto', 'agatha', 'age', 'agenc', 'agenda', 'agent', 'aggrav', 'aggress', 'agil', 'agit', 'ago', 'agoni', 'agre', 'agreement', 'ahab', 'ahead', 'ahk-ton', 'ahold', 'ai', 'aid', 'aida', 'ail', 'ailment', 'aim', 'air', 'air-walk', 'airborn', 'aircraft', 'airjitzu', 'airplan', 'airport', 'airship', 'ajax', 'aka', 'akasaka', 'akatsuki', 'akihira', 'akihiro', 'akin', 'akira', 'akita', 'akkaba', 'al', 'alan', 'alarm', 'alaska', 'albanian', 'albeit', 'albert', 'albu', 'alcatraz', 'alchemax', 'alchemi', 'alcohol', 'alderaan', 'aldo', 'alec', 'aleksei', 'alert', 'alex', 'alexand', 'alexia', 'alfr', 'ali', 'alia', 'alic', 'alicia', 'alien', 'align', 'alik', 'alison', 'aliv', 'all-american', 'all-new', 'all-out', 'all-star', 'allan', 'allat', 'alleg', 'allegedli', 'allegi', 'allen', 'allen/th', 'allevi', 'alley', 'alleyway', 'alli', 'allianc', 'allison', 'allow', 'alloy', 'almerac', 'almost', 'alon', 'along', 'alongsid', 'alp', 'alpha', 'alphonso', 'alraun', 'alreadi', 'alright', 'also', 'altar', 'alter', 'alter-ego', 'alterc', 'altern', 'although', 'altogeth', 'alucard', 'alura', 'alveu', 'alvin', 'alway', 'alyosha', 'amadeu', 'amahl', 'amalgam', 'aman', 'amanda', 'amass', 'amateur', 'amaya', 'amaz', 'amazo', 'amazon', 'amazonian', 'ambassador', 'amber', 'ambit', 'ambiti', 'ambul', 'ambush', 'amelia', 'amend', 'america', 'american', 'ami', 'amic', 'amid', 'amidst', 'amiko', 'amiss', 'ammo', 'amnesia', 'amnesiac', 'amnesti', 'amo', 'amok', 'amon', 'among', 'amongst', 'amor', 'amora', 'amount', 'amphibi', 'amplifi', 'amput', 'amulet', 'amus', 'amygdala', 'ana', 'anacondrai', 'anakin', 'analysi', 'analyz', 'anansi', 'anarki', 'ancestor', 'ancestr', 'anchor', 'ancient', 'and/or', 'ander', 'anderson', 'andi', 'ando', 'andrea', 'andrew', 'android', 'andromeda', 'anew', 'angband', 'angel', 'angela', 'angelica', 'angelo', 'angelu', 'anger', 'angl', 'angri', 'angrili', 'anguish', 'ani-m', 'ani-men', 'anim', 'animos', 'ankl', 'ann', 'anna', 'annabeth', 'annex', 'anni', 'annihil', 'annihilu', 'anniversari', 'announc', 'annoy', 'annual', 'anomali', 'anonym', 'anoth', 'answer', 'ant', 'ant-man', 'antagonist', 'antarct', 'antarctica', 'antenna', 'anthil', 'anthoni', 'anti-hero', 'anti-lif', 'anti-matt', 'anti-monitor', 'anti-mut', 'anti-spawn', 'anti-venom', 'antic', 'anticip', 'antidot', 'antimatt', 'antiop', 'antiqu', 'antithesi', 'anton', 'anya', 'anybodi', 'anymor', 'anyon', 'anyth', 'anytim', 'anyway', 'anywher', 'apach', 'apart', 'apathet', 'ape', 'apocalyps', 'apokolip', 'apollo', 'apolog', 'apostl', 'appal', 'appar', 'apparatu', 'appeal', 'appear', 'appl', 'appli', 'applic', 'appoint', 'appreci', 'apprehend', 'apprentic', 'approach', 'appropri', 'approv', 'approxim', 'april', 'aptitud', 'aqua', 'aquababi', 'aquagirl', 'aqualad', 'aquaman', 'aquat', 'aquista', 'aquon', 'arab', 'arabian', 'aramilla', 'arbit', 'arc', 'arcad', 'arcadia', 'arcadian', 'arcan', 'arch-enemi', 'archaeologist', 'archangel', 'archenemi', 'archer', 'archeri', 'archi', 'archiv', 'arclight', 'arctic', 'arcturu', 'arda', 'are', 'area', 'arena', 'argent', 'argenta', 'argo', 'argu', 'arguabl', 'argument', 'ari', 'ariana', 'ariel', 'arin', 'arion', 'aris', 'arisia', 'arizona', 'ark', 'arkham', 'arklay', 'arkon', 'arlington', 'arm', 'armada', 'armageddon', 'armament', 'armando', 'armi', 'armor', 'armori', 'armour', 'armstrong', 'arnim', 'arno', 'arnold', 'aron', 'aros', 'around', 'arous', 'arrang', 'array', 'arrest', 'arriv', 'arrog', 'arrow', 'arsen', 'art', 'artemi', 'arthur', 'arti', 'articl', 'artifact', 'artifici', 'artist', 'artoo', 'ascend', 'ascens', 'asgard', 'asgardian', 'ash', 'asha', 'asham', 'ashley', 'ashor', 'asia', 'asian', 'asid', 'ask', 'askani', 'asleep', 'asmodeu', 'aspect', 'aspheera', 'aspir', 'assail', 'assassin', 'assault', 'assembl', 'assemblag', 'assert', 'asset', 'assign', 'assimil', 'assist', 'associ', 'assort', 'assum', 'assumpt', 'assur', 'asteroid', 'asteroth', 'astonish', 'astra', 'astral', 'astronaut', 'asylum', 'ate', 'athena', 'athlet', 'atla', 'atlan', 'atlanna', 'atlant', 'atlanta', 'atlantean', 'atlanti', 'atmospher', 'atom', 'atom-smash', 'aton', 'atop', 'atroc', 'atrocitu', 'attach', 'attack', 'attain', 'attempt', 'attend', 'attent', 'attilan', 'attitud', 'attorney', 'attract', 'attribut', 'attuma', 'aubrey', 'auction', 'audienc', 'audit', 'augment', 'august', 'aunt', 'aura', 'aurora', 'auschwitz', 'auspic', 'australia', 'australian', 'austria', 'author', 'autobiographi', 'automat', 'automaton', 'automobil', 'autumn', 'avail', 'avalanch', 'avalon', 'avatar', 'aveng', 'avenu', 'averag', 'avers', 'avert', 'avia', 'avil', 'avoid', 'avram', 'aw', 'await', 'awak', 'awaken', 'awar', 'award', 'away', 'awe', 'awesom', 'awhil', 'awkward', 'awok', 'awoken', 'awri', 'axe', 'axi', 'axl', 'axlon', 'ayla', 'az-bat', 'azazel', 'azimuth', 'azkaban', 'azrael', 'b', 'b.', 'b.j', 'b.o.w.', 'b.p.r.d', 'babel', 'babi', 'babidi', 'babylon', 'babysitt', 'bach', 'back', 'back-up', 'backfir', 'background', 'backlash', 'backstori', 'backup', 'backward', 'bad', 'badg', 'badli', 'badnik', 'badoon', 'baelish', 'baffler', 'bag', 'bagalia', 'bail', 'bailey', 'bain', 'bait', 'baker', 'balanc', 'balconi', 'bald', 'balder', 'baldwin', 'balkan', 'ball', 'balrog', 'ban', 'bana-mighdal', 'band', 'bandag', 'bandit', 'bane', 'bang', 'banish', 'bank', 'banner', 'banshe', 'bantam', 'bar', 'baratheon', 'barb', 'barbara', 'barbarian', 'bard', 'barda', 'bare', 'barg', 'bargain', 'barlow', 'barn', 'barney', 'baro', 'baron', 'barrag', 'barren', 'barri', 'barrier', 'barrington', 'bart', 'bartino', 'barton', 'base', 'basebal', 'basement', 'basi', 'basic', 'basketbal', 'bass', 'bastard', 'bastion', 'bat', 'bat-famili', 'batarang', 'batcav', 'batgirl', 'bath', 'bathroom', 'batman', 'batmobil', 'batroc', 'batson', 'batsuit', 'battalion', 'batter', 'batteri', 'battl', 'battle-suit', 'battlefield', 'battleground', 'battlestar', 'battlesuit', 'battleworld', 'batw', 'batwoman', 'bauer', 'baxter', 'bay', 'bazin', 'bc', 'be', 'beach', 'beacon', 'beak', 'beal', 'beam', 'bear', 'beard', 'bearer', 'beast', 'beat', 'beaten', 'beatric', 'beaubier', 'beauti', 'becam', 'beck', 'beckett', 'becom', 'bed', 'bedlam', 'bedroom', 'bee', 'beelzebub', 'beer', 'beetl', 'beforehand', 'befriend', 'beg', 'began', 'begin', 'begrudgingli', 'begun', 'behalf', 'behavior', 'behaviour', 'behead', 'behemoth', 'behest', 'behind', 'bekka', 'belasco', 'belief', 'believ', 'bell', 'bella', 'belling', 'belmond', 'belmont', 'belong', 'belov', 'belova', 'belt', 'ben', 'bend', 'beneath', 'benefactor', 'benefici', 'benefit', 'benevol', 'benjamin', 'bennet', 'bent', 'bentley', 'bequeath', 'berat', 'beret', 'berlin', 'bermuda', 'bernard', 'berni', 'berra', 'berserk', 'bertinelli', 'bertron', 'besid', 'besieg', 'best', 'bestial', 'bestow', 'bet', 'beta', 'beth', 'betray', 'betroth', 'betsi', 'bett', 'better', 'betti', 'beverli', 'bevi', 'bewild', 'beyond', 'bialya', 'bibl', 'bicker', 'bid', 'bidder', 'bide', 'bifrost', 'big', 'big-daddi', 'bigger', 'biggest', 'bill', 'billi', 'billion', 'billionair', 'binari', 'bind', 'bio-belt', 'bio-weapon', 'biochem', 'biochemist', 'biochemistri', 'bioelectr', 'biographi', 'biohazard', 'biolog', 'biologist', 'biomet', 'bionic', 'bird', 'birdman', 'birkin', 'birth', 'birthday', 'birthplac', 'birthright', 'bishop', 'bit', 'bite', 'bitten', 'bitter', 'bizarr', 'bizarro', 'bizarro-girl', 'bizarrogirl', 'black', 'blackest', 'blackgat', 'blackguard', 'blackhawk', 'blackheart', 'blackmail', 'blackout', 'blacksmith', 'blackw', 'blackwatch', 'blackwel', 'blade', 'blair', 'blake', 'blame', 'blank', 'blast', 'blastaar', 'blaster', 'blaze', 'bldhaven', 'bleach', 'bleak', 'bleed', 'blend', 'bless', 'blew', 'blight', 'blind', 'blindfold', 'bling', 'blink', 'blizzard', 'blob', 'block', 'blockbust', 'blond', 'blonski', 'blood', 'bloodax', 'bloodhawk', 'bloodi', 'bloodlin', 'bloodlust', 'bloodsh', 'bloodsport', 'bloodston', 'bloodthirsti', 'bloodwraith', 'blossom', 'blow', 'blown', 'bludgeon', 'bludhaven', 'blue', 'blueprint', 'blunt', 'blur', 'board', 'boast', 'boat', 'boathous', 'bob', 'bobbi', 'boch', 'bodi', 'bodili', 'bodyguard', 'bodysuit', 'bogan', 'boil', 'bokk', 'bolivar', 'bolland', 'bolovax', 'bolster', 'bolt', 'bomb', 'bombard', 'bomber', 'bombshel', 'bond', 'bone', 'bong', 'boo', 'boobi', 'booby-trap', 'boodikka', 'book', 'boom', 'boom-boom', 'boomer', 'boomerang', 'boon', 'boost', 'booster', 'boot', 'booth', 'bor', 'borazzon', 'border', 'bore', 'boreal', 'boredom', 'borg', 'born', 'borrow', 'boss', 'boston', 'botan', 'botanist', 'bother', 'bottl', 'bottom', 'bought', 'boulder', 'bounc', 'bound', 'boundari', 'bounti', 'bout', 'bova', 'bow', 'bowen', 'bowl', 'bowser', 'box', 'boxer', 'boy', 'boyfriend', 'boyl', 'bprd', 'bracelet', 'braddock', 'bradley', 'brag', 'brain', 'braini', 'brainiac', 'brainpow', 'brainwash', 'brainwav', 'branch', 'brand', 'brandt', 'brash', 'brauner', 'brave', 'braveri', 'brawl', 'brazil', 'breach', 'break', 'breakdown', 'breaker', 'breakout', 'breakthrough', 'breakup', 'breakworld', 'breath', 'breed', 'brenda', 'brendan', 'brent', 'brethren', 'brew', 'brian', 'bribe', 'bride', 'bridg', 'brief', 'briefcas', 'briefli', 'brigad', 'bright', 'brightest', 'brightwind', 'brik', 'brilliant', 'brimston', 'bring', 'brink', 'britain', 'british', 'briton', 'britt', 'broadcast', 'brock', 'broke', 'broken', 'broken-heart', 'broker', 'bronz', 'brood', 'brooklyn', 'bros.', 'brothel', 'brother', 'brotherhood', 'brought', 'brown', 'bruce', 'bruis', 'brujeria', 'brundl', 'brundlefli', 'brunnhild', 'brunt', 'brush', 'brutaal', 'brutal', 'brute', 'brutish', 'bruttenholm', 'bryan', 'bryant', 'bsaa', 'bu', 'bubbl', 'buchanan', 'bucki', 'bud', 'buddi', 'buffi', 'bug', 'bugl', 'build', 'builder', 'built', 'bulk', 'bull', 'bullet', 'bulli', 'bullock', 'bullsey', 'bum', 'bumblebe', 'bumbleboy', 'bump', 'bunker', 'burden', 'bureau', 'bureaucrat', 'burgeon', 'burglar', 'burglari', 'buri', 'burial', 'burk', 'burn', 'burnt', 'burr', 'burst', 'burstein', 'burton', 'burtram', 'bushido', 'bushman', 'bushmast', 'busi', 'businessman', 'businessmen', 'bust', 'buster', 'butcher', 'butler', 'button', 'buu', 'buy', 'buyer', 'bypass', 'byron', 'bystand', 'c.', 'c4', 'ca', 'cabal', 'cabba', 'cabe', 'cabin', 'cabinet', 'cabl', 'cach', 'cadet', 'cadmu', 'cadr', 'caesar', 'cafe', 'cafeteria', 'cage', 'caiera', 'cain', 'cairo', 'caitlin', 'cake', 'calam', 'calcul', 'calendar', 'caliban', 'caliburn', 'california', 'call', 'callisto', 'calm', 'calmli', 'calogero', 'calvari', 'calvin', 'calypso', 'came', 'camelot', 'cameo', 'camera', 'cameron', 'cammi', 'camp', 'campaign', 'campbel', 'campu', 'canada', 'canadian', 'canari', 'cancel', 'cancer', 'cancervers', 'candi', 'candid', 'candl', 'cane', 'cani', 'canist', 'cannon', 'cannonbal', 'canon', 'canyon', 'cap', 'capabl', 'capac', 'cape', 'caper', 'capit', 'capitol', 'cappi', 'capsul', 'captain', 'captiv', 'captor', 'captur', 'car', 'caraka', 'carbonadium', 'card', 'cardboard', 'cardiac', 'cardin', 'care', 'career', 'careless', 'caretak', 'cargg', 'cargil', 'cargo', 'caribbean', 'carjack', 'carl', 'carlton', 'carmin', 'carnag', 'carniv', 'carol', 'carolina', 'carolyn', 'carpent', 'carri', 'carrier', 'carrion', 'carson', 'cartel', 'carter', 'cartoon', 'carv', 'case', 'cash', 'casino', 'casket', 'cassandra', 'cassi', 'cassidi', 'cast', 'castl', 'castlevania', 'casual', 'casualti', 'cat', 'cat-lik', 'cat-soul', 'cataclysm', 'catastroph', 'cataton', 'catch', 'catelyn', 'cathedr', 'cathol', 'catman', 'catwoman', 'caucasian', 'caught', 'caul', 'caulifla', 'caus', 'caution', 'cavallo', 'cave', 'cave-in', 'cavendish', 'cavern', 'caviti', 'cbi', 'cd', 'ceas', 'cede', 'ceil', 'celebr', 'celesti', 'cell', 'cellmat', 'cellular', 'cement', 'cemeteri', 'center', 'centiped', 'centr', 'central', 'centuri', 'centurion', 'ceo', 'cerdia', 'cerebr', 'cerebra', 'cerebro', 'ceremoni', 'cersei', 'certain', 'certainli', 'certif', \"ch'od\", 'cha', 'chafe', 'chagrin', 'chain', 'chainsaw', 'chair', 'chairman', 'challeng', 'chamber', 'chameleon', 'champa', 'champion', 'chanc', 'chancellor', 'chandler', 'chang', 'changel', 'channel', 'chantinel', 'chao', 'chaotic', 'chapel', 'chapter', 'char', 'charact', 'characterist', 'charax', 'charg', 'charit', 'chariti', 'charl', 'charlemagn', 'charli', 'charlott', 'charm', 'charter', 'chase', 'chasm', 'chast', 'chastis', 'chat', 'cheap', 'cheat', 'check', 'checkmat', 'cheer', 'cheerlead', 'cheetah', 'chemic', 'chemistri', 'chemo', 'chen', 'cheney', 'cheshir', 'chess', 'chessmen', 'chest', 'chew', 'chewbacca', 'cheyenn', 'chi', 'chiantang', 'chicago', 'chico', 'chief', 'child', 'childbirth', 'childhood', 'childlik', 'children', 'chimera', 'chimp', 'china', 'chines', 'chip', 'chitauri', 'cho', 'choi', 'choic', 'choke', 'choos', 'chop', 'chopper', 'chose', 'chosen', 'chri', 'christ', 'christen', 'christian', 'christin', 'christina', 'christma', 'christoph', 'chronal', 'chronicl', 'chrono', 'chronopoli', 'chrysali', 'chu', 'chuck', 'chuma', 'chunk', 'church', 'chute', 'cia', 'ciel', 'cindi', 'cipher', 'circ', 'circa', 'circl', 'circu', 'circuit', 'circuitri', 'circul', 'circumst', 'cisco', 'citadel', 'citat', 'cite', 'citi', 'citizen', 'citizenship', 'civil', 'civilian', 'clad', 'claim', 'clair', 'clan', 'clandestin', 'clariss', 'clark', 'clash', 'class', 'classic', 'classif', 'classifi', 'classmat', 'claudett', 'claw', 'clay', 'clayfac', 'clea', 'clean', 'cleans', 'clear', 'clearli', 'cleric', 'clever', 'client', 'cliff', 'climact', 'climat', 'climax', 'climb', 'clinic', 'clint', 'cloak', 'clock', 'clone', 'close', 'closer', 'closest', 'closet', 'closur', 'cloth', 'cloud', 'clous', 'clown', 'clu', 'club', 'clue', 'cluemast', 'cluster', 'clutch', 'clyde', 'co-lead', 'co-work', 'co.', 'coach', 'coagul', 'coal', 'coalit', 'coast', 'coat', 'cobalt', 'cobblepot', 'cobra', 'cocain', 'cocki', 'cockpit', 'coconut', 'cocoon', 'cocott', 'code', 'code-nam', 'codenam', 'coerc', 'coexist', 'coffe', 'coffin', 'cog', 'cogliostro', 'cohort', 'coin', 'coincid', 'coincident', 'col.', 'colcord', 'cold', 'coldfir', 'cole', 'collabor', 'collaps', 'collar', 'colleagu', 'collect', 'collector', 'colleen', 'colleg', 'collid', 'collin', 'collis', 'colombian', 'colonel', 'coloni', 'color', 'colorado', 'coloss', 'colossu', 'colu', 'coluan', 'columbia', 'column', 'coma', 'comatos', 'combat', 'combin', 'come', 'comedian', 'comet', 'comfort', 'comic', 'command', 'commando', 'commemor', 'commenc', 'commend', 'comment', 'commerci', 'commiss', 'commission', 'commit', 'committe', 'common', 'commonli', 'commun', 'communist', 'compani', 'companion', 'compar', 'comparison', 'compart', 'compass', 'compassion', 'compatriot', 'compel', 'compens', 'compet', 'competit', 'competitor', 'complac', 'complain', 'complet', 'complex', 'compli', 'complic', 'compliment', 'compon', 'compos', 'composit', 'compound', 'comprehens', 'compris', 'compromis', 'compuls', 'comput', 'comrad', 'conal', 'conceal', 'conced', 'conceiv', 'concentr', 'concept', 'concern', 'conclud', 'conclus', 'concoct', 'concret', 'concuss', 'condemn', 'condit', 'conduct', 'conduit', 'confederaci', 'confer', 'confess', 'confid', 'confidant', 'confin', 'confirm', 'confisc', 'conflict', 'confront', 'confus', 'conglomer', 'congratul', 'connect', 'connecticut', 'conner', 'connor', 'conquer', 'conqueror', 'conquest', 'conscienc', 'consciou', 'conscious', 'consent', 'consequ', 'consid', 'consider', 'consist', 'consol', 'consort', 'conspir', 'conspiraci', 'constant', 'constantin', 'constantli', 'constrictor', 'construct', 'consult', 'consum', 'consumm', 'consumpt', 'contact', 'contain', 'contamin', 'contempl', 'contemporari', 'contend', 'content', 'contest', 'contin', 'conting', 'continu', 'continuum', 'contract', 'contrail', 'contrari', 'contrast', 'contraxia', 'contraxian', 'contribut', 'control', 'controversi', 'convalesc', 'conveni', 'convent', 'converg', 'convers', 'convert', 'convict', 'convinc', 'convoy', 'cook', 'cooki', 'cool', 'cooper', 'coordin', 'cop', 'cope', 'copi', 'copperhead', 'copycat', 'corben', 'cord', 'core', 'corneliu', 'corner', 'corona', 'corp', 'corpor', 'corps', 'corpsmen', 'correct', 'correctli', 'correspond', 'corrigan', 'corrupt', 'corsair', 'cortana', 'cortex', 'cortez', 'corusc', 'corvu', 'cosmic', 'cosmo', 'cost', 'costa', 'costum', 'cottonmouth', 'cough', 'could', 'couldnt', 'coulson', 'council', 'counsel', 'count', 'countdown', 'counter', 'counter-attack', 'counter-earth', 'counteract', 'counterpart', 'counti', 'countless', 'countri', 'coup', 'coupl', 'courag', 'courier', 'cours', 'court', 'courtley', 'courtney', 'cousin', 'cove', 'coven', 'cover', 'covert', 'covertli', 'covet', 'cow', 'coward', 'cowl', 'coy', 'cpr', 'cqc', 'crabrant', 'crack', 'crackajack', 'craft', 'crane', 'crash', 'crash-land', 'crashland', 'crate', 'crave', 'crawford', 'crawl', 'cray', 'craze', 'crazi', 'cream', 'creat', 'creation', 'creativ', 'creator', 'creatur', 'credit', 'creed', 'creel', 'crescent', 'crew', 'cri', 'crime', 'crime-boss', 'crime-fight', 'crime-lord', 'crimebust', 'crimefight', 'crimelord', 'crimin', 'criminolog', 'crimson', 'crippl', 'crise', 'crisi', 'critic', 'croc', 'crocodil', 'cronal', 'croni', 'cronu', 'crook', 'cross', 'cross-tim', 'crossbon', 'crossfir', 'crossov', 'crouch', 'crow', 'crowbar', 'crowd', 'crown', 'crucial', 'crucibl', 'crucifi', 'crude', 'cruel', 'cruelti', 'cruiser', 'crumbl', 'crusad', 'crush', 'crusher', 'cruz', 'cryogen', 'crypt', 'cryptic', 'crystal', 'crystallin', 'csa', 'cuba', 'cuban', 'cube', 'cubot', 'cuckoo', 'cull', 'culloden', 'culmin', 'culprit', 'cult', 'cultist', 'cultur', 'cun', 'cup', 'curat', 'curb', 'cure', 'curios', 'curiou', 'current', 'curri', 'curs', 'curt', 'curtail', 'curti', 'custer', 'custodi', 'custom', 'cut', 'cy-gor', 'cyber', 'cyberdemon', 'cyberdyn', 'cyberfac', 'cybermanc', 'cybernet', 'cyberspac', 'cyborg', 'cycl', 'cyclop', 'cylind', 'cynic', 'cynthia', 'cypher', 'cypru', 'cyru', 'cyttorak', 'czarnian', 'czonk', \"d'bari\", \"d'ken\", \"d'nur\", \"d'spayr\", 'd.c.', 'd.l', 'da', 'dad', 'daddi', 'daedalu', 'dagger', 'daili', 'daimio', 'daimon', 'daisi', 'daken', 'dakimh', 'dakota', 'dale', 'dalla', 'dalton', 'dam', 'dama', 'damag', 'damian', 'damien', 'damn', 'damnat', 'dampen', 'dan', 'dana', 'danc', 'dane', 'danger', 'dani', 'daniel', 'danni', 'dant', 'danver', 'daphn', 'dare', 'daredevil', 'dareth', 'darhk', 'dark', 'darkchild', 'darker', 'darkest', 'darkforc', 'darkhawk', 'darkhold', 'darkholm', 'darkl', 'darkley', 'darklord', 'darkseid', 'darksoul', 'darkstar', 'darl', 'darla', 'darren', 'dart', 'darth', 'darwin', 'dash', 'data', 'databas', 'date', 'daughter', 'dava', 'dave', 'davi', 'david', 'davo', 'dawn', 'daxamit', 'daximit', 'day', 'daydream', 'daylight', 'dayton', 'daze', 'dazzler', 'dc', 'dcu', 'de', 'de-ag', 'de-pow', 'deactiv', 'dead', 'deadli', 'deadliest', 'deadman', 'deadpool', 'deadpooli', 'deadshot', 'deafen', 'deag', 'deal', 'dealer', 'dealt', 'dean', 'dearli', 'death', 'death-stalk', 'death/archangel', 'deathangel', 'deathb', 'deathbird', 'deathcard', 'deathcri', 'deathli', 'deathlok', 'deathstorm', 'deathstrik', 'deathstrok', 'debacl', 'debat', 'debbi', 'debilit', 'deborah', 'debri', 'debt', 'debut', 'decad', 'decapit', 'decay', 'deceas', 'deceit', 'deceiv', 'decemb', 'decept', 'decid', 'decim', 'deciph', 'decis', 'deck', 'declar', 'declin', 'decommiss', 'decor', 'decoy', 'decre', 'decreas', 'dedic', 'deduc', 'deed', 'deem', 'deep', 'deeper', 'deepli', 'default', 'defeat', 'defect', 'defenc', 'defend', 'defens', 'defi', 'defianc', 'defiant', 'defin', 'definit', 'deflect', 'deform', 'defus', 'degaton', 'degener', 'degre', 'deimo', 'deiti', 'delay', 'deleg', 'delet', 'delfino', 'delgado', 'deliber', 'delight', 'delirium', 'deliv', 'deliveri', 'delta', 'deltit', 'delus', 'demand', 'demara', 'demeanor', 'dement', 'dementor', 'demis', 'demiurg', 'demiurgo', 'democrat', 'demogoblin', 'demolish', 'demolit', 'demolition-man', 'demon', 'demonstr', 'demot', 'den', 'deni', 'denial', 'denizen', 'denounc', 'dent', 'depart', 'departur', 'depend', 'depict', 'deplet', 'deploy', 'deport', 'depos', 'deposit', 'depow', 'depress', 'depriv', 'depth', 'deputi', 'derang', 'derek', 'derelict', 'deriv', 'desaad', 'descend', 'descent', 'describ', 'desert', 'deserv', 'design', 'desir', 'desk', 'desmond', 'despair', 'desper', 'despero', 'despis', 'despit', 'despond', 'despot', 'destabil', 'destin', 'destini', 'destroy', 'destruct', 'det', 'detach', 'detail', 'detect', 'detent', 'deter', 'deterior', 'determin', 'dethron', 'deton', 'detroit', 'devast', 'develop', 'deviant', 'devic', 'devil', 'devil-hulk', 'devilman', 'devilmen', 'devis', 'devlin', 'devo', 'devoid', 'devot', 'devour', 'dexter', 'dez', 'dh', 'dherain', 'diablo', 'diagnos', 'dialogu', 'diamond', 'diamondback', 'dian', 'diana', 'diari', 'diaz', 'dibacco', 'dibni', 'dick', 'dictat', 'didnt', 'die', 'diego', 'differ', 'difficult', 'difficulti', 'dig', 'digger', 'diggl', 'digit', 'dillard', 'dillon', 'dimens', 'dimension', 'diminish', 'diminut', 'dimpl', 'dinah', 'diner', 'dinner', 'dinosaur', 'diplomat', 'dire', 'direct', 'directli', 'director', 'dirt', 'dirti', 'disabl', 'disagr', 'disagre', 'disappear', 'disappoint', 'disapprov', 'disarm', 'disassembl', 'disast', 'disastr', 'disavow', 'disband', 'disc', 'discard', 'discern', 'discharg', 'discipl', 'disciplin', 'discomfort', 'disconnect', 'discorpor', 'discov', 'discoveri', 'discredit', 'discuss', 'disdain', 'diseas', 'disembodi', 'disfigur', 'disgrac', 'disgruntl', 'disguis', 'disgust', 'dishearten', 'disillus', 'disintegr', 'disinterest', 'disk', 'dislik', 'dismantl', 'dismay', 'dismemb', 'dismiss', 'disobey', 'disord', 'disori', 'disown', 'dispatch', 'dispel', 'dispers', 'displac', 'display', 'displeas', 'dispos', 'disput', 'disqualifi', 'disregard', 'disrupt', 'dissatisfi', 'dissect', 'dissip', 'dissolv', 'distanc', 'distant', 'distinct', 'distinguish', 'distort', 'distract', 'distraught', 'distress', 'distribut', 'district', 'distrust', 'disturb', 'ditch', 'dive', 'diverg', 'divers', 'divert', 'divid', 'divin', 'divis', 'divorc', 'djinjago', 'djinn', 'dna', 'doc', 'dock', 'doctor', 'document', 'dodd', 'dodg', 'dodon', 'dog', 'dolan', 'doll', 'dollar', 'dollmak', 'dolphin', 'dom', 'domain', 'dome', 'domest', 'domin', 'domino', 'dominu', 'domo', 'don', 'donalbain', 'donald', 'donat', 'done', 'donkey', 'donna', 'dooku', 'doom', 'doomguy', 'doomsday', 'door', 'doorbel', 'doorstep', 'doorway', 'doppelgang', 'doppler', 'dora', 'dori', 'dorm', 'dorma', 'dormammu', 'dormant', 'dorothi', 'dorsal', 'dose', 'dosu-roku', 'dotzler', 'doubl', 'double-cross', 'doubt', 'doug', 'dougla', 'dous', 'dove', 'down', 'downfal', 'download', 'downtown', 'dox', 'dozen', 'dr', 'dr.', 'draaga', 'dracula', 'draft', 'drag', 'drago', 'dragon', 'drain', 'drake', 'drama', 'dramat', 'drank', 'draper', 'drastic', 'draw', 'drawn', 'drax', 'dread', 'dream', 'dreiberg', 'dress', 'drew', 'dri', 'drift', 'drill', 'drink', 'drive', 'driven', 'driver', 'droid', 'drone', 'drop', 'drove', 'drown', 'drug', 'druid', 'drunk', 'drunken', 'du', 'dual', 'dub', 'duck', 'dud', 'due', 'duel', 'duela', 'dug', 'dugan', 'duke', 'dum', 'dumb', 'dumbledor', 'dummi', 'dump', 'duncan', 'duo', 'dupe', 'duplic', 'durabl', 'durat', 'duress', 'duro', 'dust', 'dutch', 'dutchman', 'duti', 'dwarf', 'dwarfstar', 'dwell', 'dweller', 'dwight', 'dwindl', 'dyna-mit', 'dynam', 'dynamo', 'dyne', 'dysfunct', 'dyspo', 'dyvyn', 'dzerchenko', 'e', 'e-mail', 'e.', 'eager', 'eagerli', 'eagl', 'ear', 'earli', 'earlier', 'earliest', 'earn', 'earth', 'earth-1', 'earth-2', 'earth-3', 'earth-3145', 'earth-4935', 'earth-616', 'earth-on', 'earth-prim', 'earth-realm', 'earth-thre', 'earth-two', 'earth-x', 'earthgov', 'earthl', 'earthli', 'earthquak', 'earthrealm', 'eas', 'easi', 'easier', 'easili', 'east', 'eastern', 'eat', 'eaten', 'eater', 'eboni', 'eccentr', 'ecclesia', 'echidna', 'echo', 'eck', 'eclips', 'eclipso', 'eco-terrorist', 'ecolog', 'economi', 'ed', 'eddard', 'eddi', 'eden', 'edg', 'edgar', 'edit', 'editor', 'editori', 'edna', 'educ', 'edward', 'edwin', 'eel', 'effect', 'effici', 'effort', 'effortlessli', 'egg', 'egghead', 'eggman', 'eggpawn', 'ego', 'egypt', 'egyptian', 'eidolon', 'eight', 'eighteen', 'eighth', 'eil', 'einherjar', 'either', 'eject', 'el', 'elabor', 'elain', 'elastigirl', 'elba', 'elder', 'elderli', 'eldest', 'elect', 'electr', 'electro', 'electro-psion', 'electrocut', 'electrocution', 'electromagnet', 'electron', 'elektra', 'element', 'elena', 'elev', 'eleven', 'elf', 'elfqueen', 'eli', 'elia', 'elimin', 'elis', 'elisabetha', 'elit', 'elixir', 'elizabeth', 'ell', 'ellen', 'elli', 'elliot', 'elong', 'elpizo', 'els', 'elsewher', 'elud', 'elv', 'eman', 'embark', 'embarrass', 'embassi', 'embed', 'ember', 'embezzl', 'embitt', 'emblem', 'embodi', 'embrac', 'embroil', 'embryo', 'emerald', 'emerg', 'emerl', 'emerson', 'emigr', 'emil', 'emili', 'emissari', 'emit', 'emma', 'emot', 'emotionless', 'emp', 'empath', 'emperor', 'empir', 'emplat', 'employ', 'employe', 'empow', 'empress', 'empti', 'empyrean', 'emul', 'en', 'enabl', 'enact', 'enamor', 'encas', 'enchant', 'enchantress', 'encount', 'encourag', 'end', 'endang', 'endeavor', 'endgam', 'endless', 'endors', 'endoskeleton', 'endow', 'endur', 'enemi', 'energi', 'enfant', 'enforc', 'engag', 'engin', 'england', 'english', 'engulf', 'enhanc', 'enigma', 'enigmat', 'enjoy', 'enlarg', 'enlighten', 'enlist', 'enmiti', 'enorm', 'enough', 'enrag', 'enrol', 'enslav', 'ensu', 'ensur', 'enter', 'enterpris', 'entertain', 'enthusiast', 'entir', 'entireti', 'entiti', 'entitl', 'entourag', 'entranc', 'entrap', 'entri', 'entropi', 'entrust', 'envelop', 'environ', 'environment', 'eobar', 'eobard', 'eon', 'epic', 'epiphani', 'episod', 'equal', 'equat', 'equip', 'equival', 'era', 'erad', 'eras', 'erazor', 'erdel', 'erect', 'eric', 'erik', 'ernest', 'eron', 'errant', 'errat', 'error', 'erupt', 'erwin', 'eryni', 'escal', 'escap', 'escort', 'eskimo', 'especi', 'espionag', 'essenc', 'essenti', 'essex', 'establish', 'estat', 'estrang', 'esva', 'etc', 'etern', 'ethan', 'ethic', 'ethnic', 'etrigan', 'etta', 'eugen', 'eurasia', 'europ', 'european', 'eva', 'evacu', 'evad', 'evan', 'eve', 'evelyn', 'even', 'evenli', 'event', 'eventu', 'ever', 'ever-flust', 'everett', 'everglad', 'everi', 'everybodi', 'everyday', 'everyon', 'everyth', 'everywher', 'evid', 'evil', 'evildo', 'evilhawk', 'evok', 'evolut', 'evolutionari', 'evolv', 'ex', 'ex-boyfriend', 'ex-girlfriend', 'ex-husband', 'ex-wif', 'exacerb', 'exact', 'exactli', 'examin', 'exampl', 'excalibur', 'excav', 'exceed', 'excel', 'except', 'excess', 'exchang', 'excit', 'exclus', 'excus', 'execut', 'execution', 'exemplar', 'exempt', 'exercis', 'exert', 'exhaust', 'exhibit', 'exhum', 'exil', 'exist', 'exit', 'exodu', 'exoner', 'exorc', 'exorcis', 'exorcist', 'expand', 'expans', 'expect', 'expel', 'expend', 'expens', 'experi', 'experienc', 'experiment', 'expert', 'expertis', 'expir', 'explain', 'explan', 'explicitli', 'explod', 'exploit', 'explor', 'explos', 'expos', 'exposur', 'express', 'expuls', 'extant', 'extend', 'extens', 'extent', 'extermin', 'extern', 'extinct', 'extinguish', 'extort', 'extra', 'extra-dimension', 'extract', 'extractor', 'extradimension', 'extradit', 'extraordinari', 'extraordinarili', 'extraterrestri', 'extrem', 'extremi', 'eye', 'ezekiel', 'ezio', 'f.b.i', 'fabian', 'fabl', 'fabric', 'facad', 'face', 'face-to-fac', 'facehugg', 'faceless', 'facial', 'facil', 'facilit', 'fact', 'faction', 'facto', 'factor', 'factori', 'fade', 'fail', 'fail-saf', 'failur', 'faint', 'fair', 'fairli', 'faith', 'fake', 'falcon', 'fall', 'fallen', 'fals', 'falsworth', 'faltin', 'fame', 'famili', 'familiar', 'famin', 'famou', 'fan', 'fanat', 'fandral', 'fang', 'fangpyr', 'fangtom', 'fantasi', 'fantast', 'fantomex', 'faora', 'far', 'faraday', 'farewel', 'farm', 'farmer', 'farouk', 'farther', 'fascin', 'fashion', 'fast', 'faster', 'fastest', 'fatal', 'fate', 'father', 'fatheri', 'fault', 'faulti', 'faust', 'faustu', 'favor', 'favorit', 'fawcett', 'fay', 'fbi', 'feanor', 'fear', 'fearless', 'fearsom', 'feat', 'feather', 'featur', 'februari', 'fed', 'feder', 'fee', 'feed', 'feel', 'feet', 'feign', 'felic', 'felicia', 'felin', 'felix', 'fell', 'fellow', 'felt', 'femal', 'fen', 'fenc', 'fend', 'feng-tu', 'fenri', 'feral', 'fermin', 'fernu', 'feroci', 'ferret', 'ferri', 'ferro', 'ferrouz', 'festiv', 'fett', 'feud', 'fever', 'fey', 'ff', 'fianc', 'fiance', 'fiction', 'field', 'fiend', 'fierc', 'fieri', 'fifteen', 'fifth', 'fifti', 'fight', 'fighter', 'figur', 'file', 'fill', 'film', 'fin', 'final', 'financ', 'financi', 'finarfin', 'find', 'fine', 'finest', 'finger', 'fingernail', 'fingerprint', 'fingolfin', 'finish', 'finn', 'finw', 'fiona', 'fire', 'firearm', 'firebal', 'firebird', 'firebrand', 'firefight', 'firefli', 'fireheart', 'firelord', 'firestar', 'firestorm', 'firm', 'firmli', 'first', 'first-born', 'firstborn', 'firstbourn', 'fish', 'fisherman', 'fisk', 'fissur', 'fist', 'fit', 'fitz', 'fitzgerald', 'fitzroy', 'five', 'fix', 'fixat', 'fixer', 'fixit', 'fiyero', 'flag', 'flagship', 'flame', 'flamebird', 'flamethrow', 'flare', 'flash', 'flashback', 'flashpoint', 'flat', 'flaw', 'fled', 'fledgl', 'flee', 'fleet', 'fleme', 'flesh', 'fletcher', 'flew', 'flexibl', 'fli', 'flicker', 'flicki', 'flight', 'fling', 'flint', 'flip', 'flirt', 'flirtat', 'float', 'flood', 'floodgat', 'floor', 'flore', 'florida', 'floron', 'flow', 'flower', 'flown', 'floyd', 'fluctuat', 'fluid', 'flung', 'flush', 'flute', 'focu', 'focus', 'foe', 'foggi', 'foil', 'fold', 'follow', 'foment', 'fond', 'food', 'fool', 'foolish', 'foom', 'foot', 'footag', 'footbal', 'footstep', 'forbad', 'forbid', 'forbidden', 'forbush', 'forc', 'force-field', 'force-sensit', 'forcibl', 'forearm', 'forehead', 'foreign', 'foremost', 'forerunn', 'forese', 'foreseen', 'foreshadow', 'forest', 'foretold', 'forev', 'forfeit', 'forg', 'forgav', 'forgeri', 'forget', 'forgiv', 'forgiven', 'forgot', 'forgotten', 'form', 'formal', 'format', 'formeno', 'former', 'formerli', 'formid', 'formul', 'formula', 'forrest', 'fort', 'forth', 'forti', 'fortifi', 'fortress', 'fortun', 'fortunato', 'forward', 'foster', 'foswel', 'fought', 'found', 'foundat', 'founder', 'foundri', 'fountain', 'four', 'fourarm', 'foursom', 'fourteen', 'fourth', 'fox', 'foxdi', 'foxhound', 'foxx', 'fraction', 'fractur', 'fragil', 'fragment', 'frail', 'frame', 'framework', 'franc', 'franci', 'francin', 'francisco', 'frank', 'frankenstein', 'franklin', 'fransisco', 'frantic', 'fratern', 'fraud', 'fray', 'freak', 'fred', 'freddi', 'free', 'freed', 'freedom', 'freelanc', 'freeman', 'freez', 'freeza', 'french', 'frenzi', 'frequenc', 'frequent', 'fresh', 'freshman', 'fri', 'friction', 'friend', 'friendli', 'friendship', 'frieza', 'frigga', 'fright', 'frighten', 'frodo', 'frog', 'frog-man', 'front', 'frontier', 'frontlin', 'frost', 'froze', 'frozen', 'fruit', 'fruition', 'frustrat', 'frye', 'fu', 'fuel', 'fugit', 'fujikawa', 'fulfil', 'full', 'full-fledg', 'full-forc', 'full-scal', 'full-tim', 'fullest', 'fulli', 'fulton', 'fun', 'function', 'fund', 'funer', 'funnel', 'funni', 'furi', 'furiou', 'furious', 'further', 'furthermor', 'fuse', 'fusion', 'futil', 'futur', 'futurist', 'g', 'g-merl', 'g.', 'g.u.n', 'ga', 'gaara', 'gabriel', 'gadget', 'gaea', 'gag', 'gahck', 'gaia', 'gain', 'galact', 'galactipool', 'galactu', 'galaxi', 'galeem', 'galleri', 'gallow', 'galvez', 'gambit', 'gambl', 'game', 'gamemna', 'gamesmast', 'gamma', 'gamma-pow', 'gamma-ray', 'gamma-spawn', 'gamora', 'gandalf', 'gang', 'gangbust', 'gangster', 'ganthet', 'ganymed', 'gap', 'gar', 'garag', 'garb', 'garbag', 'garden', 'gardner', 'garfield', 'gargan', 'gargoyl', 'gari', 'garma', 'garmadon', 'garmatron', 'garner', 'garokk', 'garrett', 'garrick', 'garrington', 'garth', 'gase', 'gate', 'gateway', 'gath', 'gather', 'gauntlet', 'gave', 'gay', 'gayl', 'gcpd', 'gear', 'gehenna', 'geist', 'gem', 'gemini', 'gemma', 'gemston', 'gender', 'gene', 'gener', 'genesi', 'genet', 'geneticist', 'geni', 'genis-vel', 'geniu', 'genocid', 'genom', 'genosha', 'genoshan', 'gentek', 'gentl', 'gentleman', 'genuin', 'geo-forc', 'geoffrey', 'georg', 'georgia', 'geotronik', 'gerald', 'gerber', 'german', 'germani', 'gestur', 'get', 'getaway', 'ghetto', 'ghost', 'ghostli', 'ghul', 'giant', 'giant-man', 'gideon', 'gift', 'gig', 'gigant', 'giganta', 'gilbert', 'gill', 'gim', 'ginni', 'girder', 'girdl', 'girl', 'girlfriend', 'giurescu', 'give', 'given', 'gizoid', 'glacier', 'glad', 'gladiat', 'gladiatori', 'gladli', 'gland', 'glass', 'glenn', 'glider', 'glimps', 'gloat', 'glob', 'global', 'globe', 'glori', 'glove', 'glow', 'glum', 'glyph', 'go', 'goad', 'goal', 'goblet', 'goblin', 'god', 'god-lik', 'goddess', 'godhood', 'godli', 'godlik', 'godsey', 'godship', 'godson', 'godwav', 'godzilla', 'goe', 'gog', 'gohan', 'goku', 'gold', 'golden', 'golgotha', 'goliath', 'gomi', 'gone', 'good', 'good-by', 'goodby', 'goodman', 'goon', 'gordon', 'gorgon', 'gorilla', 'got', 'gotham', 'gotten', 'govern', 'government-sponsor', 'grab', 'grace', 'grad', 'grade', 'gradual', 'graduat', 'graft', 'grain', 'grand', 'granddaught', 'grandfath', 'grandmast', 'grandmoth', 'grandpar', 'grandson', 'granger', 'granni', 'grant', 'graphic', 'grappl', 'grappler', 'grasp', 'grate', 'gratitud', 'grave', 'graverobb', 'graveyard', 'gravit', 'graviti', 'graviton', 'gravitonium', 'gray', 'graydon', 'graymalkin', 'grayson', 'great', 'great-grandfath', 'greater', 'greatest', 'greatli', 'greec', 'greedi', 'greek', 'green', 'green-skin', 'greenwich', 'greer', 'greet', 'gregor', 'grenad', 'grew', 'grey', 'grid', 'grief', 'grief-stricken', 'griev', 'griffin', 'griffith', 'grigori', 'grim', 'grimm', 'grin', 'grip', 'grodd', 'groot', 'grotesk', 'grotesqu', 'ground', 'group', 'grove', 'grover', 'grow', 'grown', 'grown-up', 'growth', 'groznyj', 'gru', 'grudg', 'grudgingli', 'gruesom', 'grundi', 'gryaznova', 'guard', 'guardian', 'guardsman', 'guardsmen', 'guerard', 'guerrilla', 'guess', 'guest', 'guid', 'guidanc', 'guido', 'guild', 'guilt', 'guilti', 'guinea', 'guis', 'gulf', 'gun', 'gunfir', 'gunman', 'gunn', 'gunpoint', 'gunrunn', 'gunshot', 'gurlukovich', 'gut', 'guthri', 'guy', 'gw', 'gwen', 'gym', 'gymnast', 'gypsi', 'gyrich', 'h', \"h'ylthri\", 'h.', 'h.a.m.m.e.r', 'h.i.v.', 'habit', 'hack', 'hacker', 'hade', 'hagen', 'hail', 'hair', 'haiti', 'haitian', 'hal', 'hala', 'hale', 'half', 'half-broth', 'half-human', 'half-sist', 'halfworld', 'hali', 'hall', 'haller', 'halli', 'halloween', 'hallucin', 'hallucinogen', 'hallway', 'halo', 'halt', 'halv', 'hamilton', 'hamir', 'hammer', 'hammerhead', 'hammond', 'han', 'hancock', 'hand', 'hand-to-hand', 'handcuf', 'handgun', 'handl', 'handler', 'handsom', 'hang', 'hank', 'happen', 'happi', 'happili', 'har', 'harass', 'harbing', 'harbor', 'hard', 'harden', 'harder', 'hardi', 'hardli', 'hardship', 'hardwar', 'hargrov', 'hark', 'harleen', 'harlem', 'harlequin', 'harley', 'harm', 'harmless', 'harmoni', 'harold', 'harper', 'harpi', 'harpoon', 'harpuia', 'harrald', 'harri', 'harriet', 'harrison', 'harsh', 'harshli', 'hart', 'hartley', 'harvard', 'harvest', 'harvey', 'hashirama', 'hast', 'hasti', 'hat', 'hatch', 'hate', 'hatr', 'haul', 'haunt', 'havoc', 'havok', 'hawaii', 'hawk', 'hawkey', 'hawkgirl', 'hawkin', 'hawkman', 'hayashi', 'hayden', 'haywir', 'he', 'head', 'headach', 'headband', 'headhunt', 'headlok', 'headmast', 'headmen', 'headmistress', 'headpool', 'headquart', 'heal', 'healer', 'health', 'healthi', 'hear', 'heard', 'heart', 'heartbroken', 'heat', 'heather', 'heaven', 'heavenli', 'heavi', 'heavili', 'hecat', \"hecat'\", 'hecatomb', 'hector', 'hed', 'hedgehog', 'heed', 'heel', 'height', 'heighten', 'heimdal', 'heinrich', 'heir', 'heiress', 'heist', 'hela', 'helcarax', 'held', 'helen', 'helena', 'helicarri', 'helicopt', 'hell', 'hell-lord', 'hellboy', 'hellcarri', 'hellcat', 'hellfir', 'hellion', 'hellish', 'hellspawn', 'hellstorm', 'hellstrom', 'helm', 'helmet', 'helmut', 'help', 'helpless', 'helplessli', 'hels', 'hem', 'henc', 'henchman', 'henchmen', 'hendri', 'henri', 'henshaw', 'hephaestu', 'hepzibah', 'heracl', 'herald', 'herb', 'hercul', 'herd', 'heritag', 'herm', 'herman', 'hermion', 'hermit', 'hero', 'heroic', 'heroin', 'heroism', 'hesit', 'hex', 'heywood', 'hezlet', 'hi-tech', 'hiatu', 'hibern', 'hid', 'hidalgo', 'hidden', 'hide', 'hideo', 'hideou', 'hideout', 'hierarchi', 'high', 'high-level', 'high-rank', 'high-tech', 'higher', 'highest', 'highfath', 'highli', 'highway', 'hijack', 'hill', 'himalaya', 'himon', 'hinata', 'hind', 'hinder', 'hindsight', 'hint', 'hip', 'hippolyta', 'hire', 'hiro', 'hiro-kala', 'hiroshima', 'hisako', 'histor', 'histori', 'hit', 'hit-girl', 'hit-monkey', 'hitch', 'hitchhik', 'hitler', 'hitman', 'hitmen', 'hive', 'ho', 'hoax', 'hobbi', 'hobgoblin', 'hodg', 'hogan', 'hogun', 'hogwart', 'hokag', 'hokuto', 'holcroft', 'hold', 'holden', 'hole', 'holi', 'holiday', 'holland', 'holli', 'hollow', 'hollywood', 'holm', 'holocaust', 'hologram', 'holograph', 'holt', 'home', 'homeland', 'homeless', 'homestead', 'hometown', 'homeworld', 'homicid', 'homo', 'homosexu', 'homunculu', 'hone', 'honeymoon', 'hong', 'honor', 'hood', 'hook', 'hope', 'hopeless', 'horcrux', 'hord', 'hormon', 'horn', 'hornet', 'horribl', 'horrif', 'horrifi', 'horror', 'hors', 'horseman', 'horsemen', 'horu', 'hospic', 'hospit', 'host', 'hostag', 'hostil', 'hot', 'hotel', 'hound', 'hour', 'hourman', 'hous', 'household', 'houston', 'howard', 'howev', 'howl', 'howlett', 'hq', 'hub', 'hudson', 'huey', 'hug', 'huge', 'hugh', 'hugo', 'hulk', 'hulk-lik', 'hulked-out', 'human', 'humanist', 'humanitarian', 'humankind', 'humanoid', 'humbl', 'humili', 'humor', 'hundr', 'hung', 'hungari', 'hunger', 'hunt', 'hunter', 'huntress', 'hurl', 'hurri', 'hurrican', 'hurt', 'hurtl', 'husband', 'hush', 'husk', 'hybrid', 'hyde', 'hydra', 'hydraul', 'hydro-man', 'hydrogen', 'hyperion', 'hyperspac', 'hypnobrai', 'hypnosi', 'hypnot', 'hyuga', 'ian', 'ibli', 'ice', 'iceman', 'ici', 'icon', 'id', 'idea', 'ideal', 'idealist', 'ident', 'identif', 'identifi', 'idol', 'idylist', 'ifrit', 'ignit', 'ignor', 'ii', 'iii', 'ill', 'ill-temp', 'ill.', 'illeg', 'illegitim', 'illinoi', 'illuminati', 'illus', 'illusori', 'illustr', 'illyana', 'ilsa', 'iluthin', 'imag', 'imagin', 'imbu', 'imei', 'imf', 'imit', 'immedi', 'immens', 'immers', 'immigr', 'immin', 'immobil', 'immort', 'immortu', 'immun', 'imogen', 'imp', 'impact', 'impal', 'impass', 'impati', 'impend', 'impenetr', 'imper', 'imperfect', 'imperi', 'imperiex', 'imperson', 'impervi', 'implac', 'implant', 'implement', 'impli', 'implic', 'implor', 'import', 'impos', 'imposs', 'impost', 'impostor', 'impregn', 'impress', 'imprint', 'imprison', 'improv', 'improvis', 'impuls', 'impur', 'imra', 'in-gam', 'inabl', 'inact', 'inadvert', 'inanim', 'inc.', 'incap', 'incapacit', 'incarcer', 'incarn', 'inch', 'incid', 'inciner', 'inclin', 'includ', 'incom', 'incompet', 'incorpor', 'increas', 'increasingli', 'incred', 'incrimin', 'incubu', 'incurs', 'inde', 'indebt', 'indel', 'indelicato', 'independ', 'indestruct', 'index', 'indi', 'india', 'indian', 'indiana', 'indic', 'indiffer', 'indigo', 'indigo-1', 'indirectli', 'indiscrimin', 'individu', 'indoctrin', 'induc', 'induct', 'indulg', 'industri', 'industrialist', 'ineffect', 'inert', 'inertia', 'inevit', 'inexor', 'inexperienc', 'inexplic', 'infam', 'infanc', 'infant', 'infantino', 'infantri', 'infatu', 'infect', 'infectia', 'inferior', 'infern', 'inferno', 'infest', 'infiltr', 'infin', 'infinit', 'infirmari', 'inflict', 'influenc', 'info', 'inform', 'information-silk', 'infuri', 'infus', 'ingest', 'inhabit', 'inher', 'inherit', 'inheritor', 'inhibit', 'inhuman', 'initi', 'inject', 'injur', 'injuri', 'injustic', 'ink', 'inmat', 'innat', 'inner', 'innoc', 'innov', 'input', 'inquir', 'inquisitor', 'insan', 'insect', 'insectoid', 'insecur', 'insert', 'insid', 'insight', 'insignia', 'insist', 'inspect', 'inspector', 'inspir', 'instabl', 'instal', 'instanc', 'instant', 'instantli', 'instead', 'instig', 'instil', 'instinct', 'institut', 'institution', 'instruct', 'instructor', 'instrument', 'insuffici', 'insult', 'insur', 'insurg', 'intact', 'intang', 'integr', 'intel', 'intellect', 'intellig', 'intelligencia', 'intend', 'intens', 'intensifi', 'intent', 'inter-dimension', 'interact', 'interbreed', 'intercept', 'interdimension', 'interest', 'interf', 'interfac', 'interfer', 'intergalact', 'intergang', 'interim', 'interlop', 'intern', 'internet', 'interpol', 'interpret', 'interrog', 'interrupt', 'interven', 'intervent', 'interview', 'intim', 'intimid', 'intoler', 'intox', 'intrigu', 'introduc', 'introduct', 'introvert', 'intrud', 'intuit', 'invad', 'invalu', 'invas', 'invent', 'inventor', 'invert', 'invest', 'investig', 'invinc', 'invis', 'invit', 'invok', 'involv', 'invulner', 'ion', 'iq', 'iraq', 'iraqi', 'ireland', 'iren', 'iri', 'irish', 'iron', 'ironi', 'irradi', 'irrat', 'irrit', 'irv', 'irwin', 'isaac', 'ishmael', 'isi', 'isl', 'island', 'isol', 'isotop', 'israel', 'issu', 'itachi', 'itali', 'italian', 'item', 'itsu', 'iv', 'ivan', 'ivanova', 'ive', 'ivi', 'ivo', 'ix', 'izaya', \"j'onn\", \"j'onzz\", \"j'son\", 'j.', 'jabba', 'jace', 'jacen', 'jack', 'jack-jack', 'jackal', 'jacket', 'jacki', 'jackson', 'jacob', 'jacobi', 'jacquelin', 'jade', 'jaeger', 'jagi', 'jahad', 'jai', 'jail', 'jailbreak', 'jaim', 'jain', 'jake', 'jakeem', 'jakku', 'jakob', 'jallakuntilliokan', 'jam', 'jamaan', 'jamaica', 'jamanakai', 'jambo', 'jame', 'jameson', 'jami', 'jane', 'janeiro', 'janet', 'janey', 'janic', 'janin', 'janitor', 'janu', 'januari', 'japan', 'japanes', 'jar', 'jarella', 'jarvi', 'jason', 'jasper', 'java', 'javelin', 'jaw', 'jawa', 'jax', 'jay', 'jazz', 'jc', 'jd', 'jealou', 'jealousi', 'jean', 'jean-luc', 'jean-paul', 'jeanne-mari', 'jeb', 'jedi', 'jeep', 'jefferson', 'jeffrey', 'jeffri', 'jellyfish', 'jemma', 'jenkin', 'jenni', 'jennif', 'jensen', 'jeremiah', 'jericho', 'jerom', 'jerri', 'jersey', 'jess', 'jessica', 'jessn', 'jestro', 'jesu', 'jet', 'jettison', 'jew', 'jewel', 'jewelri', 'jewish', 'jiay', 'jigsaw', 'jihad', 'jill', 'jim', 'jimmi', 'jinchuriki', 'jinmen', 'jinn', 'jip', 'jiraiya', 'jiren', 'jitter', 'jiw', 'jj', 'jla', 'jli', 'joan', 'joann', 'joanna', 'job', 'jocasta', 'jock', 'joe', 'joey', 'jog', 'johann', 'john', 'johnni', 'johnsmey', 'johnson', 'join', 'joint', 'joke', 'joker', 'jokingli', 'jolt', 'jon', 'jona', 'jonah', 'jonathan', 'jone', 'jonin', 'jono', 'jonson', 'jor-el', 'jordan', 'jorgenson', 'joseph', 'josh', 'joshua', 'josiah', 'jotunheim', 'journal', 'journalist', 'journey', 'joy', 'joystick', 'jr.', 'jsa', 'jubile', 'judd', 'judg', 'judgement', 'judgment', 'judi', 'judson', 'juggernaut', 'juli', 'julia', 'juliana', 'julien', 'juliu', 'jump', 'jumper', 'jumpstart', 'jun', 'june', 'jungl', 'junior', 'junk', 'junkpil', 'junkyard', 'jupit', 'juri', 'juspeczyk', 'just', 'justic', 'justifi', 'justin', 'juvenil', 'k', \"k'ad-mon\", \"k'un-lun\", 'k-2so', 'k.', 'ka-zar', 'kabuto', 'kadabra', 'kaeciliu', 'kahn', 'kahndaq', 'kahser', 'kai', 'kaim', 'kain', 'kaishek', 'kakarot', 'kakashi', 'kako', 'kal-el', 'kal-l', 'kale', 'kali', 'kalista', 'kallark', 'kallig', 'kaluu', 'kamehameha', 'kamekeri', 'kan', 'kandor', 'kandorian', 'kane', 'kang', 'kansa', 'kanto', 'kapat', 'kapau', 'kara', 'karat', 'karen', 'karia', 'karima', 'karin', 'karl', 'karla', 'karma', 'karn', 'karnak', 'karnilla', 'karshon', 'kat', 'katana', 'katarthan', 'kataru', 'kate', 'katherin', 'kati', 'kato', 'kayoco', 'kazuhira', 'keen', 'keep', 'keeper', 'keewazi', 'kefla', 'kelex', 'keller', 'kelli', 'ken', 'kendra', 'kenji', 'kennedi', 'kenneth', 'kenobi', 'kenshiro', 'kent', 'kenya', 'kept', 'ketch', 'kettol', 'kevin', 'key', 'keyston', 'kgb', 'kgbeast', 'khadir', 'khan', 'khandaq', 'khonshu', 'khufu', 'khund', 'ki', 'kick', 'kick-ass', 'kid', 'kidnap', 'kidnapp', 'kilgrav', 'kiligrav', 'kill', 'killebrew', 'killer', 'killgrav', 'killian', 'killmong', 'kilowog', 'kim', 'kimora', 'kin', 'kincaid', 'kind', 'kinder', 'kindli', 'kindr', 'kinet', 'king', 'kingdom', 'kingpin', 'kingsguard', 'kinney', 'kinsmen', 'kinsolv', 'kirbi', 'kirk', 'kiss', 'kit', 'kitana', 'kitchen', 'kitti', 'kittridg', 'klarion', 'klaue', 'klaw', 'knee', 'knew', 'knife', 'knight', 'knighton', 'knive', 'knock', 'knockout', 'knot', 'know', 'knowher', 'knowledg', 'known', 'knox', 'knuckl', 'kobra', 'koko', \"komand'r\", 'kombat', 'kon-el', 'kong', 'konoha', 'konohagakur', 'kool-aid', 'koopal', 'kopetski', 'korbal', 'korbinit', 'kord', 'kordax', 'korea', 'korean', 'kori', \"koriand'r\", 'korrek', 'korugar', 'korvu', 'koryak', 'kosmo', 'kosmosian', 'kotal', 'koth', 'kovac', 'kozo', 'kozu', 'krahn', 'krakoa', 'krang', 'krato', 'krau', 'krauser', 'kraven', 'kravinoff', 'kray', 'kree', 'kree-skrul', 'krieger', 'kril', 'krol', 'krona', 'kronika', 'krono', 'krosaki', 'kruncha', 'kruun', 'krux', 'krypto', 'krypton', 'kryptonian', 'kryptonit', 'krystalin', 'kuasa', 'kubik', 'kung', 'kunoichi', 'kurio', 'kurt', 'kurtzberg', 'kuurth', 'kwannon', 'kwesi', 'kworri', 'kyle', 'kyllian', 'kyln', 'l', 'l.a.', 'la', 'lab', 'label', 'labor', 'laboratori', 'labyrinth', 'lace', 'lack', 'lackey', 'lad', 'ladi', 'laforg', 'lago', 'lagoon', 'laid', 'lair', 'laira', 'lake', 'lama', 'lame', 'lament', 'lamp', 'lan', 'lana', 'lanc', 'land', 'landau', 'lander', 'landlord', 'landmark', 'lando', 'lane', 'lang', 'langdon', 'langkowski', 'langowski', 'langstrom', 'languag', 'languish', 'lannist', 'lantern', 'lao', 'lapd', 'laps', 'lar', 'lara', 'larfleez', 'larg', 'larger', 'largest', 'larri', 'larsen', 'laser', 'lash', 'lashina', 'lass', 'lasso', 'last', 'latch', 'late', 'latent', 'later', 'latest', 'latex', 'latter', 'latveria', 'latverian', 'laufey', 'laugh', 'launch', 'launcher', 'laura', 'laurel', 'laurenc', 'lauri', 'lava', 'laveau', 'lavecchia', 'law', 'lawn', 'lawson', 'lawton', 'lawyer', 'lay', 'layla', 'laynia', 'lazaer', 'lazar', 'lazaru', 'lb', 'le', 'lead', 'leader', 'leadership', 'leaf', 'leagu', 'leaguer', 'leak', 'lean', 'leap', 'leapt', 'learn', 'least', 'leather', 'leav', 'lebeau', 'lectur', 'led', 'ledg', 'lee', 'leech', 'left', 'leg', 'legaci', 'legal', 'legend', 'legendari', 'legion', 'legionnair', 'legitim', 'lego', 'lehnsherr', 'lei', 'leia', 'leir', 'lemuria', 'len', 'lena', 'lend', 'length', 'lengthen', 'lengthi', 'lenni', 'lenor', 'lens', 'lent', 'leo', 'leon', 'leonard', 'leper', 'leron', 'lesbian', 'lesli', 'less', 'lesser', 'lesson', 'lest', 'let', 'lethal', 'letter', 'level', 'leverag', 'leviathan', 'lewi', 'lex', 'lexcorp', 'liaison', 'lian', 'liber', 'liberti', 'libra', 'librari', 'licens', 'lie', 'lieuten', 'life', 'life-forc', 'life-form', 'life-model', 'lifeform', 'lifeless', 'lifelong', 'lifespan', 'lifestyl', 'lifetim', 'lift', 'light', 'lighthous', 'lightn', 'lightsab', 'lightweight', 'like', 'likewis', 'lil', 'lila', 'lilandra', 'lili', 'lilin', 'lilith', 'lillian', 'limb', 'limbo', 'limit', 'limitless', 'limousin', 'lin', 'lincoln', 'linda', 'linderman', 'lindi', 'lindsay', 'line', 'lineag', 'linger', 'link', 'lion', 'lionel', 'lip', 'liquid', 'liquor', 'lisa', 'list', 'listen', 'liter', 'literatur', 'lithium', 'litterbug', 'littl', 'littlefing', 'liu', 'liuchow', 'live', 'live-act', 'liverpool', 'livewir', 'liz', 'lizard', 'llan', 'lloyd', 'llyra', 'lmd', 'lo', 'loa', 'load', 'loan', 'lobbi', 'lobe', 'lobo', 'lobotom', 'lobster', 'local', 'locat', 'lock', 'locker', 'locket', 'lockhe', 'lockjaw', 'lockley', 'locomot', 'lodeston', 'lodg', 'loeb', 'loft', 'log', 'logan', 'logic', 'logist', 'logo', 'loi', 'loki', 'loma', 'london', 'lone', 'loneli', 'loner', 'long', 'long-dead', 'long-lost', 'long-term', 'long-thought', 'long-tim', 'longer', 'longev', 'longo', 'longshot', 'longstand', 'longtim', 'lonni', 'look', 'loomworld', 'looni', 'loop', 'loos', 'loose-knit', 'loot', 'lor-zod', 'lord', 'lore', 'lorelei', 'lorena', 'lori', 'lorna', 'lose', 'loser', 'loss', 'lost', 'lot', 'lotho', 'lotteri', 'lotu', 'loud', 'loudli', 'loui', 'louis', 'louisiana', 'love', 'lover', 'low', 'low-down', 'low-level', 'lower', 'lowli', 'loyal', 'loyalist', 'loyalti', 'loyd', 'lt.', 'luca', 'luci', 'lucia', 'lucid', 'lucif', 'luciu', 'luck', 'lucki', 'luckili', 'luckman', 'lucr', 'luggag', 'lugman', 'luigi', 'luke', 'lukin', 'luma', 'lumina', 'luna', 'lunar', 'lunatica', 'lunatik', 'lunch', 'lung', 'lupe', 'lupin', 'lure', 'lurk', 'lurker', 'lust', 'luther', 'luthor', 'luxuri', 'lyja', 'lyko', 'lylla', 'lynx', 'lyon', 'lyra', 'lysa', 'lysandra', \"m'baku\", \"m'gann\", \"m'kraan\", \"m'krann\", \"m'nagalah\", \"m'rinn\", 'm-day', 'm.', 'm.l.f.', 'm.o.d.o.k', 'mac', 'mace', 'macendal', 'machin', 'machineri', 'machu', 'mackenzi', 'mactaggart', 'mactaggert', 'mad', 'madam', 'madara', 'madden', 'maddi', 'maddick', 'made', 'madelin', 'madelyn', 'madison', 'madman', 'madmen', 'madnar', 'madonna', 'madripoor', 'madrox', 'maelstrom', 'maestro', 'maev', 'mafia', 'magazin', 'magda', 'mage', 'mageddon', 'maggi', 'maggia', 'magic', 'magician', 'magick', 'magik', 'magistr', 'magma', 'magnet', 'magneto', 'magnifi', 'magnu', 'magnum', 'magu', 'maid', 'maiden', 'mail', 'maim', 'main', 'mainfram', 'mainland', 'mainli', 'mainlin', 'mainstay', 'mainstream', 'maintain', 'majesti', 'majestor', 'majin', 'major', 'make', 'maker', 'makeshift', 'makeup', 'maki', 'makimura', 'makkari', 'makluan', 'maksai', 'malankov', 'malcolm', 'male', 'malebolgia', 'malekith', 'malevol', 'malfunct', 'malic', 'malici', 'malign', 'mall', 'mallori', 'mallu', 'malu', 'mama', 'mamba', 'mammal', 'mammon', 'man', 'man-bat', 'man-beast', 'man-th', 'man-wolf', 'manag', 'manchest', 'mandalor', 'mandalorian', 'mandarin', 'mandat', 'mandi', 'mando', 'maneuv', 'manfredi', 'manga', 'mangl', 'mangog', 'manhattan', 'manhunt', 'mani', 'maniac', 'manifest', 'manipul', 'mankind', 'mannequin', 'manner', 'manor', 'manserv', 'mansion', 'manslaught', 'manstalk', 'manta', 'manti', 'mantl', 'manual', 'manuel', 'manufactur', 'map', 'mar', 'mar-vel', 'mara', 'maraud', 'march', 'marci', 'marco', 'marcu', 'mardon', 'marduk', 'marg', 'margali', 'margaret', 'mari', 'maria', 'mariah', 'mariko', 'marin', 'mario', 'marion', 'marit', 'mariu', 'marj', 'mark', 'market', 'marko', 'marksman', 'marku', 'marlen', 'marliz', 'marlo', 'maroni', 'maroon', 'marov', 'marr', 'marri', 'marriag', 'marrina', 'marrow', 'marshal', 'marston', 'martha', 'martial', 'martian', 'martin', 'martynec', 'martyr', 'marv', 'marvel', 'marvin', 'masa', 'masamun', 'mascot', 'maseo', 'mask', 'mason', 'masqu', 'masquerad', 'mass', 'massachusett', 'massacr', 'massiv', 'master', 'masteri', 'mastermind', 'masterson', 'mastodon', 'matango', 'match', 'mate', 'materi', 'matern', 'mathia', 'matrix', 'matt', 'matter', 'matthew', 'matti', 'matur', 'maul', 'maverick', 'maw', 'max', 'maxam', 'maxi', 'maxim', 'maxima', 'maximoff', 'maximu', 'maximum', 'maxin', 'maxwel', 'may', 'maya', 'mayb', 'mayer', 'mayfield', 'mayfli', 'mayhem', 'maykr', 'mayor', 'maze', 'mcbride', 'mccabe', 'mccoy', 'mcculloch', 'mckenzi', 'mcnider', 'meachum', 'meal', 'mean', 'meanstreak', 'meant', 'meantim', 'meanwhil', 'measur', 'meat', 'mech', 'mecha', 'mechan', 'mechaniloid', 'medal', 'medallion', 'meddl', 'media', 'medic', 'medicin', 'mediev', 'medit', 'medium', 'medusa', 'meek', 'meet', 'mega', 'megalomaniac', 'megan', 'meggan', 'mekt', 'melani', 'meld', 'mele', 'melinda', 'melisandr', 'melissa', 'melita', 'melkor', 'melt', 'meltdown', 'meltmassif', 'member', 'membership', 'memori', 'men', 'menac', 'menalipp', 'mend', 'menial', 'mental', 'mentallo', 'mention', 'mento', 'mentor', 'meowthra', 'mephil', 'mephisto', 'mera', 'merc', 'merced', 'mercenari', 'mercer', 'merchandis', 'merci', 'merciless', 'mercuri', 'mere', 'meredith', 'merg', 'merger', 'merit', 'merlin', 'merlina', 'merlok', 'merlyn', 'meryl', 'mesmer', 'mesmero', 'mess', 'messag', 'messeng', 'messiah', 'met', 'meta', 'meta-human', 'metabol', 'metagen', 'metahuman', 'metal', 'metalhead', 'metallo', 'metamorph', 'metamorpho', 'metaphys', 'meteor', 'meteorit', 'meteortech', 'meter', 'method', 'metro', 'metron', 'metropoli', 'metrovil', 'mettl', 'mexican', 'mexico', 'meyer', 'mi-6', 'mi13', 'mi6', 'mia', 'miami', 'micah', 'michael', 'michel', 'mick', 'micro', 'micron', 'microscop', 'microvers', 'microwav', 'mid', 'mid-air', 'mid-nit', 'middl', 'middle-ag', 'middle-earth', 'midgard', 'midnight', 'midst', 'midtown', 'midway', 'midwest', 'midwestern', 'midwif', 'might', 'mighti', 'mightiest', 'migrat', 'miguel', 'mikaal', 'mikalek', 'mike', 'mikel', 'mikhail', 'miki', 'milaj', 'mildli', 'mile', 'mileena', 'militari', 'militia', 'mill', 'millennia', 'millennia-old', 'millennium', 'miller', 'million', 'millionair', 'milo', 'milton', 'mimet', 'mimi', 'mimic', 'mimick', 'mina', 'mind', 'mind-control', 'mind-wip', 'mindless', 'mindset', 'mindwip', 'mine', 'miner', 'minerva', 'mini', 'mini-seri', 'miniatur', 'minim', 'minimum', 'minion', 'miniseri', 'minist', 'ministri', 'minor', 'minut', 'minutemen', 'miracl', 'miraclo', 'miracul', 'mirag', 'miranda', 'miriam', 'mirror', 'misako', 'miscalcul', 'miscarriag', 'mischief', 'misde', 'miser', 'miseri', 'misfit', 'misfortun', 'misguid', 'misread', 'miss', 'missil', 'mission', 'mississippi', 'missouri', 'mist', 'mistak', 'mistaken', 'mistakenli', 'mister', 'misti', 'mistook', 'mistreat', 'mistress', 'mistrust', 'misunderstand', 'misus', 'mix', 'mixtur', 'mj', 'mjolnir', 'mk', 'mk.ii', 'mo', 'mob', 'mobil', 'mobiu', 'mobster', 'mock', 'mockingbird', 'mode', 'model', 'modern', 'modern-day', 'modif', 'modifi', 'modok', 'modr', 'modu', 'modul', 'mogo', 'mogol', 'mohind', 'moira', 'moistur', 'mojav', 'mojo', 'mojovers', 'mojoworld', 'mokk', 'mold', 'mole', 'molecul', 'molecular', 'molecularli', 'molest', 'molten', 'mom', 'moment', 'momentari', 'momentarili', 'momentum', 'mon-el', 'monarch', 'monasteri', 'monet', 'monetari', 'money', 'monger', 'mongrel', 'mongul', 'monica', 'monik', 'monitor', 'monk', 'monkey', 'monna', 'monolith', 'monopol', 'monro', 'monster', 'monstros', 'monstrou', 'monstrox', 'montana', 'montesi', 'montgomeri', 'month', 'montoya', 'montreal', 'monument', 'mood', 'moon', 'moon-boy', 'moondragon', 'moonshad', 'moonstar', 'moonston', 'moor', 'mop', 'mope', 'moral', 'moran', 'morbiu', 'mordo', 'moreau', 'moreov', 'morg', 'morgain', 'morgan', 'morgoth', 'morgu', 'moriarti', 'morley', 'morlock', 'morlun', 'morn', 'morningstar', 'morph', 'morpheu', 'morphogenet', 'morri', 'morrison', 'morro', 'morrow', 'mors', 'mort', 'mortal', 'mose', 'mostli', 'motel', 'moth', 'mother', 'mothership', 'motif', 'motion', 'motiv', 'motor', 'motorcycl', 'motorhead', 'mount', 'mountain', 'mourn', 'mous', 'mouth', 'move', 'movement', 'mover', 'movi', 'mr', 'mr.', 'mrs.', 'ms.', 'msf', 'mt', 'much', 'mud', 'mug', 'mugger', 'muir', 'muller', 'multi-billion', 'multipl', 'multipli', 'multitud', 'multivers', 'mumbai', 'munich', 'munit', 'munni', 'munro', 'murad', 'muramasa', 'murder', 'murderworld', 'murdock', 'murphi', 'muscl', 'muscular', 'muse', 'museum', 'mushroom', 'music', 'must', 'mutagen', 'mutant', 'mutant-hunt', 'mutant-kil', 'mutant-kind', 'mutantkind', 'mutat', 'mute', 'mutil', 'muto', 'mutual', 'mvp', 'mxi', 'mxyzptlk', 'mxyztplk', 'myndi', 'myra', 'mysteri', 'mysterio', 'mystic', 'mystiqu', 'myth', 'mythic', 'mytholog', 'n', \"n'astirh\", \"n'garai\", \"n'jadaka\", \"n'jobu\", \"n't\", 'na', 'naboo', 'nabu', 'nadakhan', 'nadira', 'nagato', 'nail', 'naiv', 'nake', 'name', 'namek', 'nameless', 'namor', 'namora', 'namorita', 'nanda', 'nanit', 'nanni', 'nanomachin', 'nanto', 'naomi', 'nap', 'narcot', 'narrowli', 'naruto', 'narya', 'nasa', 'nascent', 'natasha', 'nate', 'nathan', 'nathaniel', 'nation', 'nativ', 'nato', 'natsumi', 'natu', 'natur', 'naught', 'naval', 'navi', 'navig', 'naze', 'nazi', 'near', 'near-death', 'near-fat', 'nearbi', 'nearest', 'nearli', 'nebraska', 'nebula', 'nebulon', 'necess', 'necessari', 'neck', 'necklac', 'necrom', 'necromanc', 'necroplasm', 'necropoli', 'necrosha', 'ned', 'need', 'needl', 'nefari', 'nefaria', 'neg', 'nega', 'nega-band', 'negason', 'negat', 'neglect', 'negoti', 'neig', 'neighbor', 'neighborhood', 'neither', 'nekra', 'nekron', 'nelson', 'nemes', 'nemesi', 'neo', 'neon', 'neophyt', 'nephew', 'neramani', 'nergal', 'neron', 'nerv', 'nervou', 'nest', 'net', 'nether', 'netherworld', 'network', 'neural', 'neutral', 'neutron', 'nevada', 'never', 'neverland', 'nevertheless', 'new', 'new-found', 'newborn', 'newcastl', 'newer', 'newest', 'newfound', 'newli', 'newly-form', 'newlyw', 'news', 'newsboy', 'newspap', 'newsstand', 'next', 'nextwav', 'nexu', 'nicaragua', 'nice', 'nichola', 'nick', 'nicknam', 'nicol', 'nicolosi', 'niec', 'niganda', 'nigel', 'nigh', 'night', 'night-slay', 'nightclub', 'nightcrawl', 'nighthawk', 'nightmar', 'nightshad', 'nightw', 'nihilist', 'nihilu', 'nijo', 'nike', 'niki', 'nimrod', 'nimu', 'nindroid', 'nine', 'nine-tail', 'nineteen', 'ninja', 'ninjago', 'nite', 'nite-owl', 'nitro', 'nitrogen', 'nixon', 'no-on', 'noah', 'nobel', 'nobl', 'nobleman', 'nobodi', 'noc', 'nocturn', 'nocturna', 'nocturnu', 'noir', 'nois', 'noldor', 'nomad', 'nomanisan', 'nomin', 'non', 'non-interfer', 'non-leth', 'non-mut', 'non-team', 'none', 'nonetheless', 'nonexist', 'nora', 'nord', 'norm', 'normal', 'norman', 'normi', 'norn', 'nornheim', 'norri', 'norrisss', 'nors', 'north', 'northern', 'northstar', 'norton', 'nostromo', 'notabl', 'note', 'noth', 'nothing', 'notic', 'notifi', 'notion', 'notori', 'notorieti', 'nova', 'novel', 'novelist', 'novemb', 'novic', 'nowher', 'nsa', 'nth', 'nuada', 'nuclear', 'nuisanc', 'nuke', 'null', 'nullifi', 'number', 'numer', 'nuptial', 'nur', 'nurs', 'nuso', 'nut', 'nya', 'nyc', 'nypd', 'nyssa', \"o'donnel\", \"o'reilli\", 'o.e.', 'o.z', 'oa', 'oan', 'oann', 'oath', 'obadiah', 'obeah', 'obedi', 'oberhaus', 'oberon', 'obes', 'obey', 'obi-wan', 'obito', 'object', 'oblig', 'obliter', 'oblivi', 'oblivion', 'obrien', 'obscur', 'observ', 'observatori', 'obsess', 'obsidian', 'obsolet', 'obstacl', 'obtain', 'obviou', 'obvious', 'occas', 'occasion', 'occult', 'occultist', 'occup', 'occupi', 'occur', 'ocean', 'ocelot', 'ocsh', 'octaviu', 'octob', 'octopu', 'odd', 'oddli', 'odessa', 'odin', 'odinson', 'odym', 'odyssey', 'off-guard', 'off-planet', 'offend', 'offens', 'offer', 'offic', 'offici', 'offshoot', 'offspr', 'often', 'ogashira', 'ogdru', 'oge', 'ogr', 'ogun', 'ohio', 'oil', 'oilix', 'okay', 'oklahoma', 'olantern', 'old', 'older', 'oldest', 'olga', 'oliv', 'olivia', 'olli', 'olnar', 'olsen', 'olson', 'olymp', 'olympian', 'olympu', 'omac', 'omega', 'omen', 'omicron', 'omin', 'omnidroid', 'omnipot', 'omnisci', 'omnitrix', 'omnivers', 'onaga', 'onboard', 'oncom', 'one', 'one-above-al', 'one-man', 'one-on-on', 'one-shot', 'one-tim', 'ongo', 'oni', 'onlook', 'onset', 'onslaught', 'onto', 'onward', 'oolong', 'op', 'opal', 'open', 'openli', 'oper', 'opinion', 'oppon', 'opportun', 'oppos', 'opposit', 'oppress', 'opt', 'optic', 'optim', 'optimist', 'option', 'optitron', 'oracl', 'orang', 'orb', 'orbit', 'orbot', 'orchestr', 'ord', 'ordeal', 'order', 'orderli', 'ordinari', 'organ', 'organis', 'orient', 'origin', 'orin', 'orion', 'orko', 'orlean', 'orm', 'orochimaru', 'ororo', 'orphan', 'orphan-mak', 'orphanag', 'orrgo', 'orson', 'osborn', 'oscorp', 'osgood', 'osiri', 'oss', 'osterman', 'oswald', 'otacon', 'other', 'other-dimension', 'otherdimension', 'otherwis', 'otherworld', 'otherworldli', 'ottawa', 'otto', 'oust', 'out', 'outback', 'outbreak', 'outcast', 'outcom', 'outer', 'outfit', 'outing', 'outlaw', 'outlet', 'outlook', 'outmatch', 'outnumb', 'outpost', 'outrag', 'outright', 'outsid', 'outskirt', 'outsmart', 'outward', 'outwardli', 'outwit', 'outworld', 'overal', 'overboard', 'overcam', 'overcom', 'overdos', 'overgirl', 'overhead', 'overhear', 'overheard', 'overjoy', 'overlap', 'overli', 'overload', 'overlook', 'overlord', 'overnight', 'overpow', 'overprotect', 'overrid', 'overrun', 'oversaw', 'overse', 'oversea', 'overtak', 'overtaken', 'overthrew', 'overthrow', 'overthrown', 'overtkil', 'overwhelm', 'owe', 'owen', 'owl', 'own', 'owner', 'ownership', 'oxford', 'oxygen', 'oyama', 'ozymandia', \"p'tah\", 'p.i.x.a.l', 'pa', 'pacif', 'pacifist', 'pack', 'packag', 'paco', 'pact', 'pad', 'padawan', 'pagan', 'page', 'paibok', 'paid', 'paig', 'pain', 'paint', 'pair', 'palac', 'paladin', 'pale', 'palm', 'palmer', 'palpatin', 'pamela', 'pan', 'pan-galact', 'pandemonium', 'pandora', 'panel', 'panic', 'panick', 'pant', 'pantha', 'pantheon', 'panther', 'papa', 'paper', 'para-med', 'parachut', 'parad', 'parademon', 'paradis', 'paradox', 'parallax', 'parallel', 'paralysi', 'paralyz', 'paramed', 'paramilitari', 'paranoia', 'paranoid', 'paranorm', 'parapleg', 'parasit', 'parbat', 'pardon', 'parent', 'parentag', 'pari', 'pariah', 'park', 'parker', 'parliament', 'parnel', 'parodi', 'parol', 'parr', 'part', 'part-tim', 'partak', 'parti', 'partial', 'particip', 'particl', 'particular', 'particularli', 'partli', 'partner', 'partnership', 'paso', 'pass', 'passag', 'passeng', 'passion', 'passiv', 'passport', 'past', 'pastor', 'pat', 'patch', 'patent', 'patern', 'path', 'pathway', 'patienc', 'patient', 'patriarch', 'patrick', 'patriot', 'patrol', 'patron', 'patronag', 'patsi', 'pattern', 'patterson', 'patti', 'paul', 'paus', 'pave', 'pawn', 'paxton', 'pay', 'payment', 'paz', 'peac', 'peacekeep', 'peach', 'peak', 'pearl', 'peel', 'peer', 'pegasu', 'peggi', 'peliali', 'pen', 'pena', 'penal', 'penanc', 'penchant', 'pend', 'pendant', 'penetr', 'penguin', 'peninsula', 'penitentiari', 'penniless', 'pennsylvania', 'pennyworth', 'pentagon', 'pentagram', 'penthous', 'peopl', 'pepper', 'per', 'perceiv', 'percent', 'percept', 'perci', 'perciv', 'perez', 'perfect', 'perfectli', 'perform', 'perhap', 'peril', 'perimet', 'period', 'perish', 'perman', 'permiss', 'permit', 'perpetr', 'perpetu', 'perri', 'persecut', 'persephon', 'persist', 'person', 'persona', 'personi', 'personif', 'personnel', 'perspect', 'persuad', 'persuas', 'pervers', 'pestil', 'pet', 'pete', 'peter', 'peterson', 'petit', 'petrelli', 'petrifi', 'petti', 'pettigrew', 'petyr', 'ph.d.', 'phaedra', 'phaethon', 'phalanx', 'phantom', 'pharaoh', 'pharmaceut', 'phase', 'phelp', 'phenomenon', 'pheromon', 'phi', 'phil', 'philadelphia', 'philanthropi', 'philip', 'phillip', 'phillipu', 'philosoph', 'philosophi', 'phinea', 'phobo', 'phoenix', 'phone', 'phoni', 'photo', 'photograph', 'photon', 'phrase', 'phyla', 'phyla-vel', 'physic', 'physician', 'physicist', 'physiolog', 'physiqu', 'picard', 'piccolo', 'pick', 'pickl', 'picnic', 'pictur', 'pie', 'piec', 'piecem', 'pier', 'pierc', 'pierrot', 'pieter', 'pietro', 'pig', 'pike', 'piko', 'pile', 'pilgrim', 'pilgrimag', 'pill', 'pillag', 'pillar', 'pilot', 'pimp', 'pin', 'pineda', 'pinehearst', 'pink', 'piotr', 'pip', 'pipe', 'piper', 'pirat', 'pirina', 'pistol', 'pit', 'pitch', 'pitcher', 'piti', 'pitrel', 'pittsburgh', 'pivot', 'pixi', 'pizza', 'pla', 'place', 'placement', 'plaga', 'plagu', 'plain', 'plaincloth', 'plan', 'plane', 'planet', 'planet.fil', 'plant', 'plantman', 'plasma', 'plastic', 'plastiqu', 'plate', 'platform', 'play', 'playabl', 'playboy', 'player', 'playmat', 'plaza', 'plea', 'plead', 'pleas', 'pleasant', 'pleasur', 'pledg', 'plight', 'pliskin', 'plot', 'plott', 'ploy', 'plu', 'pluck', 'plug', 'plummet', 'plunder', 'plung', 'pluto', 'pmc', 'poacher', 'pocket', 'pocket-dimens', 'pod', 'poindext', 'point', 'point-blank', 'pointless', 'pois', 'poison', 'poke', 'pokolistan', 'poland', 'polar', 'polari', 'polaris/malic', 'pole', 'polemachu', 'polestar', 'polic', 'policeman', 'policemen', 'polici', 'polish', 'polit', 'politician', 'pollut', 'poln', 'polyalloy', 'pond', 'ponder', 'pool', 'poor', 'poorli', 'pop', 'popul', 'populac', 'popular', 'porcupin', 'porker', 'porm', 'porsch', 'port', 'portal', 'portion', 'portray', 'pose', 'poseidon', 'poseidoni', 'posit', 'positron', 'poss', 'possess', 'possessor', 'possibl', 'post', 'post-crisi', 'post-war', 'posthum', 'postpon', 'pot', 'potara', 'potent', 'potenti', 'potion', 'pott', 'potter', 'pouch', 'pound', 'pour', 'poverti', 'powder', 'powel', 'power', 'power-dampen', 'powerhous', 'powerless', 'pr', 'practic', 'practition', 'praetor', 'pragu', 'prairi', 'prais', 'prank', 'pratt', 'praxagora', 'pray', 'prayer', 'pre-crisi', 'preach', 'preacher', 'preced', 'precinct', 'preciou', 'preciouston', 'precis', 'precognit', 'predat', 'predecessor', 'predestin', 'predetermin', 'predica', 'predict', 'preemin', 'preemptiv', 'prefer', 'pregnanc', 'pregnant', 'prematur', 'premier', 'prentiss', 'preoccupi', 'prep', 'prepar', 'presenc', 'present', 'preserv', 'presid', 'presidenti', 'press', 'pressur', 'prestigi', 'presum', 'preteen', 'pretend', 'pretens', 'pretext', 'pretti', 'prevail', 'prevent', 'previou', 'previous', 'prey', 'prez', 'pri', 'price', 'pride', 'priest', 'priestess', 'primari', 'primarili', 'primatech', 'prime', 'primev', 'primit', 'primros', 'primu', 'princ', 'princess', 'princeton', 'princip', 'principl', 'print', 'prior', 'prioriti', 'prisca', 'priscilla', 'prison', 'privaci', 'privat', 'privileg', 'prix', 'prize', 'pro-mut', 'pro-registr', 'proactiv', 'probabl', 'probe', 'problem', 'problemat', 'proce', 'procedur', 'proceed', 'process', 'processor', 'proclaim', 'procur', 'prod', 'prodigi', 'produc', 'product', 'prof.', 'profess', 'profession', 'professor', 'profici', 'profil', 'profit', 'profound', 'progenitor', 'program', 'progress', 'project', 'projector', 'prolong', 'prometheu', 'promin', 'promis', 'promot', 'prompt', 'promptli', 'prone', 'pronounc', 'proof', 'propaganda', 'propel', 'proper', 'properli', 'properti', 'propheci', 'prophesi', 'prophet', 'proport', 'propos', 'proposit', 'propuls', 'prosecut', 'prosh', 'prospect', 'prosper', 'prosthes', 'prosthet', 'prostitut', 'protagonist', 'protect', 'protector', 'proteg', 'protest', 'proteu', 'protocol', 'prototyp', 'protract', 'proud', 'proudstar', 'prove', 'proven', 'provid', 'provinc', 'provok', 'prowess', 'prowl', 'proxi', 'proxim', 'proxima', 'pryde', 'pryor', 'pryor-summ', 'pseudoderm', 'pseudonym', 'psi', 'psi-borg', 'psi-shield', 'psion', 'psionic', 'psych', 'psychiatr', 'psychiatrist', 'psychic', 'psycho', 'psycho-man', 'psycho-pir', 'psycholog', 'psychologist', 'psychopath', 'psychot', 'psylock', 'pub', 'puberti', 'public', 'publicli', 'publish', 'puck', 'pull', 'pulp', 'puls', 'puma', 'pummel', 'pump', 'pumpkin', 'punch', 'punish', 'pupil', 'puppet', 'purchas', 'pure', 'purg', 'purifi', 'puriti', 'purpl', 'purpos', 'purs', 'pursu', 'pursuer', 'pursuit', 'push', 'pushkin', 'put', 'puzzl', 'pyg', 'pyko', 'pym', 'pyramid', 'pyro', 'pyrokinesi', 'pyrokinet', 'pythia', 'python', 'pythor', 'quadrant', 'quak', 'qualifi', 'qualiti', 'quan', 'quanhooga', 'quantum', 'quarantin', 'quark', 'quarrel', 'quarri', 'quarter', 'quartermain', 'quartet', 'quasar', 'quasi-son', 'quatermain', 'queen', 'queen/green', 'quell', 'quentin', 'querl', 'quest', 'question', 'quick', 'quickli', 'quicksilv', 'quiet', 'quietli', 'quill', 'quinci', 'quinjet', 'quinn', 'quinzel', 'quit', 'quiver', 'qurac', 'qward', 'r', 'r2-d2', 'ra', 'rabbit', 'raccoon', 'race', 'racer', 'rachel', 'racial', 'racist', 'racket', 'radar', 'radcliff', 'radd', 'radiant', 'radiat', 'radic', 'radio', 'radioact', 'raditz', 'radiu', 'raft', 'rag', 'rage', 'ragnarok', 'ragtag', 'rahn', 'rahul', 'raid', 'raiden', 'rail', 'railroad', 'rain', 'rainbow', 'rais', 'rajaki', 'ralli', 'ralph', 'ram', 'rama', 'rama-tut', 'raman', 'rambeau', 'rambo', 'rames', 'ramon', 'rampag', 'rampant', 'rams', 'ramsey', 'ran', 'rand', \"rand-k'ai\", 'randal', 'randolph', 'random', 'rang', 'ranger', 'rank', 'rann', 'rannian', 'ransack', 'ransom', 'rant', 'ranx', 'rao', 'raoh', 'rape', 'raphael', 'rapid', 'rapidli', 'raptor', 'raptur', 'rare', 'rasber', 'rash', 'rasputin', 'rat', 'ratcatch', 'rate', 'ratha', 'rathaway', 'rather', 'ration', 'ravag', 'rave', 'raven', 'ravencroft', 'ravonna', 'raw', 'rawhid', 'rawlin', 'raxalu', 'raxton', 'ray', 'raya', 'raymond', 'rayner', 'raza', 'raze', 'razor', 'razor-fist', 'razorback', 'razorfist', 're-activ', 're-appear', 're-captur', 're-creat', 're-emerg', 're-establish', 're-form', 're-integr', 're-merg', 're-open', 're-pow', 'reabsorb', 'reach', 'react', 'reaction', 'reactiv', 'reactor', 'reactron', 'read', 'reader', 'readi', 'readili', 'real', 'real-lif', 'realis', 'realist', 'realiti', 'reality-alt', 'realiz', 'realli', 'realm', 'reanim', 'reaper', 'reappear', 'rear', 'reardon', 'reason', 'reassembl', 'reassert', 'reassign', 'reassur', 'reaver', 'reawaken', 'rebar', 'rebecca', 'rebel', 'rebelli', 'rebellion', 'rebirth', 'reboot', 'reborn', 'rebuf', 'rebuild', 'rebuilt', 'recal', 'recaptur', 'receiv', 'recent', 'recept', 'receptor', 'recharg', 'rechristen', 'reciev', 'recipi', 'reciproc', 'recit', 'reckless', 'reclaim', 'reclus', 'recogn', 'recognis', 'recognit', 'recogniz', 'recollect', 'recommend', 'recon', 'reconcil', 'reconcili', 'reconfigur', 'reconnaiss', 'reconnect', 'reconsid', 'reconstitut', 'reconstruct', 'reconven', 'record', 'recount', 'recov', 'recoveri', 'recreat', 'recruit', 'recuper', 'recur', 'red', 'red-and-blu', 'red-head', 'redbird', 'reded', 'redeem', 'redempt', 'redesign', 'redfield', 'redip', 'redirect', 'rediscov', 'reduc', 'redund', 'reec', 'reed', 'reef', 'reemerg', 'rees', 'reestablish', 'refer', 'referenc', 'refin', 'reflect', 'reflex', 'refocus', 'reform', 'refrain', 'refriger', 'refug', 'refuge', 'refus', 'regain', 'regard', 'regardless', 'regener', 'regim', 'regimen', 'regiment', 'region', 'regist', 'registr', 'regress', 'regret', 'regroup', 'regular', 'regularli', 'rehabilit', 'reich', 'reid', 'reign', 'reignfir', 'reilli', 'rein', 'reincarn', 'reinforc', 'reinhardt', 'reinstat', 'reintegr', 'reinvent', 'reiter', 'reject', 'rejoin', 'rejuven', 'rekindl', 'rel', 'relaps', 'relat', 'relationship', 'relax', 'releas', 'releg', 'relent', 'reli', 'relic', 'relief', 'reliev', 'religi', 'religion', 'relinquish', 'relish', 'reliv', 'reloc', 'reluct', 'reluctantli', 'remain', 'remaind', 'remak', 'remand', 'remark', 'rematch', 'rememb', 'remi', 'remind', 'reminisc', 'remnant', 'remors', 'remot', 'remov', 'ren', 'renam', 'render', 'rendezv', 'rene', 'reneg', 'renegad', 'renew', 'renounc', 'renown', 'rent', 'reopen', 'reorgan', 'repair', 'repeal', 'repeat', 'repeatedli', 'repel', 'repent', 'replac', 'replenish', 'repli', 'replic', 'replica', 'repliforc', 'reploid', 'report', 'reportedli', 'repres', 'represent', 'repress', 'reprimand', 'reproduc', 'reproduct', 'reprogram', 'reptil', 'reptilian', 'republ', 'repuls', 'repulsor', 'reput', 'request', 'requir', 'rescu', 'research', 'resembl', 'resent', 'reserv', 'reservist', 'reset', 'reshap', 'resid', 'residu', 'resign', 'resili', 'resist', 'resolv', 'resort', 'resourc', 'respect', 'respond', 'respons', 'rest', 'restart', 'restaur', 'restor', 'restrain', 'restraint', 'restrict', 'restructur', 'result', 'resum', 'resurfac', 'resurg', 'resurrect', 'resuscit', 'retain', 'retak', 'retali', 'retcon', 'rethink', 'retir', 'retort', 'retrac', 'retract', 'retreat', 'retribut', 'retriev', 'return', 'reunion', 'reunit', 'rev', 'revamp', 'reve', 'reveal', 'revel', 'reveng', 'rever', 'reverbium', 'reverend', 'revers', 'reverse-flash', 'revert', 'revis', 'revit', 'reviv', 'revok', 'revolt', 'revolut', 'revolutionari', 'revolv', 'reward', 'rewrit', 'rex', 'rey', 'reynold', 'rhaegar', 'rhane', 'rhapsodi', 'rhino', 'rhode', 'rhodey', 'rhyme', 'rib', 'ribbon', 'rican', 'ricardo', 'rice', 'rich', 'richard', 'richmond', 'richter', 'rick', 'ricki', 'ricochet', 'rictor', 'rid', 'riddl', 'riddler', 'ride', 'rider', 'ridicul', 'rifl', 'rift', 'rig', 'rigellian', 'right', 'right-hand', 'right-w', 'rigor', 'riker', 'rikki', 'rinehart', 'ring', 'ringmast', 'rintrah', 'rio', 'riot', 'rip', 'ripe', 'ripper', 'riptid', 'rise', 'risen', 'risk', 'risqu', 'rita', 'ritchi', 'rite', 'ritual', 'rival', 'rivalri', 'river', 'riverrun', 'rnr', 'road', 'roam', 'roar', 'rob', 'robber', 'robberi', 'robbi', 'robbin', 'robe', 'robern', 'robert', 'roberta', 'roberto', 'robertson', 'robin', 'robinson', 'robot', 'robotman', 'robotnik', 'rocca', 'roch', 'rock', 'rocket', 'rocki', 'rod', 'rode', 'rodor', 'rodriguez', 'roger', 'rogu', \"roh'kar\", 'role', 'roll', 'rom', 'roma', 'roman', 'romanc', 'romani', 'romanoff', 'romant', 'rome', 'romeo', 'romulu', 'ron', 'ronald', 'ronan', 'ronin', 'ronni', 'roof', 'rooftop', 'rook', \"rook'shir\", 'rooki', 'room', 'roommat', 'roosevelt', 'root', 'rope', 'rori', 'rorschach', 'rosa', 'rosalina', 'rosalind', 'rose', 'rosemari', 'rosenberg', 'rosewood', 'roshi', 'rosi', 'ross', 'roster', 'rot', 'rotat', 'roth', 'rothstein', 'rottwel', 'roug', 'rough', 'roughli', 'roughous', 'roulett', 'round', 'rourk', 'rous', 'rout', 'routin', 'rowland', 'roxxon', 'roy', 'royal', 'royalti', 'roz', 'rubber', 'rubbl', 'rubi', 'rucku', 'rude', 'rudi', 'rudimentari', 'ruin', 'rule', 'ruler', 'rumekistan', 'rumor', 'run', 'run-in', 'runaway', 'rune', 'runner', 'ruptur', 'rusch', 'ruse', 'rush', 'russel', 'russia', 'russian', 'russo', 'rusti', 'ruthless', 'ruthlessli', 'rutland', 'ruve', 'ryan', 'ryker', 'rynda', 'ryo', 'ryuken', 'ryuko', \"s'ym\", 's.h.i.e.l.d', 's.h.i.e.l.d.', 's.h.i.e.l.d..', 's.o.', 's.t.a.r', 's.t.a.r.', 's.t.r.i.k.', 's.t.r.i.p.', 's.w.o.r.d', 'sabah', 'saber', 'sabina', 'sabl', 'sabotag', 'sabra', 'sabretooth', 'sachiko', 'sack', 'sacorria', 'sacr', 'sacrif', 'sacrific', 'sad', 'sadden', 'sadi', 'sadist', 'sadli', 'safe', 'safe-hous', 'safeguard', 'safehous', 'safekeep', 'safer', 'safeti', 'saga', 'sage', 'sahara', 'sai', 'said', 'saigon', 'saiko', 'sail', 'saint', 'saint-clair', 'sainte-cloud', 'saitama', 'saiyajin', 'saiyan', 'sakaar', 'sake', 'sakura', 'sal', 'salamand', 'sale', 'salem', 'salli', 'salom', 'saloon', 'salt', 'salvador', 'salvag', 'salvat', 'sam', 'sampl', 'sampson', 'samson', 'samuel', 'samukai', 'samurai', 'san', 'sanction', 'sanctorum', 'sanctuari', 'sanctum', 'sand', 'sandal', 'sander', 'sandi', 'sandman', 'sandov', 'sandra', 'sandsmark', 'sangtre', 'saniti', 'sank', 'sannin', 'santa', 'santo', 'saonel', 'sapien', 'sapper', 'sapphir', 'sara', 'sarah', 'sarcast', 'sarg', 'sargon', 'sasha', 'sasquatch', 'sasuk', 'sat', 'satan', 'satana', 'satannish', 'sate', 'satellit', 'satisfact', 'satisfi', 'saturn', 'saturnyn', 'saunder', 'sauron', 'savag', 'save', 'savior', 'savitar', 'saw', 'sawyer', 'say', 'sazia', 'scabbard', 'scale', 'scam', 'scan', 'scandal', 'scar', 'scarab', 'scare', 'scarecrow', 'scarfac', 'scari', 'scarlet', 'scarlett', 'scatter', 'scaveng', 'scenario', 'scene', 'scent', 'scepter', 'schedul', 'scheme', 'schexnayd', 'schiff', 'schism', 'schist', 'schmidt', 'scholar', 'scholarship', 'school', 'schorr', 'schott', 'schultz', 'scienc', 'scientif', 'scientist', 'scimitar', 'scold', 'scoop', 'scorch', 'score', 'scorpia', 'scorpion', 'scotland', 'scott', 'scotti', 'scour', 'scourg', 'scout', 'scr-hd', 'scrambl', 'scrap', 'scrapper', 'scratch', 'scream', 'screen', 'scroll', 'scuffl', 'sculptur', \"scy'ar\", 'sea', 'seagat', 'seal', 'sean', 'seanc', 'search', 'season', 'seat', 'seattl', 'sebastian', 'seclud', 'seclus', 'second', 'second-in-command', 'secondari', 'secreci', 'secret', 'secretari', 'secretli', 'sect', 'section', 'sector', 'secur', 'sedat', 'seduc', 'see', 'seed', 'seek', 'seeker', 'seem', 'seemingli', 'seen', 'seer', 'seismic', 'seiz', 'select', 'selen', 'self', 'self-defens', 'self-destruct', 'self-impos', 'self-styl', 'selfish', 'selflessli', 'selina', 'sell', 'selv', 'selys', 'semblanc', 'semest', 'semi-act', 'semi-retir', 'senat', 'send', 'senior', 'senju', 'sens', 'sensat', 'sensei', 'sensit', 'sensor', 'sensori', 'sent', 'sentenc', 'sentienc', 'sentient', 'sentiment', 'sentinel', 'sentri', 'separ', 'septemb', 'sequenc', 'sequest', 'ser', 'seraph', 'serbian', 'sergeant', 'sergei', 'seri', 'serial', 'seriesedit', 'seriou', 'serious', 'serpent', 'serpentin', 'serpentina', 'sersi', 'serum', 'serv', 'servant', 'servic', 'servitud', 'session', 'set', 'setback', 'seth', 'settl', 'settlement', 'seven', 'seventeen', 'sever', 'severu', 'sew', 'sewer', 'sex', 'sexual', 'sgt', 'shackl', 'shade', 'shado', 'shadow', 'shadowcat', 'shadowi', 'shadowpact', 'shadowqueen', 'shaft', 'shagohod', 'shahra', 'shaitan', 'shakari', 'shake', 'shaken', 'shall', 'sham', 'shaman', 'shambl', 'shame', 'shang', 'shang-chi', 'shanghai', 'shannon', 'shanoa', 'shao', 'shaolin', 'shapanka', 'shape', 'shape-chang', 'shape-shift', 'shaper', 'shapeshift', 'shard', 'share', 'sharingan', 'shark', 'sharon', 'sharp', 'sharra', 'shatter', 'shatterstar', 'shave', 'shaw', 'shay', 'shazam', 'shdb', 'she-dragon', 'she-hulk', 'shear', 'sheath', 'shed', 'sheenarian', 'sheer', 'sheerah', 'sheila', 'shell', 'shelley', 'shelter', 'shepherd', 'sheridan', 'sheriff', 'sherman', 'sheva', 'shi', \"shi'ar\", 'shialmar', 'shiar', 'shield', 'shift', \"shim'tar\", 'shimura', 'shin', 'shinagawa', 'shine', 'shingen', 'shinken', 'shinobi', 'ship', 'shipment', 'shireen', 'shirle', 'shirt', 'shiva', 'shmidt', 'shock', 'shocker', 'shoe', 'shogun', 'shondra', 'shook', 'shoot', 'shootout', 'shop', 'shore', 'short', 'short-circuit', 'short-liv', 'shorten', 'shortli', 'shot', 'shotgun', 'shou-lao', 'shoulder', 'shout', 'shove', 'show', 'showdown', 'shower', 'shown', 'shrank', 'shrapnel', 'shred', 'shriek', 'shrink', 'shroud', 'shrug', 'shrunk', 'shrunken', 'shu', 'shuffl', 'shuma-gorath', 'shun', 'shunt', 'shuri', 'shuriken', 'shut', 'shuttl', 'si', 'siberia', 'sibl', 'sicili', 'sick', 'side', 'side-by-sid', 'side-effect', 'sidekick', 'sidelin', 'sider', 'sidewind', 'sidiou', 'sidri', 'sieg', 'siegfri', 'siegmund', 'sif', 'sight', 'sigil', 'sigint', 'sigma', 'sign', 'signal', 'signatur', 'signific', 'significantli', 'silenc', 'silent', 'silicon', 'silk', 'silmaril', 'silver', 'silverclaw', 'silverman', 'sim', 'similar', 'similarli', 'simmon', 'simon', 'simpl', 'simpli', 'simpson', 'simul', 'simultan', 'sin', 'sinc', 'sincer', 'sinclair', 'sindel', 'sinestro', 'sing', 'singapor', 'singer', 'singl', 'single-handedli', 'singular', 'sinist', 'sink', 'sinner', 'siobhan', 'siphon', 'sir', 'sire', 'siredam', 'siren', 'siriu', 'siryn', 'sister', 'sisterhood', 'sit', 'site', 'sith', 'situat', 'sivana', 'six', 'sixteen', 'sixth', 'size', 'size-chang', 'skaar', 'skadi', 'skale', 'skater', 'skeet', 'skelet', 'skeleton', 'skeptic', 'skewer', 'ski', 'skid', 'skill', 'skin', 'skinless', 'skip', 'skirmish', 'skornn', 'skreet', 'skrull', 'skulkin', 'skull', 'skullfir', 'skurg', 'skuttlebutt', 'sky', 'skye', 'skynet', 'skyscrap', 'skywalk', 'slab', 'slabsid', 'slade', 'slag', 'slain', 'slam', 'slap', 'slapstick', 'slash', 'slasher', 'slatteri', 'slaughter', 'slave', 'slaver', 'slaveri', 'slay', 'slayback', 'slayer', 'slaymast', 'sledg', 'sleep', 'sleeper', 'slender', 'slept', 'slew', 'slice', 'slide', 'slideway', 'slight', 'slightli', 'slip', 'slit', 'slither', 'slithraa', 'slizzath', 'sloan', 'slow', 'slowli', 'slug', 'sluggo', 'slum', 'smack', 'small', 'smaller', 'smallvil', 'smart', 'smart-mouth', 'smartest', 'smash', 'smasher', 'smear', 'smell', 'smile', 'smiley', 'smite', 'smith', 'smither', 'smitti', 'smoak', 'smoke', 'smuggl', 'smyth', 'snag', 'snake', 'snake-ey', 'snakeroot', 'snap', 'snape', 'snart', 'snatch', 'sneak', 'sneer', 'sniper', 'snow', 'snowbird', 'snuck', 'so-cal', 'soar', 'sobek', 'sobrieti', 'soccer', 'social', 'socialit', 'societi', 'sociopath', 'sodam', 'soft', 'softwar', 'soil', 'sokolov', 'sokovia', 'sol', 'solac', 'solar', 'solari', 'solarr', 'sold', 'soldier', 'sole', 'soleanna', 'solid', 'solidu', 'solitari', 'solitud', 'solli', 'solo', 'solomon', 'solovar', 'solut', 'solv', 'someday', 'somehow', 'someon', 'somer', 'someth', 'sometim', 'somewhat', 'somewher', 'son', 'sonar', 'sondheim', 'songbird', 'sonic', 'sonya', 'soon', 'sooner', 'soong', 'sooth', 'sop', 'sophi', 'sophist', 'soranik', 'sorcer', 'sorceress', 'sorceri', 'sorri', 'sorrow', 'sort', 'soto', 'sought', 'soul', 'soul-gem', 'soulgem', 'soulless', 'soulsword', 'sound', 'soundli', 'sour', 'sourc', 'south', 'southeast', 'souther', 'southern', 'souvenir', 'sovereign', 'soviet', 'space', 'space-st', 'space-tim', 'spacecraft', 'spaceknight', 'spaceport', 'spacer', 'spaceship', 'spaceway', 'spacewheel', 'spain', 'span', 'spanish', 'spar', 'spare', 'spark', 'sparrow', 'spartan', 'spartax', 'spartoi', 'spat', 'spawn', 'speak', 'spear', 'spearhead', 'speci', 'special', 'specialist', 'specialti', 'specif', 'specimen', 'spectacular', 'spectat', 'spector', 'spectr', 'spectral', 'spectrum', 'specul', 'sped', 'speech', 'speechless', 'speed', 'speedbal', 'speedboyz', 'speeder', 'speedi', 'speedster', 'speedsuit', 'spell', 'spencer', 'spend', 'spent', 'sphere', 'sphinx', 'spi', 'spider', 'spider-armi', 'spider-girl', 'spider-island', 'spider-lik', 'spider-man', 'spider-sens', 'spider-totem', 'spider-trac', 'spider-uk', 'spider-woman', 'spider-women', 'spidey', 'spike', 'spill', 'spin', 'spin-off', 'spinal', 'spine', 'spineless', 'spinjitzu', 'spinner', 'spiral', 'spire', 'spirit', 'spiritu', 'spit', 'spite', 'spitfir', 'spivot', 'splice', 'splinter', 'split', 'spoil', 'spoiler', 'spoke', 'spoken', 'sponsor', 'spontan', 'spook', 'sporad', 'spore', 'sport', 'spot', 'spotlight', 'spout', 'sprang', 'spray', 'spread', 'spree', 'spring', 'springdal', 'sprint', 'sprite', 'sprixi', 'sprout', 'sprung', 'spurn', 'spyke', 'spymast', 'squad', 'squadron', 'squar', 'squeez', 'squidboy', 'squir', 'squirrel', 'sr.', 'ssangyong', 'ssr', 'st', 'st.', 'stab', 'stabil', 'stabl', 'staci', 'stack', 'staff', 'stage', 'stagg', 'stain', 'stair', 'stake', 'stalem', 'stalk', 'stalker', 'stall', 'stalwart', 'stamford', 'stamina', 'stamped', 'stan', 'stanc', 'stand', 'standard', 'standstil', 'stane', 'stanni', 'star', 'star-lord', 'star-shark', 'star-spangl', 'starbolt', 'stardriv', 'stardust', 'stare', 'starfir', 'starfox', 'stargirl', 'stargod', 'starhawk', 'starjamm', 'stark', 'stark-fujikawa', 'starl', 'starlight', 'starlord', 'starman', 'starr', 'starro', 'starship', 'starsmor', 'start', 'startl', 'starv', 'stasi', 'state', 'state-of-the-art', 'statement', 'statesman', 'static', 'station', 'statu', 'statur', 'staunch', 'stave', 'stay', 'stead', 'steadi', 'steadili', 'steal', 'stealth', 'steam', 'steed', 'steel', 'steelwork', 'steer', 'stefan', 'stein', 'stellar', 'stellarax', 'stellarium', 'stem', 'step', 'step-broth', 'stepbroth', 'stepfath', 'stepford', 'stephani', 'stephen', 'stepmoth', 'steppenwolf', 'steril', 'stern', 'steve', 'steven', 'stevi', 'stewart', 'stick', 'still', 'stillman', 'stilt-man', 'stimul', 'stimuli', 'sting', 'stingare', 'stint', 'stir', 'stirk', 'stock', 'stockpil', 'stoke', 'stole', 'stolen', 'stomach', 'stomp', 'stone', 'stoneworld', 'stood', 'stop', 'storag', 'store', 'stori', 'stork', 'storm', 'stormblud', 'stormbreak', 'stormi', 'stormtroop', 'storylin', 'storytel', 'stow', 'straight', 'straighten', 'strain', 'strand', 'strang', 'strangelov', 'stranger', 'strangl', 'strap', 'strateg', 'strategi', 'strategist', 'stray', 'streak', 'stream', 'street', 'street-level', 'street-smart', 'strength', 'strengthen', 'stress', 'stretch', 'stricken', 'strict', 'strictli', 'strife', 'strike', 'strikeforc', 'string', 'strip', 'stroke', 'stromm', 'strong', 'stronger', 'strongest', 'stronghold', 'strongli', 'strontia', 'strontian', 'struck', 'strucker', 'structur', 'struggl', 'strut', 'stryfe', 'stryker', 'stuart', 'stubborn', 'stuck', 'student', 'studi', 'studio', 'stuff', 'stumbl', 'stun', 'stunt', 'stuntman', 'stupor', 'style', 'styx', 'su', 'sub', 'sub-marin', 'sub-zero', 'subatom', 'subcon', 'subconsci', 'subdu', 'subject', 'subjug', 'sublim', 'sublimin', 'submarin', 'submerg', 'submiss', 'submit', 'subordin', 'subsequ', 'subservi', 'substanc', 'substanti', 'substitut', 'subterranean', 'subtl', 'subtli', 'suburb', 'subvers', 'subvert', 'subway', 'succe', 'succeed', 'success', 'successor', 'succubu', 'succumb', 'suck', 'sudan', 'sudden', 'suddenli', 'sue', 'suffer', 'suffici', 'suffoc', 'suggest', 'suicid', 'suit', 'suitabl', 'sum', 'suma-ket', 'summarili', 'summer', 'summit', 'summon', 'sun', 'sunday', 'sunder', 'sunderland', 'sunfir', 'sunglass', 'sunk', 'sunken', 'sunlight', 'sunni', 'sunnydal', 'sunris', 'sunset', 'sunspot', 'sunston', 'super', 'super-ag', 'super-b', 'super-crimin', 'super-gang', 'super-hero', 'super-human', 'super-pow', 'super-skrul', 'super-soldi', 'super-spe', 'super-spi', 'super-strength', 'super-strong', 'super-team', 'super-villain', 'superb', 'superboy', 'superboy-prim', 'superflu', 'supergirl', 'superhero', 'superheroin', 'superhuman', 'superhumanli', 'superia', 'superior', 'superman', 'superman-prim', 'supermen', 'supernatur', 'supernova', 'superpatriot', 'superpow', 'superspe', 'supersuit', 'supervillain', 'supervis', 'superwoman', 'supplant', 'supplement', 'suppli', 'support', 'suppos', 'supposedli', 'suppress', 'suprem', 'supremaci', 'sur', 'sure', 'suresh', 'surfac', 'surface-dwel', 'surfer', 'surg', 'surgeon', 'surgeri', 'surgic', 'surli', 'surmis', 'surpass', 'surpris', 'surprisingli', 'surrend', 'surreptiti', 'surrog', 'surround', 'surtur', 'surveil', 'surviv', 'survivor', 'susan', 'suscept', 'suspect', 'suspend', 'suspens', 'suspici', 'suspicion', 'sustain', 'sutter', 'suwan', 'suzi', 'svartalfheim', 'swagman', 'swallow', 'swamp', 'swan', 'swann', 'swap', 'swarm', 'swat', 'sway', 'swear', 'sweatshop', 'swell', 'swept', 'swift', 'swiftli', 'swim', 'swing', 'swirl', 'swiss', 'switch', 'switzerland', 'sword', 'swordsman', 'swore', 'sworn', 'swung', 'sydney', 'sylar', 'symbiot', 'symbol', 'sympath', 'sympathet', 'sympathi', 'symptom', 'synch', 'syndic', 'syndrom', 'syng', 'synn', 'synthes', 'synthet', 'synthezoid', 'syntho-ste', 'syphon', 'syphonn', 'system', 'systemat', 'szardo', \"t'chaka\", \"t'challa\", \"t'korr\", 't-1000', 't-1001', 't-800', 't-ray', 't-shirt', 't-veronica', 't-viru', 't-x', 'tab', 'tabitha', 'tabl', 'tablet', 'tabula', 'tabur', 'tabuu', 'tachyon', 'tackl', 'tactic', 'tactician', 'tag', 'tail', 'tailor', 'taint', 'take', 'taken', 'takeov', 'taki', 'takion', 'tal', 'talan', 'talbot', 'tale', 'talent', 'talia', 'talisman', 'talk', 'tall', 'talon', 'talzin', 'tam', 'tamaran', 'tame', 'tamper', 'tanaraq', 'tandi', 'tank', 'tanker', 'tanner', 'tantu', 'tap', 'tape', 'tara', 'tarantula', 'tare', 'taren', 'targaryen', 'target', 'tarot', 'tartaru', 'taryn', 'taser', 'tasha', 'task', 'taskmast', 'tast', 'tatanga', 'tatooin', 'tatsu', 'tatter', 'tattoo', 'taught', 'taunt', 'tax', 'taxi', 'taylor', 'tea', 'teach', 'teacher', 'team', 'team-up', 'teamed-up', 'teammat', 'teamwork', 'teapot', 'tear', 'teas', 'tech', 'technarchi', 'technet', 'techni', 'technic', 'technician', 'techniqu', 'techno', 'techno-organ', 'technolog', 'ted', 'teen', 'teenag', 'teeth', 'tef', 'telekinesi', 'telekinet', 'telepath', 'telepathi', 'teleport', 'teleri', 'televis', 'tell', 'telo', 'temper', 'tempera', 'temperatur', 'tempest', 'templ', 'templar', 'templat', 'tempor', 'temporari', 'temporarili', 'tempt', 'temptat', 'ten', 'tend', 'tendenc', 'tender', 'tendra', 'tengu', 'tennyson', 'tens', 'tension', 'tent', 'tentacl', 'tenth', 'tenur', 'term', 'termin', 'termineu', 'terminu', 'termit', 'terra', 'terraform', 'terrax', 'terri', 'terribl', 'terrif', 'terrifi', 'terrigen', 'terrigenesi', 'territori', 'terror', 'terrorist', 'tesseract', 'test', 'testament', 'testifi', 'testimoni', 'teth-adam', 'tether', 'texa', 'text', 'thaddeu', 'thalia', 'thame', 'thanagar', 'thanagarian', 'thanato', 'thank', 'thanksgiv', 'thano', 'thanosi', 'thar', 'thara', 'thaw', 'thawn', 'thawne/reverse-flash', 'thea', 'theater', 'theatr', 'theft', 'theme', 'themyscara', 'themyscira', 'then-curr', 'thena', 'theo', 'theoret', 'theori', 'theoriz', 'therapi', 'therapist', 'thereaft', 'therebi', 'therefor', 'theresa', 'thesi', 'thesili', 'thessali', 'theta', 'thick', 'thief', 'thiev', 'thin', 'thing', 'think', 'thinker', 'third', 'thirst', 'thirteen', 'thirti', 'thog', 'thoma', 'thompkin', 'thompson', 'thor', 'thori', 'thornn', 'thoro', 'thoroughli', 'though', 'thought', 'thousand', 'thrall', 'thrasher', 'threat', 'threaten', 'three', 'three-way', 'threw', 'thrill', 'throat', 'throne', 'throneworld', 'throttl', 'throughout', 'throw', 'thrown', 'thrust', 'thu', 'thug', 'thuggish', 'thunder', 'thunderbird', 'thunderbolt', 'thunderclap', 'thunderstorm', 'thunderstrik', 'thundra', 'thurman', 'thwart', 'tiara', 'tibet', 'tick', 'ticket', 'tidal', 'tide', 'tie', 'tier', 'tiger', 'tigra', 'tikal', 'tim', 'timber', 'time', 'time-displac', 'time-keep', 'time-spac', 'time-travel', 'timebrok', 'timelin', 'timepoint', 'timeslip', 'timestream', 'timid', 'timothi', 'tina', 'tini', 'tinker', 'tip', 'tire', 'tirion', 'tissu', 'titan', 'titania', 'titanian', 'titanium', 'titl', 'titu', 'tivan', 'tiwaz', 'toad', 'toadsworth', 'toast', 'tobi', 'tobia', 'tod', 'today', 'todd', 'toddler', 'toe', 'togeth', 'token', 'toki', 'tokyo', 'told', 'toler', 'toll', 'tolliv', 'tom', 'toma', 'tomb', 'tombston', 'tome', 'tommi', 'tomorrow', 'ton', 'tone', 'tongu', 'toni', 'took', 'tool', 'toom', 'top', 'top-secret', 'topaz', 'topic', 'toppl', 'torch', 'tore', 'torment', 'tormentor', 'torn', 'tornado', 'toro', 'torpedo', 'torso', 'tortur', 'toss', 'tot', 'total', 'totem', 'touch', 'tough', 'tour', 'tournament', 'tourney', 'tow', 'toward', 'tower', 'town', 'townhous', 'townspeopl', 'toxic', 'toxin', 'toy', 'toyman', 'toynbe', 'trace', 'tracer', 'traci', 'track', 'tracker', 'tractor', 'trade', 'trademark', 'trader', 'tradit', 'traffic', 'traffick', 'tragedi', 'tragic', 'trail', 'train', 'traine', 'trainer', 'trait', 'traitor', 'tranc', 'tranquil', 'transact', 'transbelvia', 'transfer', 'transform', 'transfus', 'transia', 'transigen', 'transit', 'translat', 'transmiss', 'transmit', 'transmitt', 'transmod', 'transmut', 'transpar', 'transpir', 'transplant', 'transport', 'transylvania', 'trap', 'trapper', 'trash', 'trask', 'trauma', 'traumat', 'travel', 'travers', 'traya', 'traynor', 'treacher', 'treacheri', 'treadmil', 'treason', 'treasur', 'treat', 'treati', 'treatment', 'tree', 'trek', 'tremend', 'tremont', 'trench', 'trenchcoat', 'trestl', 'trevor', 'tri', 'trial', 'triangl', 'tribb', 'tribe', 'tribun', 'tribut', 'tricel', 'trick', 'trickshot', 'trickster', 'trident', 'trigger', 'trigon', 'trini', 'triniti', 'trio', 'trip', 'tripl', 'trish', 'triton', 'tritoni', 'triumph', 'triumphant', 'triumvir', 'trogg', 'troi', 'troll', 'trolley', 'troop', 'trooper', 'trophi', 'troubl', 'troy', 'troyjan', 'truce', 'truck', 'true', 'truli', 'trust', 'trustworthi', 'truth', 'tselinoyarsk', 'tsung', 'tsurayaba', 'tube', 'tula', 'tumolo', 'tumor', 'tumulo', 'tumultu', 'tune', 'tunnel', 'turbin', 'turbo', 'turbul', 'turkey', 'turmoil', 'turn', 'turnbul', 'turtl', 'tussl', 'tutelag', 'tutor', 'tv', 'twain', 'twelv', 'twenti', 'twentieth', 'twenty-first', 'twice', 'twilight', 'twin', 'twist', 'twister', 'twitch', 'two', 'two-fac', 'two-gun', 'tyannan', 'tyger', 'tyler', 'tyme', 'type', 'typhoid', 'typic', 'tyrahn', 'tyrann', 'tyrannu', 'tyrant', 'tyrion', 'tyro', 'tyron', 'tywin', 'tzu', 'u-men', 'u.k.', 'u.n.', 'u.s.', 'uac', 'ualac', 'uatu', 'uchiha', 'ugli', 'uk', 'ultim', 'ultimo', 'ultra', 'ultron', 'ulyss', 'umar', 'umbrella', 'umbridg', 'un', 'una', 'unabl', 'unaffect', 'unansw', 'unauthor', 'unawar', 'unbalanc', 'unbeknown', 'unbeknownst', 'unborn', 'unbreak', 'uncanni', 'uncertain', 'uncertainti', 'unchang', 'uncharacterist', 'unchart', 'uncheck', 'uncl', 'unclear', 'uncomfort', 'unconsci', 'uncontrol', 'unconvent', 'uncov', 'uncreat', 'undaunt', 'undead', 'undercov', 'underestim', 'undergo', 'undergon', 'undergradu', 'underground', 'underl', 'undermin', 'underneath', 'undersea', 'understand', 'understood', 'undertak', 'undertaken', 'undertook', 'underw', 'underwat', 'underway', 'underwear', 'underwood', 'underworld', 'undi', 'undisclos', 'undo', 'undon', 'uneas', 'uneasi', 'unemploy', 'unexpect', 'unexpectedli', 'unexplain', 'unfamiliar', 'unfaz', 'unfeel', 'unfold', 'unforese', 'unfortun', 'ungoli', 'unharm', 'unhing', 'unholi', 'uni-pow', 'unicorn', 'unicron', 'unidentifi', 'unifi', 'uniform', 'unintent', 'uninterest', 'union', 'uniqu', 'unit', 'uniti', 'univers', 'unknowingli', 'unknown', 'unleash', 'unless', 'unlik', 'unlimit', 'unliv', 'unlock', 'unmask', 'unmov', 'unnam', 'unnot', 'unoffici', 'unpreced', 'unpredict', 'unprepar', 'unravel', 'unregist', 'unresolv', 'unrest', 'unrev', 'unscath', 'unseen', 'unsheath', 'unspecifi', 'unstabl', 'unstopp', 'unsuccess', 'unsuit', 'unsur', 'unsurpris', 'unsuspect', 'unternet', 'untim', 'untold', 'untouch', 'unu', 'unus', 'unusu', 'unveil', 'unwant', 'unwil', 'unwilling', 'unwit', 'unwittingli', 'unworthi', 'up', 'up-and-com', 'upbring', 'upcom', 'updat', 'upgrad', 'uphold', 'upload', 'upon', 'upper', 'upris', 'uproot', 'upset', 'upsid', 'upstat', 'uranium', 'urban', 'urg', 'urich', 'uroboro', 'ursa', 'urthona', 'uru', 'us', 'usa', 'usag', 'use', 'useless', 'user', 'usher', 'uss', 'ussr', 'usual', 'usurp', 'utah', 'utgard-loki', 'util', 'utopia', 'utopian', 'utter', 'utterli', 'uub', 'uzumaki', 'v', 'v-battalion', 'vacant', 'vacat', 'vaccin', 'vacuum', 'vader', 'vagabond', 'vagrant', 'vagu', 'vain', 'val', 'valar', 'valdez', 'vale', 'valentin', 'valeri', 'valeria', 'valeska', 'valet', 'valhalla', 'valid', 'validu', 'valinor', 'valkyri', 'valley', 'valu', 'valuabl', 'valyrian', 'vamp', 'vampir', 'van', 'vanc', 'vandal', 'vanessa', 'vanguard', 'vanilla', 'vanish', 'vaniti', 'vanko', 'vanquish', 'vapor', 'varga', 'vari', 'variant', 'variat', 'varieti', 'variou', 'various', 'vase', 'vast', 'vastli', 'vat', 'vault', 'vega', 'veget', 'vegeta', 'vehicl', 'veidt', 'velocipod', 'vendetta', 'veng', 'vengeanc', 'venic', 'venom', 'vent', 'ventriloquist', 'ventur', 'venu', 'verbal', 'verd', 'verg', 'verifi', 'vermillion', 'vermin', 'vermont', 'veronica', 'version', 'vertigo', 'vessel', 'veteran', 'vex', 'via', 'viabl', 'vial', 'vibe', 'vibranium', 'vibrat', 'vibratori', 'vic', 'vice', 'vicin', 'viciou', 'vicious', 'vicki', 'victim', 'victor', 'victori', 'victoria', 'video', 'vietnam', 'view', 'viewpoint', 'vigilant', 'vigma', 'vike', 'vile', 'vilgax', 'villa', 'villag', 'villai', 'villain', 'villaini', 'vincent', 'vindic', 'violat', 'violenc', 'violent', 'violet', 'viper', 'virago', 'viral', 'virginia', 'virtual', 'viru', 'virus', 'vishanti', 'visibl', 'vision', 'visit', 'visitor', 'visual', 'vita', 'vital', 'vitamin', 'vivian', 'vixen', 'vizier', 'vlad', 'vladimir', 'vlava', 'vocal', 'voic', 'void', 'vol', 'volatil', 'volcan', 'volcano', 'voldemort', 'volgin', 'volstagg', 'volum', 'volunt', 'voluntarili', 'vomit', 'von', 'vong', 'voodoo', 'vortex', 'vote', 'vow', 'vril', 'vs.', 'vulcan', 'vulcann', 'vulko', 'vulner', 'vultur', 'vung', 'w', 'w.', 'wade', 'wage', 'wager', 'wagner', 'waist', 'wait', 'waitress', 'wakanda', 'wakandan', 'wake', 'walk', 'walker', 'wall', 'wall-crawl', 'waller', 'walli', 'walru', 'walsh', 'walter', 'wand', 'wanda', 'wander', 'wane', 'wannab', 'want', 'war', 'war-torn', 'warbird', 'warbound', 'ward', 'warden', 'wardrob', 'warehous', 'warfar', 'warhawk', 'warhead', 'wari', 'warlock', 'warlord', 'warm', 'warn', 'warp', 'warpath', 'warrant', 'warren', 'warrior', 'warsaw', 'warship', 'warstar', 'wartim', 'warwolv', 'warworld', 'wash', 'washington', 'washout', 'wasnt', 'wasp', 'wast', 'wasteland', 'watch', 'watchdog', 'watcher', 'watchmak', 'watchmen', 'watchtow', 'water', 'waterbear', 'waterfal', 'waterfront', 'watkin', 'watson', 'wauer', 'wave', 'waverid', 'way', 'way-open', 'wayfind', 'waylon', 'wayn', 'wca', 'we', 'weak', 'weaken', 'weaker', 'weakest', 'wealth', 'wealthi', 'weapon', 'weaponri', 'wear', 'wearer', 'weari', 'weasel', 'weather', 'weaver', 'web', 'web-sling', 'webster', 'wed', 'week', 'weekend', 'weep', 'weigh', 'weight', 'weil', 'weird', 'welcom', 'welfar', 'well', 'well-b', 'well-known', 'wench', 'wendel', 'wendigo', 'went', 'went-on', 'werehog', 'werewolf', 'werewolv', 'werner', 'wesker', 'wesley', 'west', 'westchest', 'western', 'westero', 'westlak', 'wet', 'whale', 'whatev', 'wheel', 'wheelchair', 'wheelchair-bound', 'wheeler', 'whenev', 'wherea', 'whereabout', 'wherein', 'whereupon', 'wherev', 'whether', 'whilst', 'whim', 'whip', 'whirlwind', 'whisk', 'whisker', 'whisper', 'whitbi', 'white', 'whitecloud', 'whitman', 'whitmor', 'whole', 'wholli', 'whose', 'wiccan', 'wide', 'wideawak', 'widespread', 'widget', 'widow', 'wield', 'wielder', 'wife', 'wig', 'wight', 'wild', 'wildcat', 'wildebeest', 'wilder', 'wildfir', 'wildheart', 'wile', 'wilhelm', 'wili', 'wilkin', 'will', 'willi', 'william', 'willing', 'willingli', 'willow', 'willpow', 'wilma', 'wilson', 'wilsoni', 'win', 'winchest', 'wind', 'window', 'wine', 'wing', 'wingfoot', 'wink', 'winner', 'winston', 'winter', 'wintergreen', 'wipe', 'wire', 'wisconsin', 'wisdom', 'wise', 'wise-crack', 'wisecrack', 'wish', 'wisp', 'wit', 'witch', 'witchcraft', 'withdraw', 'withdrawn', 'withdrew', 'within', 'without', 'withstand', 'witter', 'wizard', 'wizardri', 'wo', 'woke', 'wolf', 'wolfgang', 'wolfl', 'wolfsban', 'wolv', 'wolverin', 'woman', 'womb', 'women', 'wonder', 'wong', 'wong-chu', 'woo', 'wood', 'wooden', 'woodru', 'woozi', 'word', 'wore', 'work', 'worker', 'workshop', 'world', 'world-devour', 'world-wid', 'worldmind', 'worldship', 'worldwid', 'worm', 'wormhol', 'worn', 'worri', 'wors', 'worsen', 'worship', 'worshipp', 'worst', 'worth', 'worthi', 'worthington', 'would', 'would-b', 'wound', 'wrack', 'wraith', 'wrap', 'wrath', 'wreak', 'wreck', 'wreckag', 'wrest', 'wrestl', 'wrestler', 'wright', 'wrist', 'write', 'writer', 'written', 'wrong', 'wrongli', 'wrote', 'wrought', 'wu', 'wundagor', 'wunderkind', 'wwhulk.jpg', 'wwii', 'wyatt', 'wyndham', 'wynn', 'x', 'x-23', 'x-51', 'x-babi', 'x-club', 'x-corp', 'x-corpor', 'x-factor', 'x-forc', 'x-hunter', 'x-jet', 'x-man', 'x-mansion', 'x-men', 'x-nation', 'x-termin', 'x-treme', 'x.', 'x.s.e', 'x4', 'x5', 'x6', 'xandar', 'xandarian', 'xander', 'xavier', 'xebel', 'xenomorph', \"xi'an\", 'xian', 'xii', 'xof', 'xorn', 'xs', 'y2k', \"ya'wara\", 'yacht', 'yacker', 'yaguchi', 'yahweh', 'yakuza', 'yamanaka', 'yamashiro', 'yandroth', 'yang', 'yann', 'yard', 'yashida', 'yashiori', 'yat', 'yavin', 'ye', 'year', 'yearn', 'yell', 'yellow', 'yellowjacket', 'yet', 'yeti', 'yggdrasil', 'yield', 'yin', 'yinsen', 'ymir', 'yo-yo', 'yoda', 'yon-rogg', 'yondu', 'york', 'yoshi', 'yoshioka', 'young', 'younger', 'youngest', 'youngster', 'youth', 'yu', 'yu-ti', 'yukio', 'yukon', 'yuria', 'yuriko', 'yuuzhan', 'yvett', 'z', \"z'nox\", 'z-saber', 'zail', 'zaladan', 'zane', 'zann', 'zanzibar', 'zaratho', 'zarek', 'zatanna', 'zatara', 'zath', 'zator', 'zauber', 'zavok', 'zazz', 'zeal', 'zealot', 'zebediah', 'zebra', 'zed', 'zeena', 'zeke', 'zemo', 'zennon', 'zeno', 'zero', 'zeta', 'zeta-beam', 'zeti', 'zeu', 'zhao', 'zhered-na', 'zinco', 'zoann', 'zod', 'zodiac', 'zoe', 'zoiray', 'zola', 'zolomon', 'zom', 'zombi', 'zomom', 'zone', 'zoo', 'zoom', 'zor', 'zor-el', 'zor-l', 'zsaji', 'zsasz', 'zucco', 'zuel', 'zzzax']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhnVkgiG3Gvg",
        "outputId": "f5fe26db-fad4-4a63-8ab6-0bd783000a71"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "atributos_de_interes = ['intelligence_score', 'strength_score', 'speed_score', 'durability_score', 'power_score', 'combat_score']\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(df_comics[atributos_de_interes])\n",
        "scaler.transform(df_comics[atributos_de_interes])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.85, 0.3 , 0.6 , 0.6 , 0.4 , 0.7 ],\n",
              "       [0.8 , 1.  , 0.8 , 1.  , 1.  , 0.8 ],\n",
              "       [0.8 , 0.5 , 0.55, 0.45, 1.  , 0.55],\n",
              "       ...,\n",
              "       [0.95, 0.5 , 1.  , 0.75, 1.  , 0.8 ],\n",
              "       [0.75, 0.1 , 1.  , 0.3 , 1.  , 0.3 ],\n",
              "       [0.45, 0.8 , 0.75, 0.95, 0.8 , 0.5 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzHaBU7Q8EHj"
      },
      "source": [
        "ColumnTransformer(\n",
        "    transformers=[\n",
        "                    ('bow', CountVectorizer(\n",
        "                    tokenizer=LemmaTokenizer(),\n",
        "                    lowercase=True,  # Transformamos todo a minúsuculas.\n",
        "                    max_features=10000,  # Dejamos solo las 10000 palabras más frecuentes,\n",
        "                    ngram_range=(1, 2)\n",
        "                    ), \n",
        "                    'history_text'),\n",
        "                    ('scaler', MinMaxScaler(), \n",
        "                    ['intelligence_score', 'strength_score', 'speed_score', 'durability_score', 'power_score', 'combat_score'])\n",
        "                  ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stHncQ-A-j4I"
      },
      "source": [
        "## 1.2 Diseño de Pipeline y  Primer Entrenamiento [1.5 puntos]\n",
        "\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://pa1.narvii.com/6374/9eaec1b7bf9157334151452a669516f9a78b954c_hq.gif\" width=\"300\">\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeMiptpQ_EWb"
      },
      "source": [
        "A continuación, genere un Pipeline con las caracteristicas solicitadas en la sección 1.1, añadiendo un reductor de dimensionalidad llamado `TruncatedSVD()` ajustando el número de componentes en 1000 (este reducto de dimensionalidad es similar al PCA pero funciona para vectores dispersos) y un clasificador `MultinomialNB()` por defecto.  Luego, separe el conjunto de datos en un conjunto de entrenamiento y prueba, donde el etiquetado vendrá dado por el atributo `alignment`. Finalmente entrene el modelo y reporte el desempeño con un `classification_report`. ¿ Nos recomendaría predecir la alineación de BatCow con este clasificador?.\n",
        "\n",
        "**Nota:** Debido al desbalance que existe entre las clases, puede ser util aplicar método de [`imbalanced-learn`](https://github.com/scikit-learn-contrib/imbalanced-learn) como RandomOverSampler sobre los datos de entrenamiento. \n",
        "\n",
        "**To-DO:**\n",
        "- [ ] Realizar un pipeline con las caracteristicas solicitadas en 1.1,aplicar un reductor de dimensionalidad `TruncatedSVD` y aplicar un clasificador  `MultinomialNB()`.\n",
        "- [ ] Entrenar el pipeline.\n",
        "- [ ] (Opcional - **0.5 bonus**) Utilizar técnicas de Sampling para balancear los datos de entrenamiento.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nYoOucGDEZj"
      },
      "source": [
        "X = df_comics[['history_text','intelligence_score', 'strength_score', 'speed_score', 'durability_score', 'power_score', 'combat_score']]\n",
        "y = df_comics['alignment']"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0QIpm56DB7v"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.30, random_state=12)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fivqr52OF5yx",
        "outputId": "b9b795c7-5396-4545-9256-916924557a07"
      },
      "source": [
        "# Balanceamos clases.\n",
        "over = RandomOverSampler(random_state=1)\n",
        "X_train_balanced, y_train_balanced = over.fit_resample(X_train, y_train)\n",
        "X_train_balanced = pd.DataFrame(X_train_balanced)\n",
        "y_train_balanced = pd.Series(y_train_balanced)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWavGybV6A3_"
      },
      "source": [
        "index_ = ['history_text','intelligence_score', 'strength_score', 'speed_score', 'durability_score', 'power_score', 'combat_score']\n",
        "X_train_balanced.columns = index_"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMwJgg3G5nhY",
        "outputId": "df3d89e0-fc56-425f-a6de-e373d135684f"
      },
      "source": [
        "# Aca vemos que esta balanceado\n",
        "y_train_balanced.value_counts()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Neutral    525\n",
              "Good       525\n",
              "Bad        525\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhwgMg_A-Ug9",
        "outputId": "e19fb8f6-bd87-474f-d2a3-c224cef1c178"
      },
      "source": [
        "preprocessing_transformer = ColumnTransformer(\n",
        "    transformers=[\n",
        "                    ('bow', CountVectorizer(\n",
        "                    tokenizer=LemmaTokenizer(),\n",
        "                    lowercase=True,  # Transformamos todo a minúsuculas.\n",
        "                    max_features=10000,  # Dejamos solo las 10000 palabras más frecuentes,\n",
        "                    ngram_range=(1, 2)\n",
        "                    ), \n",
        "                    'history_text'),\n",
        "                    ('scaler', MinMaxScaler(), \n",
        "                    ['intelligence_score', 'strength_score', 'speed_score', 'durability_score', 'power_score', 'combat_score'])\n",
        "                  ]\n",
        ")\n",
        "\n",
        "pipe = Pipeline(steps=[\n",
        "                       ('preprocessing', preprocessing_transformer),\n",
        "                       ('clf', MultinomialNB() )\n",
        "                       ]\n",
        "                )\n",
        "# Probamos desbalanceado\n",
        "pipe.fit(X_train, y_train)\n",
        "y_pred = pipe.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         Bad       0.52      0.59      0.55       133\n",
            "        Good       0.70      0.71      0.71       218\n",
            "     Neutral       0.08      0.03      0.04        35\n",
            "\n",
            "    accuracy                           0.61       386\n",
            "   macro avg       0.43      0.44      0.43       386\n",
            "weighted avg       0.58      0.61      0.59       386\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJg_kqy67p_g",
        "outputId": "33170623-1f47-4ca2-fa5e-f3ef9ac040c8"
      },
      "source": [
        "# Balanceado\n",
        "pipe.fit(X_train_balanced, y_train_balanced)\n",
        "y_pred = pipe.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         Bad       0.60      0.56      0.58       133\n",
            "        Good       0.69      0.79      0.73       218\n",
            "     Neutral       0.36      0.11      0.17        35\n",
            "\n",
            "    accuracy                           0.65       386\n",
            "   macro avg       0.55      0.49      0.50       386\n",
            "weighted avg       0.63      0.65      0.63       386\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZJBWQ5XjXRR"
      },
      "source": [
        "Podemos notar que al balancear las clases tenemos mejores resultados, sobretodo en la clase neutral"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfm7I2B7_rfB"
      },
      "source": [
        "## 1.3 Entrenamiento con Grid Search [2 Puntos]\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media1.tenor.com/images/70fdfeea52a8e2e4505498c230a0d2f9/tenor.gif?itemid=5134219\" width=\"250\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14siiavzK67p"
      },
      "source": [
        "No conformes con el rendimiento obtenido en la sección 1.2, el cuerpo docente les pide que realicen una búsqueda de grilla de los mejores hiperparámetros utilizando `GridSearchCV`. \n",
        "\n",
        "Para esto, se le solicita que defina al menos 3 configuraciones de hiperparámetros e intente obtener mejores resultados que los obtenidos en la sección anterior. \n",
        "\n",
        "A continuación, un ejemplo de parametros para GridSearch:\n",
        "\n",
        "```python\n",
        "params = [\n",
        "  # esta es la configuración de una busqueda en particular\n",
        "  # con el clasificador classificator1.\n",
        "  # en este caso se entrenará el clasificador 1 con combinaciones de todos los \n",
        "  # parámetros de bow__max_features, bow__ngram_range, clf__n_estimators \n",
        "  # y se seleccionará la mejor combinación.\n",
        "  {\n",
        "  'bow__max_features': [5000, 10000, ...],\n",
        "  'bow__ngram_range': [(1, 1), (1, 2), (1,3)],\n",
        "  ...,\n",
        "  'clf': [classificator1()],\n",
        "  'clf__n_estimators': [200]\n",
        "  },\n",
        "  # esta es la configuración de una busqueda en particular\n",
        "  # con el clasificador classificator2:\n",
        "  {'clf': [classificator2()],\n",
        "   'clf__penalty': ['ovr'],\n",
        "   'clf__multi_class': ['liblinear']\n",
        "  },\n",
        "  # esta es la configuración de una busqueda en particular\n",
        "  # con el clasificador classificator3:\n",
        "  {'clf': [classificator3()]\n",
        "  }\n",
        "             ]\n",
        "```\n",
        "\n",
        "Además, note que puede obtener todos los parámetros configurables de un pipeline invocando sobre este el método `.get_params()`.\n",
        "\n",
        "**Nota:** El GridSearch puede tomar tiempos de búsqueda exorbitantes, por lo que se le recomienda dejar corriendo el código y tomarse un tecito."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7HkTmLEJZ4g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84fa7cf4-8476-4ce0-c4a6-bcaa494c7898"
      },
      "source": [
        "MAX_FEATURES = [5000, 10000, 15000]\n",
        "NGRAM_RANGE = [(1,1), (1,2), (1,3)]\n",
        "FIT_PRIOR = [True, False]\n",
        "\n",
        "param_grid = [\n",
        "    {\n",
        "        'preprocessing__bow__max_features': MAX_FEATURES,\n",
        "        'preprocessing__bow__ngram_range': NGRAM_RANGE,\n",
        "        'clf__fit_prior': FIT_PRIOR\n",
        "    }\n",
        "]\n",
        "\n",
        "grid = GridSearchCV(pipe, n_jobs=1, param_grid=param_grid)\n",
        "grid.fit(X_train, y_train)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('preprocessing',\n",
              "                                        ColumnTransformer(n_jobs=None,\n",
              "                                                          remainder='drop',\n",
              "                                                          sparse_threshold=0.3,\n",
              "                                                          transformer_weights=None,\n",
              "                                                          transformers=[('bow',\n",
              "                                                                         CountVectorizer(analyzer='word',\n",
              "                                                                                         binary=False,\n",
              "                                                                                         decode_error='strict',\n",
              "                                                                                         dtype=<class 'numpy.int64'>,\n",
              "                                                                                         encoding='utf-8',\n",
              "                                                                                         input='content',\n",
              "                                                                                         lowercase=True,\n",
              "                                                                                         ma...\n",
              "                                                          verbose=False)),\n",
              "                                       ('clf',\n",
              "                                        MultinomialNB(alpha=1.0,\n",
              "                                                      class_prior=None,\n",
              "                                                      fit_prior=True))],\n",
              "                                verbose=False),\n",
              "             iid='deprecated', n_jobs=1,\n",
              "             param_grid=[{'clf__fit_prior': [True, False],\n",
              "                          'preprocessing__bow__max_features': [5000, 10000,\n",
              "                                                               15000],\n",
              "                          'preprocessing__bow__ngram_range': [(1, 1), (1, 2),\n",
              "                                                              (1, 3)]}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OP99gl-NB0ip",
        "outputId": "ce647f47-b596-4cf2-9f79-ecbb63fe4974"
      },
      "source": [
        "grid.cv_results_"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mean_fit_time': array([11.35334992, 12.9886426 , 15.67488885, 11.53019567, 13.00671043,\n",
              "        15.66645136, 11.41127267, 13.0250483 , 15.60156465, 11.32597909,\n",
              "        13.09207902, 15.72181764, 11.31367903, 13.03388176, 15.54173608,\n",
              "        11.38321776, 13.00598016, 15.61596208]),\n",
              " 'mean_score_time': array([2.82793999, 2.8926703 , 2.95835223, 2.898067  , 2.89173384,\n",
              "        2.97508488, 2.82097616, 2.89638553, 2.96557498, 2.84230852,\n",
              "        2.90539422, 2.99474072, 2.81216578, 2.89034452, 2.96713762,\n",
              "        2.81964698, 2.89325004, 2.97543402]),\n",
              " 'mean_test_score': array([0.62736189, 0.62401614, 0.62625078, 0.64404718, 0.64292986,\n",
              "        0.64848541, 0.65962135, 0.64849783, 0.64962135, 0.61845438,\n",
              "        0.60735568, 0.61180633, 0.6262694 , 0.62956549, 0.62734947,\n",
              "        0.64961515, 0.63515208, 0.6451707 ]),\n",
              " 'param_clf__fit_prior': masked_array(data=[True, True, True, True, True, True, True, True, True,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_preprocessing__bow__max_features': masked_array(data=[5000, 5000, 5000, 10000, 10000, 10000, 15000, 15000,\n",
              "                    15000, 5000, 5000, 5000, 10000, 10000, 10000, 15000,\n",
              "                    15000, 15000],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_preprocessing__bow__ngram_range': masked_array(data=[(1, 1), (1, 2), (1, 3), (1, 1), (1, 2), (1, 3), (1, 1),\n",
              "                    (1, 2), (1, 3), (1, 1), (1, 2), (1, 3), (1, 1), (1, 2),\n",
              "                    (1, 3), (1, 1), (1, 2), (1, 3)],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'params': [{'clf__fit_prior': True,\n",
              "   'preprocessing__bow__max_features': 5000,\n",
              "   'preprocessing__bow__ngram_range': (1, 1)},\n",
              "  {'clf__fit_prior': True,\n",
              "   'preprocessing__bow__max_features': 5000,\n",
              "   'preprocessing__bow__ngram_range': (1, 2)},\n",
              "  {'clf__fit_prior': True,\n",
              "   'preprocessing__bow__max_features': 5000,\n",
              "   'preprocessing__bow__ngram_range': (1, 3)},\n",
              "  {'clf__fit_prior': True,\n",
              "   'preprocessing__bow__max_features': 10000,\n",
              "   'preprocessing__bow__ngram_range': (1, 1)},\n",
              "  {'clf__fit_prior': True,\n",
              "   'preprocessing__bow__max_features': 10000,\n",
              "   'preprocessing__bow__ngram_range': (1, 2)},\n",
              "  {'clf__fit_prior': True,\n",
              "   'preprocessing__bow__max_features': 10000,\n",
              "   'preprocessing__bow__ngram_range': (1, 3)},\n",
              "  {'clf__fit_prior': True,\n",
              "   'preprocessing__bow__max_features': 15000,\n",
              "   'preprocessing__bow__ngram_range': (1, 1)},\n",
              "  {'clf__fit_prior': True,\n",
              "   'preprocessing__bow__max_features': 15000,\n",
              "   'preprocessing__bow__ngram_range': (1, 2)},\n",
              "  {'clf__fit_prior': True,\n",
              "   'preprocessing__bow__max_features': 15000,\n",
              "   'preprocessing__bow__ngram_range': (1, 3)},\n",
              "  {'clf__fit_prior': False,\n",
              "   'preprocessing__bow__max_features': 5000,\n",
              "   'preprocessing__bow__ngram_range': (1, 1)},\n",
              "  {'clf__fit_prior': False,\n",
              "   'preprocessing__bow__max_features': 5000,\n",
              "   'preprocessing__bow__ngram_range': (1, 2)},\n",
              "  {'clf__fit_prior': False,\n",
              "   'preprocessing__bow__max_features': 5000,\n",
              "   'preprocessing__bow__ngram_range': (1, 3)},\n",
              "  {'clf__fit_prior': False,\n",
              "   'preprocessing__bow__max_features': 10000,\n",
              "   'preprocessing__bow__ngram_range': (1, 1)},\n",
              "  {'clf__fit_prior': False,\n",
              "   'preprocessing__bow__max_features': 10000,\n",
              "   'preprocessing__bow__ngram_range': (1, 2)},\n",
              "  {'clf__fit_prior': False,\n",
              "   'preprocessing__bow__max_features': 10000,\n",
              "   'preprocessing__bow__ngram_range': (1, 3)},\n",
              "  {'clf__fit_prior': False,\n",
              "   'preprocessing__bow__max_features': 15000,\n",
              "   'preprocessing__bow__ngram_range': (1, 1)},\n",
              "  {'clf__fit_prior': False,\n",
              "   'preprocessing__bow__max_features': 15000,\n",
              "   'preprocessing__bow__ngram_range': (1, 2)},\n",
              "  {'clf__fit_prior': False,\n",
              "   'preprocessing__bow__max_features': 15000,\n",
              "   'preprocessing__bow__ngram_range': (1, 3)}],\n",
              " 'rank_test_score': array([11, 15, 14,  7,  8,  5,  1,  4,  2, 16, 18, 17, 13, 10, 12,  3,  9,\n",
              "         6], dtype=int32),\n",
              " 'split0_test_score': array([0.59444444, 0.57222222, 0.58333333, 0.63888889, 0.58888889,\n",
              "        0.6       , 0.65      , 0.62777778, 0.61666667, 0.58333333,\n",
              "        0.57222222, 0.56666667, 0.60555556, 0.58888889, 0.57222222,\n",
              "        0.63888889, 0.59444444, 0.6       ]),\n",
              " 'split1_test_score': array([0.61111111, 0.61111111, 0.60555556, 0.61111111, 0.63888889,\n",
              "        0.64444444, 0.63333333, 0.62222222, 0.62777778, 0.60555556,\n",
              "        0.58888889, 0.59444444, 0.58888889, 0.63888889, 0.63333333,\n",
              "        0.62222222, 0.61111111, 0.63333333]),\n",
              " 'split2_test_score': array([0.65555556, 0.67222222, 0.66666667, 0.67222222, 0.67777778,\n",
              "        0.67222222, 0.66666667, 0.67777778, 0.67777778, 0.64444444,\n",
              "        0.63333333, 0.63888889, 0.66111111, 0.64444444, 0.63888889,\n",
              "        0.66666667, 0.67222222, 0.67222222]),\n",
              " 'split3_test_score': array([0.65      , 0.65      , 0.65      , 0.65555556, 0.67222222,\n",
              "        0.68888889, 0.68888889, 0.66666667, 0.66666667, 0.65      ,\n",
              "        0.62222222, 0.63333333, 0.63333333, 0.66666667, 0.67777778,\n",
              "        0.66666667, 0.66111111, 0.66666667]),\n",
              " 'split4_test_score': array([0.62569832, 0.61452514, 0.62569832, 0.6424581 , 0.63687151,\n",
              "        0.63687151, 0.65921788, 0.64804469, 0.65921788, 0.60893855,\n",
              "        0.62011173, 0.62569832, 0.6424581 , 0.60893855, 0.61452514,\n",
              "        0.65363128, 0.63687151, 0.65363128]),\n",
              " 'std_fit_time': array([0.17076712, 0.28074693, 0.37258161, 0.30241825, 0.25358515,\n",
              "        0.26003492, 0.2598707 , 0.26815769, 0.3294906 , 0.18235748,\n",
              "        0.29340779, 0.35186939, 0.23606583, 0.23660171, 0.34167442,\n",
              "        0.2637196 , 0.21005373, 0.33464555]),\n",
              " 'std_score_time': array([0.19413924, 0.22680918, 0.21922999, 0.2000463 , 0.21363164,\n",
              "        0.22165262, 0.23420569, 0.21097316, 0.22058919, 0.20571325,\n",
              "        0.21367643, 0.21154516, 0.22948277, 0.22703206, 0.23066018,\n",
              "        0.18790901, 0.2210392 , 0.22532739]),\n",
              " 'std_test_score': array([0.0230555 , 0.0344622 , 0.02989306, 0.02019997, 0.03176753,\n",
              "        0.03065265, 0.01838488, 0.02148188, 0.0234033 , 0.0251437 ,\n",
              "        0.02295191, 0.02730893, 0.02589318, 0.02744035, 0.03439609,\n",
              "        0.01710592, 0.02927833, 0.02625246])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iUUmpd1IpNa",
        "outputId": "e1405cf6-d651-4191-8606-392833cc6ff3"
      },
      "source": [
        "\n",
        "over = RandomOverSampler(random_state=1)\n",
        "X_balanced, y_balanced = over.fit_resample(X, y)\n",
        "X_balanced = pd.DataFrame(X_train_balanced)\n",
        "y_balanced = pd.Series(y_train_balanced)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x31Nub9WGdy3",
        "outputId": "1bfada4d-93db-448b-e20d-979522a2a26b"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "MAX_FEATURES = [5000, 10000, 15000]\n",
        "NGRAM_RANGE = [(1,1), (1,2), (1,3)]\n",
        "FIT_PRIOR = [True, False]\n",
        "\n",
        "param_grid = [\n",
        "    {\n",
        "        'preprocessing__bow__max_features': MAX_FEATURES,\n",
        "        'preprocessing__bow__ngram_range': NGRAM_RANGE,\n",
        "        'clf__fit_prior': FIT_PRIOR\n",
        "    },\n",
        "    {\n",
        "        'clf': [LogisticRegression()],\n",
        "        'clf__multi_class': ['multinomial']\n",
        "    },\n",
        "    {\n",
        "        'clf': [DecisionTreeClassifier()],\n",
        "        'clf__criterion': ['gini', 'entropy']\n",
        "    }\n",
        "]\n",
        "\n",
        "grid_2 = GridSearchCV(pipe, n_jobs=1, param_grid=param_grid)\n",
        "grid_2.fit(X_balanced, y_balanced)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('preprocessing',\n",
              "                                        ColumnTransformer(n_jobs=None,\n",
              "                                                          remainder='drop',\n",
              "                                                          sparse_threshold=0.3,\n",
              "                                                          transformer_weights=None,\n",
              "                                                          transformers=[('bow',\n",
              "                                                                         CountVectorizer(analyzer='word',\n",
              "                                                                                         binary=False,\n",
              "                                                                                         decode_error='strict',\n",
              "                                                                                         dtype=<class 'numpy.int64'>,\n",
              "                                                                                         encoding='utf-8',\n",
              "                                                                                         input='content',\n",
              "                                                                                         lowercase=True,\n",
              "                                                                                         ma...\n",
              "                                                         criterion='gini',\n",
              "                                                         max_depth=None,\n",
              "                                                         max_features=None,\n",
              "                                                         max_leaf_nodes=None,\n",
              "                                                         min_impurity_decrease=0.0,\n",
              "                                                         min_impurity_split=None,\n",
              "                                                         min_samples_leaf=1,\n",
              "                                                         min_samples_split=2,\n",
              "                                                         min_weight_fraction_leaf=0.0,\n",
              "                                                         presort='deprecated',\n",
              "                                                         random_state=None,\n",
              "                                                         splitter='best')],\n",
              "                          'clf__criterion': ['gini', 'entropy']}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        },
        "id": "HH0v2F8oUddU",
        "outputId": "7c5f334e-f27f-4f34-c9af-8fa92c526f04"
      },
      "source": [
        "pd.concat([pd.DataFrame(grid_2.cv_results_[\"params\"]),pd.DataFrame(grid_2.cv_results_[\"mean_test_score\"], columns=[\"Accuracy\"])],axis=1)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clf__fit_prior</th>\n",
              "      <th>preprocessing__bow__max_features</th>\n",
              "      <th>preprocessing__bow__ngram_range</th>\n",
              "      <th>clf</th>\n",
              "      <th>clf__multi_class</th>\n",
              "      <th>clf__criterion</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>True</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.770159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>True</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.716825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>True</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>(1, 3)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.715556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>True</td>\n",
              "      <td>10000.0</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.831111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>True</td>\n",
              "      <td>10000.0</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.765079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>True</td>\n",
              "      <td>10000.0</td>\n",
              "      <td>(1, 3)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.742222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>True</td>\n",
              "      <td>15000.0</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.840000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>True</td>\n",
              "      <td>15000.0</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.765079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>True</td>\n",
              "      <td>15000.0</td>\n",
              "      <td>(1, 3)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.751111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>False</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.770159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>False</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.716825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>False</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>(1, 3)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.715556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>False</td>\n",
              "      <td>10000.0</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.831111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>False</td>\n",
              "      <td>10000.0</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.765079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>False</td>\n",
              "      <td>10000.0</td>\n",
              "      <td>(1, 3)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.742222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>False</td>\n",
              "      <td>15000.0</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.840000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>False</td>\n",
              "      <td>15000.0</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.765079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>False</td>\n",
              "      <td>15000.0</td>\n",
              "      <td>(1, 3)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.751111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
              "      <td>multinomial</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.885714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>DecisionTreeClassifier(ccp_alpha=0.0, class_we...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>gini</td>\n",
              "      <td>0.806349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>DecisionTreeClassifier(ccp_alpha=0.0, class_we...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>entropy</td>\n",
              "      <td>0.794921</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   clf__fit_prior  preprocessing__bow__max_features  ... clf__criterion  Accuracy\n",
              "0            True                            5000.0  ...            NaN  0.770159\n",
              "1            True                            5000.0  ...            NaN  0.716825\n",
              "2            True                            5000.0  ...            NaN  0.715556\n",
              "3            True                           10000.0  ...            NaN  0.831111\n",
              "4            True                           10000.0  ...            NaN  0.765079\n",
              "5            True                           10000.0  ...            NaN  0.742222\n",
              "6            True                           15000.0  ...            NaN  0.840000\n",
              "7            True                           15000.0  ...            NaN  0.765079\n",
              "8            True                           15000.0  ...            NaN  0.751111\n",
              "9           False                            5000.0  ...            NaN  0.770159\n",
              "10          False                            5000.0  ...            NaN  0.716825\n",
              "11          False                            5000.0  ...            NaN  0.715556\n",
              "12          False                           10000.0  ...            NaN  0.831111\n",
              "13          False                           10000.0  ...            NaN  0.765079\n",
              "14          False                           10000.0  ...            NaN  0.742222\n",
              "15          False                           15000.0  ...            NaN  0.840000\n",
              "16          False                           15000.0  ...            NaN  0.765079\n",
              "17          False                           15000.0  ...            NaN  0.751111\n",
              "18            NaN                               NaN  ...            NaN  0.885714\n",
              "19            NaN                               NaN  ...           gini  0.806349\n",
              "20            NaN                               NaN  ...        entropy  0.794921\n",
              "\n",
              "[21 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItbNfY9tVCtc",
        "outputId": "26780706-9df2-4779-ca1e-cc1ba98a97e5"
      },
      "source": [
        "MAX_FEATURES = [5000, 10000, 15000]\n",
        "NGRAM_RANGE = [(1,1), (1,2), (1,3)]\n",
        "\n",
        "param_grid = [\n",
        "    {\n",
        "        'preprocessing__bow__max_features': MAX_FEATURES,\n",
        "        'preprocessing__bow__ngram_range': NGRAM_RANGE,\n",
        "        'clf': [LogisticRegression()],\n",
        "        'clf__multi_class': ['multinomial']\n",
        "    }\n",
        "]\n",
        "\n",
        "grid_3 = GridSearchCV(pipe, n_jobs=1, param_grid=param_grid)\n",
        "grid_3.fit(X_balanced, y_balanced)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('preprocessing',\n",
              "                                        ColumnTransformer(n_jobs=None,\n",
              "                                                          remainder='drop',\n",
              "                                                          sparse_threshold=0.3,\n",
              "                                                          transformer_weights=None,\n",
              "                                                          transformers=[('bow',\n",
              "                                                                         CountVectorizer(analyzer='word',\n",
              "                                                                                         binary=False,\n",
              "                                                                                         decode_error='strict',\n",
              "                                                                                         dtype=<class 'numpy.int64'>,\n",
              "                                                                                         encoding='utf-8',\n",
              "                                                                                         input='content',\n",
              "                                                                                         lowercase=True,\n",
              "                                                                                         ma...\n",
              "                                                     multi_class='multinomial',\n",
              "                                                     n_jobs=None, penalty='l2',\n",
              "                                                     random_state=None,\n",
              "                                                     solver='lbfgs', tol=0.0001,\n",
              "                                                     verbose=0,\n",
              "                                                     warm_start=False)],\n",
              "                          'clf__multi_class': ['multinomial'],\n",
              "                          'preprocessing__bow__max_features': [5000, 10000,\n",
              "                                                               15000],\n",
              "                          'preprocessing__bow__ngram_range': [(1, 1), (1, 2),\n",
              "                                                              (1, 3)]}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "XSarZnmWbRU3",
        "outputId": "a7d08e83-e5cf-49db-f184-09e92530f799"
      },
      "source": [
        "pd.concat([pd.DataFrame(grid_3.cv_results_[\"params\"]),pd.DataFrame(grid_3.cv_results_[\"mean_test_score\"], columns=[\"Accuracy\"])],axis=1)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clf</th>\n",
              "      <th>clf__multi_class</th>\n",
              "      <th>preprocessing__bow__max_features</th>\n",
              "      <th>preprocessing__bow__ngram_range</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
              "      <td>multinomial</td>\n",
              "      <td>5000</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>0.871111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
              "      <td>multinomial</td>\n",
              "      <td>5000</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>0.873016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
              "      <td>multinomial</td>\n",
              "      <td>5000</td>\n",
              "      <td>(1, 3)</td>\n",
              "      <td>0.866667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
              "      <td>multinomial</td>\n",
              "      <td>10000</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>0.874286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
              "      <td>multinomial</td>\n",
              "      <td>10000</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>0.885714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
              "      <td>multinomial</td>\n",
              "      <td>10000</td>\n",
              "      <td>(1, 3)</td>\n",
              "      <td>0.883175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
              "      <td>multinomial</td>\n",
              "      <td>15000</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>0.869841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
              "      <td>multinomial</td>\n",
              "      <td>15000</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>0.880000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
              "      <td>multinomial</td>\n",
              "      <td>15000</td>\n",
              "      <td>(1, 3)</td>\n",
              "      <td>0.881905</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 clf  ...  Accuracy\n",
              "0  LogisticRegression(C=1.0, class_weight=None, d...  ...  0.871111\n",
              "1  LogisticRegression(C=1.0, class_weight=None, d...  ...  0.873016\n",
              "2  LogisticRegression(C=1.0, class_weight=None, d...  ...  0.866667\n",
              "3  LogisticRegression(C=1.0, class_weight=None, d...  ...  0.874286\n",
              "4  LogisticRegression(C=1.0, class_weight=None, d...  ...  0.885714\n",
              "5  LogisticRegression(C=1.0, class_weight=None, d...  ...  0.883175\n",
              "6  LogisticRegression(C=1.0, class_weight=None, d...  ...  0.869841\n",
              "7  LogisticRegression(C=1.0, class_weight=None, d...  ...  0.880000\n",
              "8  LogisticRegression(C=1.0, class_weight=None, d...  ...  0.881905\n",
              "\n",
              "[9 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ag2XHuGZbUbx",
        "outputId": "a91adf50-9ecc-4540-c0c8-141dce5917ad"
      },
      "source": [
        "grid_3.best_estimator_"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('preprocessing',\n",
              "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
              "                                   sparse_threshold=0.3,\n",
              "                                   transformer_weights=None,\n",
              "                                   transformers=[('bow',\n",
              "                                                  CountVectorizer(analyzer='word',\n",
              "                                                                  binary=False,\n",
              "                                                                  decode_error='strict',\n",
              "                                                                  dtype=<class 'numpy.int64'>,\n",
              "                                                                  encoding='utf-8',\n",
              "                                                                  input='content',\n",
              "                                                                  lowercase=True,\n",
              "                                                                  max_df=1.0,\n",
              "                                                                  max_features=10000,\n",
              "                                                                  min_df=1,\n",
              "                                                                  ngram_rang...\n",
              "                                                   'strength_score',\n",
              "                                                   'speed_score',\n",
              "                                                   'durability_score',\n",
              "                                                   'power_score',\n",
              "                                                   'combat_score'])],\n",
              "                                   verbose=False)),\n",
              "                ('clf',\n",
              "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    l1_ratio=None, max_iter=100,\n",
              "                                    multi_class='multinomial', n_jobs=None,\n",
              "                                    penalty='l2', random_state=None,\n",
              "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                    warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9TXQK3Hi0Kz"
      },
      "source": [
        "#### 1.3.1 Mejor configuración [0.5]\n",
        "\n",
        "Comente cual fue la mejor configuración obtenida por Grid Search y por qué cree que esta fue la mejor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzMu7kU_jJsB"
      },
      "source": [
        "Podemos observar que en el primer Grid Search que se computo el mejor resultado para el Accuracy se obtuvo con el modelo de clasificación Logit en su versión multiclase, y luego en el segundo Grid Search que se computo utilizando este clasificador, se observa que los mejores parametros para el preprocesamiento de texto son un ngram_range = (1,2) y max_features = 10000.\n",
        "Nos resulta extraño que el modelo Logit sea el que tiene mejor desempeño, ya que este asume que la distribución de los atributos es gaussiana y esto es un poco contraintuitivo, ya que los artistas al crear un personaje probablemente no piensen en que los personajes distribuyan de forma gaussiana, en el sentido de que tengan atributos similares para cada clase, es decir, un artista no se pone a pensar cuales son los atributos clásicos para un hereo, villano o neutral a la hora de crearlo. Posiblemente Logit sea el que mejor funciona en este caso debido a la forma de los datos, que se encuentran entre 0 y 1 debido a la normalización, lo que puede generar que el output de cada observacion este entre 0 y 1, y sabemos que Logit es un modelo que funciona bastante bien cuando la variable de salida es binaria (0 o 1)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmQUw2aZ_6z2"
      },
      "source": [
        "## 1.4 Predicción del datos sin etiquetado\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://pbs.twimg.com/media/DolotxUUYAAbg7f.jpg\" width=\"350\">\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cj0ERBgTBFWN"
      },
      "source": [
        "Llego el momento de predecir cual es la verdadera alineación de `Batcow`. Para esto, deben escoger el mejor pipeline obtenido en las secciones anteriores y predecir la alineación de todos los datos presentes en `df_comics_no_label`.Luego, anexen las alineaciones obtenidas a su correspondiente columna  del dataframe original (atributo `alignment`) y busquen a los flamantes personajes `Batcow`, `Vergil`, y `Gorilla Girl'. Presente los resultados en un `Dataframe`.\n",
        "\n",
        "**Nota:** Recuerde que pueden existir campos vacios en `history_text`, por lo que se les recomienda borrar los nan."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3irRF18cj_E"
      },
      "source": [
        "df_comics_no_label = df_comics_no_label.dropna(subset=['history_text'])\n",
        "df_comics_no_label = df_comics_no_label.drop_duplicates()\n",
        "X_predict = df_comics_no_label[['history_text','intelligence_score', 'strength_score', 'speed_score', 'durability_score', 'power_score', 'combat_score']]"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-mizeQZaLUY"
      },
      "source": [
        "preprocessing_transformer = ColumnTransformer(\n",
        "    transformers=[\n",
        "                    ('bow', CountVectorizer(\n",
        "                    tokenizer=LemmaTokenizer(),\n",
        "                    lowercase=True,  # Transformamos todo a minúsuculas.\n",
        "                    max_features=10000,  # Dejamos solo las 10000 palabras más frecuentes,\n",
        "                    ngram_range=(1, 2)\n",
        "                    ), \n",
        "                    'history_text'),\n",
        "                    ('scaler', MinMaxScaler(), \n",
        "                    ['intelligence_score', 'strength_score', 'speed_score', 'durability_score', 'power_score', 'combat_score'])\n",
        "                  ]\n",
        ")\n",
        "\n",
        "pipe_logit = Pipeline(steps=[\n",
        "                       ('preprocessing', preprocessing_transformer),\n",
        "                       ('clf', LogisticRegression(multi_class = 'multinomial', max_iter = 1000))\n",
        "                       ]\n",
        "                )\n",
        "\n",
        "pipe_logit.fit(X_balanced, y_balanced)\n",
        "y_pred = pipe_logit.predict(X_predict)"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auVQl1WTdKKI"
      },
      "source": [
        "df_comics_no_label['alignment'] = y_pred"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "P-Sss4wLdcQc",
        "outputId": "9cfcda14-cc0c-42a0-9566-83c30d175ebd"
      },
      "source": [
        "entes_poderosos = ['Batcow', 'Vergil', 'Gorilla Girl']\n",
        "  \n",
        "df_comics_no_label[df_comics_no_label['name'].isin(entes_poderosos)]"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>name</th>\n",
              "      <th>real_name</th>\n",
              "      <th>full_name</th>\n",
              "      <th>overall_score</th>\n",
              "      <th>history_text</th>\n",
              "      <th>powers_text</th>\n",
              "      <th>intelligence_score</th>\n",
              "      <th>strength_score</th>\n",
              "      <th>speed_score</th>\n",
              "      <th>durability_score</th>\n",
              "      <th>power_score</th>\n",
              "      <th>combat_score</th>\n",
              "      <th>superpowers</th>\n",
              "      <th>alter_egos</th>\n",
              "      <th>aliases</th>\n",
              "      <th>place_of_birth</th>\n",
              "      <th>first_appearance</th>\n",
              "      <th>creator</th>\n",
              "      <th>alignment</th>\n",
              "      <th>occupation</th>\n",
              "      <th>base</th>\n",
              "      <th>teams</th>\n",
              "      <th>relatives</th>\n",
              "      <th>gender</th>\n",
              "      <th>type_race</th>\n",
              "      <th>height</th>\n",
              "      <th>weight</th>\n",
              "      <th>eye_color</th>\n",
              "      <th>hair_color</th>\n",
              "      <th>skin_color</th>\n",
              "      <th>img</th>\n",
              "      <th>has_electrokinesis</th>\n",
              "      <th>has_energy_constructs</th>\n",
              "      <th>has_mind_control_resistance</th>\n",
              "      <th>has_matter_manipulation</th>\n",
              "      <th>has_telepathy_resistance</th>\n",
              "      <th>has_mind_control</th>\n",
              "      <th>has_enhanced_hearing</th>\n",
              "      <th>has_dimensional_travel</th>\n",
              "      <th>...</th>\n",
              "      <th>has_fire_resistance</th>\n",
              "      <th>has_fire_control</th>\n",
              "      <th>has_dexterity</th>\n",
              "      <th>has_reality_warping</th>\n",
              "      <th>has_illusions</th>\n",
              "      <th>has_energy_beams</th>\n",
              "      <th>has_peak_human_condition</th>\n",
              "      <th>has_shapeshifting</th>\n",
              "      <th>has_heat_resistance</th>\n",
              "      <th>has_jump</th>\n",
              "      <th>has_self-sustenance</th>\n",
              "      <th>has_energy_absorption</th>\n",
              "      <th>has_cold_resistance</th>\n",
              "      <th>has_magic</th>\n",
              "      <th>has_telekinesis</th>\n",
              "      <th>has_toxin_and_disease_resistance</th>\n",
              "      <th>has_telepathy</th>\n",
              "      <th>has_regeneration</th>\n",
              "      <th>has_immortality</th>\n",
              "      <th>has_teleportation</th>\n",
              "      <th>has_force_fields</th>\n",
              "      <th>has_energy_manipulation</th>\n",
              "      <th>has_endurance</th>\n",
              "      <th>has_longevity</th>\n",
              "      <th>has_weapon-based_powers</th>\n",
              "      <th>has_energy_blasts</th>\n",
              "      <th>has_enhanced_senses</th>\n",
              "      <th>has_invulnerability</th>\n",
              "      <th>has_stealth</th>\n",
              "      <th>has_marksmanship</th>\n",
              "      <th>has_flight</th>\n",
              "      <th>has_accelerated_healing</th>\n",
              "      <th>has_weapons_master</th>\n",
              "      <th>has_intelligence</th>\n",
              "      <th>has_reflexes</th>\n",
              "      <th>has_super_speed</th>\n",
              "      <th>has_durability</th>\n",
              "      <th>has_stamina</th>\n",
              "      <th>has_agility</th>\n",
              "      <th>has_super_strength</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>122</td>\n",
              "      <td>Batcow</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>3</td>\n",
              "      <td>Bat-Cow was originally a cow that was found by...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>70</td>\n",
              "      <td>10</td>\n",
              "      <td>25</td>\n",
              "      <td>20</td>\n",
              "      <td>10</td>\n",
              "      <td>20</td>\n",
              "      <td>['Animal Attributes', 'Animal Oriented Powers']</td>\n",
              "      <td>['Milkman Man', 'Red Torpedo', 'Red Volcano']</td>\n",
              "      <td>[\"Battlin' Bovine\"]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>DC Comics</td>\n",
              "      <td>Good</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Wayne Manor</td>\n",
              "      <td>[]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Animal</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>/pictures2/portraits/11/050/13425.jpg?v=157425...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>529</td>\n",
              "      <td>Gorilla Girl</td>\n",
              "      <td>Fahnbullah Eddy</td>\n",
              "      <td>Fahnbullah Eddy</td>\n",
              "      <td>7</td>\n",
              "      <td>A carnival performer with the ability to turn ...</td>\n",
              "      <td>Gorilla Girl can transform into a talking gori...</td>\n",
              "      <td>90</td>\n",
              "      <td>35</td>\n",
              "      <td>60</td>\n",
              "      <td>60</td>\n",
              "      <td>45</td>\n",
              "      <td>100</td>\n",
              "      <td>['Agility', 'Jump', 'Super Strength', 'Transfo...</td>\n",
              "      <td>[]</td>\n",
              "      <td>['Gorilla Woman']</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Marvel Comics</td>\n",
              "      <td>Good</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>1368</td>\n",
              "      <td>Vergil</td>\n",
              "      <td>Vergil Sparda</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16</td>\n",
              "      <td>Vergil, later also known as Nelo Angelo, is on...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>90</td>\n",
              "      <td>75</td>\n",
              "      <td>95</td>\n",
              "      <td>90</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>['Accelerated Healing', 'Agility', 'Duplicatio...</td>\n",
              "      <td>[]</td>\n",
              "      <td>['Gilver, Nelo Angelo, Son of Sparda, The Dark...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Devil May Cry</td>\n",
              "      <td>Capcom</td>\n",
              "      <td>Good</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>Sparda (father) ,Eva (mother) ,Dante (Brother)...</td>\n",
              "      <td>Male</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6'3 • 191 cm</td>\n",
              "      <td>207 lb • 93 kg</td>\n",
              "      <td>Blue</td>\n",
              "      <td>White</td>\n",
              "      <td>NaN</td>\n",
              "      <td>/pictures2/portraits/10/050/11657.jpg?v=154990...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 82 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    Unnamed: 0          name  ... has_agility has_super_strength\n",
              "16         122        Batcow  ...         0.0                0.0\n",
              "40         529  Gorilla Girl  ...         1.0                1.0\n",
              "78        1368        Vergil  ...         1.0                1.0\n",
              "\n",
              "[3 rows x 82 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDhCWnJReUMQ"
      },
      "source": [
        "Se observa que los tres entes poderosos son clasificados como buenos héroes :D.\n",
        "Aplicando san Google pudimos confirmar que tanto Batcow como Gorilla Girl son efectivamente héroes, pero por otro lado, Vergil al ser un antagonista del juego Devil May Cry probablemente sea villano (o por lo menos no un héroe bueno).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BF1beoqllTj"
      },
      "source": [
        "### Wordclouds [Opcional- 0,5] \n",
        "\n",
        "Una buena pero informal forma de comunicar los resultados del trabajo con texto es generar Wordclouds. Este tipo de visualizaciones nos informan de forma gráfica cuales son las palabras más frecuentes según el tamaño de estas al ser posicionadas en un lienzo.\n",
        "<center>\n",
        "<img alt='Ejemplo de una Wordcloud de Starwars' src='https://amueller.github.io/word_cloud/_images/sphx_glr_a_new_hope_001.png' width=400/>\n",
        "\n",
        "Ejemplo de una Wordcloud de Starwars\n",
        "\n",
        "</center>\n",
        "Dicho esto, como equipo docente nos encantaría conocer cuales son las palabras que caracterizan tanto a heroes como neutrales y a villanos y cuales son sus principales diferencias. Por esta razón, les pedimos como última tarea generar una wordcloud con las historias de cada personaje según cada alineamiento (clase). Pueden ocupar el dataset completo para esto. \n",
        "\n",
        "\n",
        "**Nota:** Recuerde eliminar las stopwords. Guías completas para generar las wordclouds, eliminar las stopwords y configurar los parámetros de las nubes creadas pueden ser encontradas en su [documentación oficial](https://amueller.github.io/word_cloud/) y en [datacamp](https://www.datacamp.com/community/tutorials/wordcloud-python).\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBdONTJZnLbd"
      },
      "source": [
        "#### Wordcloud para heroes ####"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-IiZ7PXnLfS"
      },
      "source": [
        "#### Wordcloud para neutrales ####"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVV1M-osnLnj"
      },
      "source": [
        "#### Wordcloud para villanos ####"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HljnDhRcoK83"
      },
      "source": [
        "Comente las principales diferencias entre las tres wordclouds.\n",
        "¿Hay palabras que caracterizen a los grupos y que no aparezcan en los otros?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tM1jthVRoY93"
      },
      "source": [
        "---> Comente aquí <---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rg4ZMq8ezAH6"
      },
      "source": [
        "# Conclusión\n",
        "Eso ha sido todo para el lab de hoy, recuerden que el laboratorio tiene un plazo de entrega de una semana y que **los días de atraso no se pueden utilizar para entregas de lab, solo para tareas**. Cualquier duda del laboratorio, no duden en contactarnos por mail o U-cursos.\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media1.tenor.com/images/fb5bf7cc5a4acb91b4177672886a88ba/tenor.gif?itemid=5591338\">\n",
        "</p>"
      ]
    }
  ]
}